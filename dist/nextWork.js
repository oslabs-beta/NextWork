/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/cookie/index.js":
/*!**************************************!*\
  !*** ./node_modules/cookie/index.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("/*!\n * cookie\n * Copyright(c) 2012-2014 Roman Shtylman\n * Copyright(c) 2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * Module exports.\n * @public\n */\n\nexports.parse = parse;\nexports.serialize = serialize;\n\n/**\n * Module variables.\n * @private\n */\n\nvar __toString = Object.prototype.toString\n\n/**\n * RegExp to match field-content in RFC 7230 sec 3.2\n *\n * field-content = field-vchar [ 1*( SP / HTAB ) field-vchar ]\n * field-vchar   = VCHAR / obs-text\n * obs-text      = %x80-FF\n */\n\nvar fieldContentRegExp = /^[\\u0009\\u0020-\\u007e\\u0080-\\u00ff]+$/;\n\n/**\n * Parse a cookie header.\n *\n * Parse the given cookie header string into an object\n * The object has the various cookies as keys(names) => values\n *\n * @param {string} str\n * @param {object} [options]\n * @return {object}\n * @public\n */\n\nfunction parse(str, options) {\n  if (typeof str !== 'string') {\n    throw new TypeError('argument str must be a string');\n  }\n\n  var obj = {}\n  var opt = options || {};\n  var dec = opt.decode || decode;\n\n  var index = 0\n  while (index < str.length) {\n    var eqIdx = str.indexOf('=', index)\n\n    // no more cookie pairs\n    if (eqIdx === -1) {\n      break\n    }\n\n    var endIdx = str.indexOf(';', index)\n\n    if (endIdx === -1) {\n      endIdx = str.length\n    } else if (endIdx < eqIdx) {\n      // backtrack on prior semicolon\n      index = str.lastIndexOf(';', eqIdx - 1) + 1\n      continue\n    }\n\n    var key = str.slice(index, eqIdx).trim()\n\n    // only assign once\n    if (undefined === obj[key]) {\n      var val = str.slice(eqIdx + 1, endIdx).trim()\n\n      // quoted values\n      if (val.charCodeAt(0) === 0x22) {\n        val = val.slice(1, -1)\n      }\n\n      obj[key] = tryDecode(val, dec);\n    }\n\n    index = endIdx + 1\n  }\n\n  return obj;\n}\n\n/**\n * Serialize data into a cookie header.\n *\n * Serialize the a name value pair into a cookie string suitable for\n * http headers. An optional options object specified cookie parameters.\n *\n * serialize('foo', 'bar', { httpOnly: true })\n *   => \"foo=bar; httpOnly\"\n *\n * @param {string} name\n * @param {string} val\n * @param {object} [options]\n * @return {string}\n * @public\n */\n\nfunction serialize(name, val, options) {\n  var opt = options || {};\n  var enc = opt.encode || encode;\n\n  if (typeof enc !== 'function') {\n    throw new TypeError('option encode is invalid');\n  }\n\n  if (!fieldContentRegExp.test(name)) {\n    throw new TypeError('argument name is invalid');\n  }\n\n  var value = enc(val);\n\n  if (value && !fieldContentRegExp.test(value)) {\n    throw new TypeError('argument val is invalid');\n  }\n\n  var str = name + '=' + value;\n\n  if (null != opt.maxAge) {\n    var maxAge = opt.maxAge - 0;\n\n    if (isNaN(maxAge) || !isFinite(maxAge)) {\n      throw new TypeError('option maxAge is invalid')\n    }\n\n    str += '; Max-Age=' + Math.floor(maxAge);\n  }\n\n  if (opt.domain) {\n    if (!fieldContentRegExp.test(opt.domain)) {\n      throw new TypeError('option domain is invalid');\n    }\n\n    str += '; Domain=' + opt.domain;\n  }\n\n  if (opt.path) {\n    if (!fieldContentRegExp.test(opt.path)) {\n      throw new TypeError('option path is invalid');\n    }\n\n    str += '; Path=' + opt.path;\n  }\n\n  if (opt.expires) {\n    var expires = opt.expires\n\n    if (!isDate(expires) || isNaN(expires.valueOf())) {\n      throw new TypeError('option expires is invalid');\n    }\n\n    str += '; Expires=' + expires.toUTCString()\n  }\n\n  if (opt.httpOnly) {\n    str += '; HttpOnly';\n  }\n\n  if (opt.secure) {\n    str += '; Secure';\n  }\n\n  if (opt.priority) {\n    var priority = typeof opt.priority === 'string'\n      ? opt.priority.toLowerCase()\n      : opt.priority\n\n    switch (priority) {\n      case 'low':\n        str += '; Priority=Low'\n        break\n      case 'medium':\n        str += '; Priority=Medium'\n        break\n      case 'high':\n        str += '; Priority=High'\n        break\n      default:\n        throw new TypeError('option priority is invalid')\n    }\n  }\n\n  if (opt.sameSite) {\n    var sameSite = typeof opt.sameSite === 'string'\n      ? opt.sameSite.toLowerCase() : opt.sameSite;\n\n    switch (sameSite) {\n      case true:\n        str += '; SameSite=Strict';\n        break;\n      case 'lax':\n        str += '; SameSite=Lax';\n        break;\n      case 'strict':\n        str += '; SameSite=Strict';\n        break;\n      case 'none':\n        str += '; SameSite=None';\n        break;\n      default:\n        throw new TypeError('option sameSite is invalid');\n    }\n  }\n\n  return str;\n}\n\n/**\n * URL-decode string value. Optimized to skip native call when no %.\n *\n * @param {string} str\n * @returns {string}\n */\n\nfunction decode (str) {\n  return str.indexOf('%') !== -1\n    ? decodeURIComponent(str)\n    : str\n}\n\n/**\n * URL-encode value.\n *\n * @param {string} str\n * @returns {string}\n */\n\nfunction encode (val) {\n  return encodeURIComponent(val)\n}\n\n/**\n * Determine if value is a Date.\n *\n * @param {*} val\n * @private\n */\n\nfunction isDate (val) {\n  return __toString.call(val) === '[object Date]' ||\n    val instanceof Date\n}\n\n/**\n * Try decoding a string using a decoding function.\n *\n * @param {string} str\n * @param {function} decode\n * @private\n */\n\nfunction tryDecode(str, decode) {\n  try {\n    return decode(str);\n  } catch (e) {\n    return str;\n  }\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/cookie/index.js?");

/***/ }),

/***/ "./node_modules/node-domexception/index.js":
/*!*************************************************!*\
  !*** ./node_modules/node-domexception/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/*! node-domexception. MIT License. Jimmy WÃ¤rting <https://jimmy.warting.se/opensource> */\n\nif (!globalThis.DOMException) {\n  try {\n    const { MessageChannel } = __webpack_require__(/*! worker_threads */ \"worker_threads\"),\n    port = new MessageChannel().port1,\n    ab = new ArrayBuffer()\n    port.postMessage(ab, [ab, ab])\n  } catch (err) {\n    err.constructor.name === 'DOMException' && (\n      globalThis.DOMException = err.constructor\n    )\n  }\n}\n\nmodule.exports = globalThis.DOMException\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-domexception/index.js?");

/***/ }),

/***/ "./node_modules/set-cookie-parser/lib/set-cookie.js":
/*!**********************************************************!*\
  !*** ./node_modules/set-cookie-parser/lib/set-cookie.js ***!
  \**********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar defaultParseOptions = {\n  decodeValues: true,\n  map: false,\n  silent: false,\n};\n\nfunction isNonEmptyString(str) {\n  return typeof str === \"string\" && !!str.trim();\n}\n\nfunction parseString(setCookieValue, options) {\n  var parts = setCookieValue.split(\";\").filter(isNonEmptyString);\n\n  var nameValuePairStr = parts.shift();\n  var parsed = parseNameValuePair(nameValuePairStr);\n  var name = parsed.name;\n  var value = parsed.value;\n\n  options = options\n    ? Object.assign({}, defaultParseOptions, options)\n    : defaultParseOptions;\n\n  try {\n    value = options.decodeValues ? decodeURIComponent(value) : value; // decode cookie value\n  } catch (e) {\n    console.error(\n      \"set-cookie-parser encountered an error while decoding a cookie with value '\" +\n        value +\n        \"'. Set options.decodeValues to false to disable this feature.\",\n      e\n    );\n  }\n\n  var cookie = {\n    name: name,\n    value: value,\n  };\n\n  parts.forEach(function (part) {\n    var sides = part.split(\"=\");\n    var key = sides.shift().trimLeft().toLowerCase();\n    var value = sides.join(\"=\");\n    if (key === \"expires\") {\n      cookie.expires = new Date(value);\n    } else if (key === \"max-age\") {\n      cookie.maxAge = parseInt(value, 10);\n    } else if (key === \"secure\") {\n      cookie.secure = true;\n    } else if (key === \"httponly\") {\n      cookie.httpOnly = true;\n    } else if (key === \"samesite\") {\n      cookie.sameSite = value;\n    } else {\n      cookie[key] = value;\n    }\n  });\n\n  return cookie;\n}\n\nfunction parseNameValuePair(nameValuePairStr) {\n  // Parses name-value-pair according to rfc6265bis draft\n\n  var name = \"\";\n  var value = \"\";\n  var nameValueArr = nameValuePairStr.split(\"=\");\n  if (nameValueArr.length > 1) {\n    name = nameValueArr.shift();\n    value = nameValueArr.join(\"=\"); // everything after the first =, joined by a \"=\" if there was more than one part\n  } else {\n    value = nameValuePairStr;\n  }\n\n  return { name: name, value: value };\n}\n\nfunction parse(input, options) {\n  options = options\n    ? Object.assign({}, defaultParseOptions, options)\n    : defaultParseOptions;\n\n  if (!input) {\n    if (!options.map) {\n      return [];\n    } else {\n      return {};\n    }\n  }\n\n  if (input.headers) {\n    if (typeof input.headers.getSetCookie === \"function\") {\n      // for fetch responses - they combine headers of the same type in the headers array,\n      // but getSetCookie returns an uncombined array\n      input = input.headers.getSetCookie();\n    } else if (input.headers[\"set-cookie\"]) {\n      // fast-path for node.js (which automatically normalizes header names to lower-case\n      input = input.headers[\"set-cookie\"];\n    } else {\n      // slow-path for other environments - see #25\n      var sch =\n        input.headers[\n          Object.keys(input.headers).find(function (key) {\n            return key.toLowerCase() === \"set-cookie\";\n          })\n        ];\n      // warn if called on a request-like object with a cookie header rather than a set-cookie header - see #34, 36\n      if (!sch && input.headers.cookie && !options.silent) {\n        console.warn(\n          \"Warning: set-cookie-parser appears to have been called on a request object. It is designed to parse Set-Cookie headers from responses, not Cookie headers from requests. Set the option {silent: true} to suppress this warning.\"\n        );\n      }\n      input = sch;\n    }\n  }\n  if (!Array.isArray(input)) {\n    input = [input];\n  }\n\n  options = options\n    ? Object.assign({}, defaultParseOptions, options)\n    : defaultParseOptions;\n\n  if (!options.map) {\n    return input.filter(isNonEmptyString).map(function (str) {\n      return parseString(str, options);\n    });\n  } else {\n    var cookies = {};\n    return input.filter(isNonEmptyString).reduce(function (cookies, str) {\n      var cookie = parseString(str, options);\n      cookies[cookie.name] = cookie;\n      return cookies;\n    }, cookies);\n  }\n}\n\n/*\n  Set-Cookie header field-values are sometimes comma joined in one string. This splits them without choking on commas\n  that are within a single set-cookie field-value, such as in the Expires portion.\n\n  This is uncommon, but explicitly allowed - see https://tools.ietf.org/html/rfc2616#section-4.2\n  Node.js does this for every header *except* set-cookie - see https://github.com/nodejs/node/blob/d5e363b77ebaf1caf67cd7528224b651c86815c1/lib/_http_incoming.js#L128\n  React Native's fetch does this for *every* header, including set-cookie.\n\n  Based on: https://github.com/google/j2objc/commit/16820fdbc8f76ca0c33472810ce0cb03d20efe25\n  Credits to: https://github.com/tomball for original and https://github.com/chrusart for JavaScript implementation\n*/\nfunction splitCookiesString(cookiesString) {\n  if (Array.isArray(cookiesString)) {\n    return cookiesString;\n  }\n  if (typeof cookiesString !== \"string\") {\n    return [];\n  }\n\n  var cookiesStrings = [];\n  var pos = 0;\n  var start;\n  var ch;\n  var lastComma;\n  var nextStart;\n  var cookiesSeparatorFound;\n\n  function skipWhitespace() {\n    while (pos < cookiesString.length && /\\s/.test(cookiesString.charAt(pos))) {\n      pos += 1;\n    }\n    return pos < cookiesString.length;\n  }\n\n  function notSpecialChar() {\n    ch = cookiesString.charAt(pos);\n\n    return ch !== \"=\" && ch !== \";\" && ch !== \",\";\n  }\n\n  while (pos < cookiesString.length) {\n    start = pos;\n    cookiesSeparatorFound = false;\n\n    while (skipWhitespace()) {\n      ch = cookiesString.charAt(pos);\n      if (ch === \",\") {\n        // ',' is a cookie separator if we have later first '=', not ';' or ','\n        lastComma = pos;\n        pos += 1;\n\n        skipWhitespace();\n        nextStart = pos;\n\n        while (pos < cookiesString.length && notSpecialChar()) {\n          pos += 1;\n        }\n\n        // currently special character\n        if (pos < cookiesString.length && cookiesString.charAt(pos) === \"=\") {\n          // we found cookies separator\n          cookiesSeparatorFound = true;\n          // pos is inside the next cookie, so back up and return it.\n          pos = nextStart;\n          cookiesStrings.push(cookiesString.substring(start, lastComma));\n          start = pos;\n        } else {\n          // in param ',' or param separator ';',\n          // we continue from that comma\n          pos = lastComma + 1;\n        }\n      } else {\n        pos += 1;\n      }\n    }\n\n    if (!cookiesSeparatorFound || pos >= cookiesString.length) {\n      cookiesStrings.push(cookiesString.substring(start, cookiesString.length));\n    }\n  }\n\n  return cookiesStrings;\n}\n\nmodule.exports = parse;\nmodule.exports.parse = parse;\nmodule.exports.parseString = parseString;\nmodule.exports.splitCookiesString = splitCookiesString;\n\n\n//# sourceURL=webpack://next-work/./node_modules/set-cookie-parser/lib/set-cookie.js?");

/***/ }),

/***/ "./src/helpers.ts":
/*!************************!*\
  !*** ./src/helpers.ts ***!
  \************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getDuration = exports.buildResponseCookies = exports.buildParams = exports.buildQueryParams = exports.buildHeaders = exports.buildRequestCookies = exports.addHeaders = void 0;\nconst cookie_1 = __importDefault(__webpack_require__(/*! cookie */ \"./node_modules/cookie/index.js\"));\nconst set_cookie_parser_1 = __importDefault(__webpack_require__(/*! set-cookie-parser */ \"./node_modules/set-cookie-parser/lib/set-cookie.js\"));\nconst query_string_1 = __importDefault(__webpack_require__(/*! query-string */ \"./node_modules/query-string/index.js\"));\nconst addHeaders = (oldHeaders, requestIdHeader) => {\n    if (!oldHeaders) {\n        return new Headers(requestIdHeader);\n    }\n    else if (oldHeaders instanceof Map || oldHeaders instanceof Headers) {\n        const headers = new Headers(oldHeaders);\n        for (const name in requestIdHeader) {\n            headers.set(name, requestIdHeader[name]);\n        }\n        return headers;\n    }\n    else {\n        const headers = new Headers({ ...oldHeaders, ...requestIdHeader });\n        return headers;\n    }\n};\nexports.addHeaders = addHeaders;\nconst buildRequestCookies = (headers) => {\n    const cookies = [];\n    for (const header in headers) {\n        if (header.toLowerCase() === 'cookie') {\n            const parsed = cookie_1.default.parse(headers[header]);\n            for (const name in parsed) {\n                const value = parsed[name];\n                cookies.push({ name, value });\n            }\n        }\n    }\n    return cookies;\n};\nexports.buildRequestCookies = buildRequestCookies;\nconst buildHeaders = (headers) => {\n    const list = [];\n    if (Array.isArray(headers)) {\n        for (let i = 0; i < headers.length; i += 2) {\n            list.push({\n                name: headers[i],\n                value: headers[i + 1],\n            });\n        }\n    }\n    else {\n        for (const [key, values] of Object.entries(headers)) {\n            if (Array.isArray(values)) {\n                for (const value of values) {\n                    list.push({ name: key, value });\n                }\n            }\n            else if (typeof values === 'string') {\n                list.push({ name: key, value: values });\n            }\n        }\n    }\n    return list;\n};\nexports.buildHeaders = buildHeaders;\nconst buildQueryParams = (queryParams) => {\n    return [...queryParams].map(([name, value]) => ({ name, value }));\n};\nexports.buildQueryParams = buildQueryParams;\nconst buildParams = (paramString) => {\n    const params = [];\n    const parsed = query_string_1.default.parse(paramString);\n    for (const [key, value] of Object.entries(parsed)) {\n        if (Array.isArray(value)) {\n            for (const item of value) {\n                params.push({ name: key, value: item });\n            }\n        }\n        else {\n            params.push({ name: key, value: value });\n        }\n    }\n    return params;\n};\nexports.buildParams = buildParams;\nconst buildResponseCookies = (headers) => {\n    const cookies = [];\n    const setCookies = headers['set-cookie'];\n    if (setCookies) {\n        setCookies.forEach((headerValue) => {\n            let parsed;\n            try {\n                parsed = set_cookie_parser_1.default.parse(headerValue);\n            }\n            catch (err) {\n                return;\n            }\n            parsed.forEach((cookie) => {\n                const { name, value, path, domain, expires, httpOnly, secure } = cookie;\n                if (!name || !value)\n                    return;\n                const harCookie = {\n                    name,\n                    value,\n                    httpOnly: httpOnly || false,\n                    secure: secure || false,\n                };\n                if (path) {\n                    harCookie.path = path;\n                }\n                if (domain) {\n                    harCookie.domain = domain;\n                }\n                if (expires) {\n                    const dt = new Date(expires);\n                    harCookie.expires = dt.toISOString();\n                }\n                cookies.push(harCookie);\n            });\n        });\n    }\n    return cookies;\n};\nexports.buildResponseCookies = buildResponseCookies;\nconst getDuration = (a, b) => {\n    const seconds = b[0] - a[0];\n    const nanoseconds = b[1] - a[1];\n    return seconds * 1000 + nanoseconds / 1e6;\n};\nexports.getDuration = getDuration;\n\n\n//# sourceURL=webpack://next-work/./src/helpers.ts?");

/***/ }),

/***/ "./src/nextWork.ts":
/*!*************************!*\
  !*** ./src/nextWork.ts ***!
  \*************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.nextWorkFetch = exports.getInputUrl = exports.createAgentClass = void 0;\nconst node_http_1 = __importDefault(__webpack_require__(/*! node:http */ \"node:http\"));\nconst node_http_2 = __webpack_require__(/*! node:http */ \"node:http\");\n// import { Response } from 'node-fetch';\nconst node_https_1 = __webpack_require__(/*! node:https */ \"node:https\");\nconst node_fetch_1 = __importDefault(__webpack_require__(/*! node-fetch */ \"./node_modules/node-fetch/src/index.js\"));\n// @ts-ignore\nconst baseFetch = node_fetch_1.default;\nconst nanoid_1 = __webpack_require__(/*! nanoid */ \"./node_modules/nanoid/index.js\");\n// const generateId = nanoid;\nconst fs = __importStar(__webpack_require__(/*! node:fs */ \"node:fs\"));\nconst path = __importStar(__webpack_require__(/*! node:path */ \"node:path\"));\nconst node_url_1 = __webpack_require__(/*! node:url */ \"node:url\");\nconst helpers_1 = __webpack_require__(/*! ./helpers */ \"./src/helpers.ts\");\nconst headerName = 'x-har-request-id';\nconst harEntryMap = new Map();\nconst handleRequest = (request, options) => {\n    if (!options || typeof options !== 'object') {\n        return;\n    }\n    const headers = options.headers || {};\n    const requestId = headers[headerName] ? headers[headerName] : null;\n    if (!requestId) {\n        return;\n    }\n    // Redirects! Fetch follows them (in `follow`) mode and uses the same request\n    // headers. So we'll see multiple requests with the same ID. We should remove\n    // any previous entry from `harEntryMap` and attach it as a \"parent\" to this\n    // one.\n    const parentEntry = harEntryMap.get(requestId);\n    if (parentEntry) {\n        harEntryMap.delete(requestId);\n    }\n    const url = new node_url_1.URL(options.url || options.href); // Depends on Node version?\n    const entry = {\n        _parent: parentEntry,\n        _timestamps: {\n            // needs to be changed to bigint - issues with json parse\n            //process.hrtime() returns [seconds, nanoseconds]\n            start: process.hrtime(),\n        },\n        _resourceType: 'fetch',\n        startedDateTime: new Date(Date.now()).toISOString(),\n        cache: {\n            beforeRequest: null,\n            afterRequest: null,\n        },\n        timings: {\n            blocked: -1,\n            dns: -1,\n            connect: -1,\n            send: 0,\n            wait: 0,\n            receive: 0,\n            ssl: -1,\n        },\n        request: {\n            method: request.method,\n            url: url.href,\n            cookies: (0, helpers_1.buildRequestCookies)(headers),\n            headers: (0, helpers_1.buildHeaders)(headers),\n            queryString: (0, helpers_1.buildQueryParams)(url.searchParams),\n            headersSize: -1,\n            bodySize: -1,\n        },\n    };\n    const _write = request.write;\n    const _end = request.end;\n    let requestBody;\n    const concatBody = (chunk) => {\n        if (typeof chunk === 'string') {\n            if (!requestBody) {\n                requestBody = chunk;\n            }\n            else {\n                requestBody += chunk;\n            }\n        }\n        else if (Buffer.isBuffer(chunk)) {\n            if (!requestBody) {\n                requestBody = chunk;\n            }\n            else {\n                let copiedBody = Buffer.from(requestBody);\n                requestBody = Buffer.concat([copiedBody, chunk]);\n            }\n        }\n    };\n    request.write = function (chunk, encoding, callback) {\n        concatBody(chunk);\n        return _write.call(this, chunk, encoding, callback);\n    };\n    request.end = function (chunk, encoding, callback) {\n        concatBody(chunk);\n        if (requestBody) {\n            entry.request.bodySize = Buffer.byteLength(requestBody);\n            let mimeType;\n            for (const name in headers) {\n                if (name.toLowerCase() === 'content-type') {\n                    mimeType = headers[name];\n                    break;\n                }\n            }\n            if (mimeType) {\n                const bodyString = requestBody.toString(); // FIXME: Assumes encoding?\n                if (mimeType === 'application/x-www-form-urlencoded') {\n                    entry.request.postData = {\n                        mimeType,\n                        params: (0, helpers_1.buildParams)(bodyString),\n                    };\n                }\n                else {\n                    entry.request.postData = { mimeType, text: bodyString };\n                }\n            }\n        }\n        return _end.call(this, chunk, encoding, callback);\n    };\n    let removeSocketListeners;\n    request.on('socket', (socket) => {\n        entry._timestamps.socket = process.hrtime();\n        const onLookup = () => {\n            entry._timestamps.lookup = process.hrtime();\n        };\n        const onConnect = () => {\n            entry._timestamps.connect = process.hrtime();\n        };\n        const onSecureConnect = () => {\n            entry._timestamps.secureConnect = process.hrtime();\n        };\n        socket.once('lookup', onLookup);\n        socket.once('connect', onConnect);\n        socket.once('secureConnect', onSecureConnect);\n        removeSocketListeners = () => {\n            socket.removeListener('lookup', onLookup);\n            socket.removeListener('connect', onConnect);\n            socket.removeListener('secureConnect', onSecureConnect);\n        };\n    });\n    request.on('finish', () => {\n        entry._timestamps.sent = process.hrtime();\n        removeSocketListeners();\n    });\n    request.on('response', (response) => {\n        entry._timestamps.firstByte = process.hrtime();\n        harEntryMap.set(requestId, entry);\n        // Now we know whether `lookup` or `connect` happened. It's possible they\n        // were skipped if the hostname was already resolved (or we were given an\n        // IP directly), or if a connection was already open (e.g. due to\n        // `keep-alive`).\n        if (!entry._timestamps.lookup) {\n            entry._timestamps.lookup = entry._timestamps.socket;\n        }\n        if (!entry._timestamps.connect) {\n            entry._timestamps.connect = entry._timestamps.lookup;\n        }\n        // Populate request info that isn't available until now.\n        const httpVersion = `HTTP/${response.httpVersion}`;\n        entry.request.httpVersion = httpVersion;\n        entry.response = {\n            status: response.statusCode,\n            statusText: response.statusMessage,\n            httpVersion,\n            cookies: (0, helpers_1.buildResponseCookies)(response.headers),\n            headers: (0, helpers_1.buildHeaders)(response.rawHeaders),\n            content: {\n                size: -1,\n                mimeType: response.headers['content-type'],\n            },\n            redirectURL: response.headers.location || '',\n            headersSize: -1,\n            bodySize: -1,\n        };\n        let compressed;\n        // Detect supported compression encodings.\n        if (response.headers['content-encoding']) {\n            compressed = /^(gzip|compress|deflate|br)$/.test(response.headers['content-encoding']);\n        }\n        if (compressed) {\n            entry._compressed = true;\n            response.on('data', (chunk) => {\n                if (entry.response) {\n                    if (entry.response.bodySize === -1) {\n                        entry.response.bodySize = 0;\n                    }\n                    entry.response.bodySize += Buffer.byteLength(chunk);\n                }\n            });\n        }\n    });\n};\nconst createAgentClass = (BaseAgent) => {\n    //http(s).Agent\n    class HarAgent extends BaseAgent {\n        // what args are going into constructor?\n        constructor(...args) {\n            super(...args);\n            this.addRequest.customHarAgentEnabled = true;\n        }\n        addRequest(request, ...args) {\n            // @ts-ignore\n            handleRequest(request, ...args);\n            super.addRequest(request, ...args);\n        }\n    }\n    return HarAgent;\n};\nexports.createAgentClass = createAgentClass;\nlet globalHarHttpAgent;\nlet globalHarHttpsAgent;\nconst HarHttpAgent = (0, exports.createAgentClass)(node_http_2.Agent);\nconst HarHttpsAgent = (0, exports.createAgentClass)(node_https_1.Agent);\nconst instrumentAgentInstance = (agent) => {\n    const { addRequest: originalAddRequest } = agent;\n    if (originalAddRequest) {\n        if (!originalAddRequest.customHarAgentEnabled) {\n            agent.addRequest = function addRequest(request, options, port, localAddress) {\n                handleRequest(request, options);\n                return originalAddRequest.call(this, request, options, port, localAddress); //here 'this' refers to agent object\n            };\n            agent.addRequest.customHarAgentEnabled = true;\n        }\n    }\n};\nfunction getInputUrl(resource) {\n    let url;\n    if (typeof resource === 'string') {\n        url = resource;\n    }\n    else {\n        url = resource.href;\n    }\n    return new node_url_1.URL(url);\n}\nexports.getInputUrl = getInputUrl;\n// handle cases where agent does not exist in fetch options\nconst getGlobalAgent = (resource) => {\n    const url = getInputUrl(resource);\n    if (url.protocol === 'http:') {\n        if (!globalHarHttpAgent) {\n            globalHarHttpAgent = new HarHttpAgent();\n        }\n        return globalHarHttpAgent;\n    }\n    if (!globalHarHttpsAgent) {\n        globalHarHttpsAgent = new HarHttpsAgent();\n    }\n    return globalHarHttpsAgent;\n};\n// handle agent creation and/or assignment\nconst getAgent = (resource, options) => {\n    if (options.agent) {\n        if (typeof options.agent === 'function') {\n            const agentFn = options.agent; // Type guard\n            return function (...args) {\n                //args are going to be resource and options obj\n                // @ts-ignore\n                const agent = agentFn.call(this, ...args);\n                if (agent) {\n                    instrumentAgentInstance(agent);\n                    return agent;\n                }\n                return getGlobalAgent(resource);\n            };\n        }\n        instrumentAgentInstance(options.agent);\n        return options.agent;\n    }\n    return getGlobalAgent(resource);\n};\nlet globalHarLog;\nconst harLogQueue = [];\nconst createNextWorkServer = () => {\n    const server = node_http_1.default.createServer();\n    let timeoutId;\n    server.on('request', (request, response) => {\n        // below is for dev purposes only - will delete when push to production\n        // as GUI will be Chrome Extension\n        if (request.method === 'GET' && request.url === '/') {\n            const data = fs.readFile(path.join(__dirname, '../nextWorkFetchLibrary/stream.html'), 'utf-8', (err, data) => {\n                if (err) {\n                    console.log(err);\n                }\n                else {\n                    response.writeHead(200, { 'Content-Type': 'text/html' });\n                    response.write(data);\n                }\n                response.end();\n            });\n        }\n        if (request.method === 'GET' && request.url === '/stream') {\n            response.writeHead(200, { 'Content-Type': 'text/event-stream' });\n            const send = (response) => {\n                if (harLogQueue.length) {\n                    response.write(`data: ${JSON.stringify(harLogQueue[0])}\\n\\n`);\n                    harLogQueue.shift();\n                }\n                timeoutId = setTimeout(() => send(response), 1000);\n            };\n            // handle client close connection\n            request.once('close', () => {\n                console.log('client closed connection');\n                clearTimeout(timeoutId);\n            });\n            send(response);\n        }\n    });\n    server.listen(3001, () => {\n        console.log('server listening on port 3001');\n    });\n};\n// Wrap and return custom fetch with HAR entry tracking\nconst nextWorkFetch = () => {\n    createNextWorkServer();\n    return function fetch(resource, options = {}, defaults = { trackRequest: true, harPageRef: '' }) {\n        if (defaults.trackRequest === false) {\n            return baseFetch(resource, options);\n        }\n        const requestId = (0, nanoid_1.nanoid)();\n        options = Object.assign({}, options, {\n            //add unique request id to headers\n            headers: (0, helpers_1.addHeaders)(options.headers, { [headerName]: requestId }),\n            // get custom agent class to pass into baseFetch to handle request\n            agent: getAgent(resource, options),\n        });\n        const { trackRequest, harPageRef } = defaults;\n        return baseFetch(resource, options)\n            .then(async (response) => {\n            const entry = harEntryMap.get(requestId);\n            harEntryMap.delete(requestId);\n            if (!entry) {\n                return response;\n            }\n            // We need to consume the decoded response in order to populate the\n            // `response.content` field.\n            const text = await response.text();\n            const { _timestamps: time } = entry;\n            time.received = process.hrtime();\n            const parents = [];\n            let child = entry;\n            do {\n                const parent = child._parent;\n                // Remove linked parent references as they're flattened.\n                delete child._parent;\n                if (parent) {\n                    parents.unshift(parent);\n                }\n                child = parent;\n            } while (child);\n            const responseCopy = new Response(text, {\n                status: response.status,\n                statusText: response.statusText,\n                headers: response.headers,\n                ok: response.ok,\n                size: response.size,\n                url: response.url,\n            });\n            // Allow grouping by pages.\n            entry.pageref = harPageRef || 'page_1';\n            parents.forEach((parent) => {\n                parent.pageref = entry.pageref;\n            });\n            // Response content info.\n            const bodySize = Buffer.byteLength(text);\n            entry.response.content.text = text;\n            entry.response.content.size = bodySize;\n            if (entry._compressed) {\n                if (entry.response.bodySize !== -1) {\n                    entry.response.content.compression =\n                        entry.response.content.size - entry.response.bodySize;\n                }\n            }\n            else {\n                entry.response.bodySize = bodySize;\n            }\n            // Finalize timing info.\n            // Chrome's HAR viewer (the Network panel) is broken and doesn't honor\n            // the HAR spec. If `blocked` is not a positive number, it shows the\n            // `wait` time as stalled instead of the time waiting for the response.\n            entry.timings.blocked = Math.max((0, helpers_1.getDuration)(time.start, time.socket), 0.01 // Minimum value, see above.\n            );\n            entry.timings.dns = (0, helpers_1.getDuration)(time.socket, time.lookup);\n            entry.timings.connect = (0, helpers_1.getDuration)(time.lookup, \n            // For backwards compatibility with HAR 1.1, the `connect` timing\n            // includes `ssl` instead of being mutually exclusive.\n            time.secureConnect || time.connect);\n            if (time.secureConnect) {\n                entry.timings.ssl = (0, helpers_1.getDuration)(time.connect, time.secureConnect);\n            }\n            entry.timings.send = (0, helpers_1.getDuration)(time.secureConnect || time.connect, time.sent);\n            entry.timings.wait = Math.max(\n            // Seems like it might be possible to receive a response before the\n            // request fires its `finish` event. This is just a hunch and it would\n            // be worthwhile to disprove.\n            (0, helpers_1.getDuration)(time.sent, time.firstByte), 0);\n            entry.timings.receive = (0, helpers_1.getDuration)(time.firstByte, time.received);\n            entry.time = (0, helpers_1.getDuration)(time.start, time.received);\n            responseCopy.harEntry = entry;\n            harLogQueue.push(...parents, entry);\n            return responseCopy;\n        })\n            .catch((err) => {\n            harEntryMap.delete(requestId);\n            throw err;\n        });\n    };\n};\nexports.nextWorkFetch = nextWorkFetch;\n// @ts-ignore\nfetch = (0, exports.nextWorkFetch)();\n\n\n//# sourceURL=webpack://next-work/./src/nextWork.ts?");

/***/ }),

/***/ "./node_modules/web-streams-polyfill/dist/ponyfill.es2018.js":
/*!*******************************************************************!*\
  !*** ./node_modules/web-streams-polyfill/dist/ponyfill.es2018.js ***!
  \*******************************************************************/
/***/ (function(__unused_webpack_module, exports) {

eval("/**\n * web-streams-polyfill v3.2.1\n */\n(function (global, factory) {\n     true ? factory(exports) :\n    0;\n}(this, (function (exports) { 'use strict';\n\n    /// <reference lib=\"es2015.symbol\" />\n    const SymbolPolyfill = typeof Symbol === 'function' && typeof Symbol.iterator === 'symbol' ?\n        Symbol :\n        description => `Symbol(${description})`;\n\n    /// <reference lib=\"dom\" />\n    function noop() {\n        return undefined;\n    }\n    function getGlobals() {\n        if (typeof self !== 'undefined') {\n            return self;\n        }\n        else if (typeof window !== 'undefined') {\n            return window;\n        }\n        else if (typeof global !== 'undefined') {\n            return global;\n        }\n        return undefined;\n    }\n    const globals = getGlobals();\n\n    function typeIsObject(x) {\n        return (typeof x === 'object' && x !== null) || typeof x === 'function';\n    }\n    const rethrowAssertionErrorRejection = noop;\n\n    const originalPromise = Promise;\n    const originalPromiseThen = Promise.prototype.then;\n    const originalPromiseResolve = Promise.resolve.bind(originalPromise);\n    const originalPromiseReject = Promise.reject.bind(originalPromise);\n    function newPromise(executor) {\n        return new originalPromise(executor);\n    }\n    function promiseResolvedWith(value) {\n        return originalPromiseResolve(value);\n    }\n    function promiseRejectedWith(reason) {\n        return originalPromiseReject(reason);\n    }\n    function PerformPromiseThen(promise, onFulfilled, onRejected) {\n        // There doesn't appear to be any way to correctly emulate the behaviour from JavaScript, so this is just an\n        // approximation.\n        return originalPromiseThen.call(promise, onFulfilled, onRejected);\n    }\n    function uponPromise(promise, onFulfilled, onRejected) {\n        PerformPromiseThen(PerformPromiseThen(promise, onFulfilled, onRejected), undefined, rethrowAssertionErrorRejection);\n    }\n    function uponFulfillment(promise, onFulfilled) {\n        uponPromise(promise, onFulfilled);\n    }\n    function uponRejection(promise, onRejected) {\n        uponPromise(promise, undefined, onRejected);\n    }\n    function transformPromiseWith(promise, fulfillmentHandler, rejectionHandler) {\n        return PerformPromiseThen(promise, fulfillmentHandler, rejectionHandler);\n    }\n    function setPromiseIsHandledToTrue(promise) {\n        PerformPromiseThen(promise, undefined, rethrowAssertionErrorRejection);\n    }\n    const queueMicrotask = (() => {\n        const globalQueueMicrotask = globals && globals.queueMicrotask;\n        if (typeof globalQueueMicrotask === 'function') {\n            return globalQueueMicrotask;\n        }\n        const resolvedPromise = promiseResolvedWith(undefined);\n        return (fn) => PerformPromiseThen(resolvedPromise, fn);\n    })();\n    function reflectCall(F, V, args) {\n        if (typeof F !== 'function') {\n            throw new TypeError('Argument is not a function');\n        }\n        return Function.prototype.apply.call(F, V, args);\n    }\n    function promiseCall(F, V, args) {\n        try {\n            return promiseResolvedWith(reflectCall(F, V, args));\n        }\n        catch (value) {\n            return promiseRejectedWith(value);\n        }\n    }\n\n    // Original from Chromium\n    // https://chromium.googlesource.com/chromium/src/+/0aee4434a4dba42a42abaea9bfbc0cd196a63bc1/third_party/blink/renderer/core/streams/SimpleQueue.js\n    const QUEUE_MAX_ARRAY_SIZE = 16384;\n    /**\n     * Simple queue structure.\n     *\n     * Avoids scalability issues with using a packed array directly by using\n     * multiple arrays in a linked list and keeping the array size bounded.\n     */\n    class SimpleQueue {\n        constructor() {\n            this._cursor = 0;\n            this._size = 0;\n            // _front and _back are always defined.\n            this._front = {\n                _elements: [],\n                _next: undefined\n            };\n            this._back = this._front;\n            // The cursor is used to avoid calling Array.shift().\n            // It contains the index of the front element of the array inside the\n            // front-most node. It is always in the range [0, QUEUE_MAX_ARRAY_SIZE).\n            this._cursor = 0;\n            // When there is only one node, size === elements.length - cursor.\n            this._size = 0;\n        }\n        get length() {\n            return this._size;\n        }\n        // For exception safety, this method is structured in order:\n        // 1. Read state\n        // 2. Calculate required state mutations\n        // 3. Perform state mutations\n        push(element) {\n            const oldBack = this._back;\n            let newBack = oldBack;\n            if (oldBack._elements.length === QUEUE_MAX_ARRAY_SIZE - 1) {\n                newBack = {\n                    _elements: [],\n                    _next: undefined\n                };\n            }\n            // push() is the mutation most likely to throw an exception, so it\n            // goes first.\n            oldBack._elements.push(element);\n            if (newBack !== oldBack) {\n                this._back = newBack;\n                oldBack._next = newBack;\n            }\n            ++this._size;\n        }\n        // Like push(), shift() follows the read -> calculate -> mutate pattern for\n        // exception safety.\n        shift() { // must not be called on an empty queue\n            const oldFront = this._front;\n            let newFront = oldFront;\n            const oldCursor = this._cursor;\n            let newCursor = oldCursor + 1;\n            const elements = oldFront._elements;\n            const element = elements[oldCursor];\n            if (newCursor === QUEUE_MAX_ARRAY_SIZE) {\n                newFront = oldFront._next;\n                newCursor = 0;\n            }\n            // No mutations before this point.\n            --this._size;\n            this._cursor = newCursor;\n            if (oldFront !== newFront) {\n                this._front = newFront;\n            }\n            // Permit shifted element to be garbage collected.\n            elements[oldCursor] = undefined;\n            return element;\n        }\n        // The tricky thing about forEach() is that it can be called\n        // re-entrantly. The queue may be mutated inside the callback. It is easy to\n        // see that push() within the callback has no negative effects since the end\n        // of the queue is checked for on every iteration. If shift() is called\n        // repeatedly within the callback then the next iteration may return an\n        // element that has been removed. In this case the callback will be called\n        // with undefined values until we either \"catch up\" with elements that still\n        // exist or reach the back of the queue.\n        forEach(callback) {\n            let i = this._cursor;\n            let node = this._front;\n            let elements = node._elements;\n            while (i !== elements.length || node._next !== undefined) {\n                if (i === elements.length) {\n                    node = node._next;\n                    elements = node._elements;\n                    i = 0;\n                    if (elements.length === 0) {\n                        break;\n                    }\n                }\n                callback(elements[i]);\n                ++i;\n            }\n        }\n        // Return the element that would be returned if shift() was called now,\n        // without modifying the queue.\n        peek() { // must not be called on an empty queue\n            const front = this._front;\n            const cursor = this._cursor;\n            return front._elements[cursor];\n        }\n    }\n\n    function ReadableStreamReaderGenericInitialize(reader, stream) {\n        reader._ownerReadableStream = stream;\n        stream._reader = reader;\n        if (stream._state === 'readable') {\n            defaultReaderClosedPromiseInitialize(reader);\n        }\n        else if (stream._state === 'closed') {\n            defaultReaderClosedPromiseInitializeAsResolved(reader);\n        }\n        else {\n            defaultReaderClosedPromiseInitializeAsRejected(reader, stream._storedError);\n        }\n    }\n    // A client of ReadableStreamDefaultReader and ReadableStreamBYOBReader may use these functions directly to bypass state\n    // check.\n    function ReadableStreamReaderGenericCancel(reader, reason) {\n        const stream = reader._ownerReadableStream;\n        return ReadableStreamCancel(stream, reason);\n    }\n    function ReadableStreamReaderGenericRelease(reader) {\n        if (reader._ownerReadableStream._state === 'readable') {\n            defaultReaderClosedPromiseReject(reader, new TypeError(`Reader was released and can no longer be used to monitor the stream's closedness`));\n        }\n        else {\n            defaultReaderClosedPromiseResetToRejected(reader, new TypeError(`Reader was released and can no longer be used to monitor the stream's closedness`));\n        }\n        reader._ownerReadableStream._reader = undefined;\n        reader._ownerReadableStream = undefined;\n    }\n    // Helper functions for the readers.\n    function readerLockException(name) {\n        return new TypeError('Cannot ' + name + ' a stream using a released reader');\n    }\n    // Helper functions for the ReadableStreamDefaultReader.\n    function defaultReaderClosedPromiseInitialize(reader) {\n        reader._closedPromise = newPromise((resolve, reject) => {\n            reader._closedPromise_resolve = resolve;\n            reader._closedPromise_reject = reject;\n        });\n    }\n    function defaultReaderClosedPromiseInitializeAsRejected(reader, reason) {\n        defaultReaderClosedPromiseInitialize(reader);\n        defaultReaderClosedPromiseReject(reader, reason);\n    }\n    function defaultReaderClosedPromiseInitializeAsResolved(reader) {\n        defaultReaderClosedPromiseInitialize(reader);\n        defaultReaderClosedPromiseResolve(reader);\n    }\n    function defaultReaderClosedPromiseReject(reader, reason) {\n        if (reader._closedPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(reader._closedPromise);\n        reader._closedPromise_reject(reason);\n        reader._closedPromise_resolve = undefined;\n        reader._closedPromise_reject = undefined;\n    }\n    function defaultReaderClosedPromiseResetToRejected(reader, reason) {\n        defaultReaderClosedPromiseInitializeAsRejected(reader, reason);\n    }\n    function defaultReaderClosedPromiseResolve(reader) {\n        if (reader._closedPromise_resolve === undefined) {\n            return;\n        }\n        reader._closedPromise_resolve(undefined);\n        reader._closedPromise_resolve = undefined;\n        reader._closedPromise_reject = undefined;\n    }\n\n    const AbortSteps = SymbolPolyfill('[[AbortSteps]]');\n    const ErrorSteps = SymbolPolyfill('[[ErrorSteps]]');\n    const CancelSteps = SymbolPolyfill('[[CancelSteps]]');\n    const PullSteps = SymbolPolyfill('[[PullSteps]]');\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isFinite#Polyfill\n    const NumberIsFinite = Number.isFinite || function (x) {\n        return typeof x === 'number' && isFinite(x);\n    };\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/trunc#Polyfill\n    const MathTrunc = Math.trunc || function (v) {\n        return v < 0 ? Math.ceil(v) : Math.floor(v);\n    };\n\n    // https://heycam.github.io/webidl/#idl-dictionaries\n    function isDictionary(x) {\n        return typeof x === 'object' || typeof x === 'function';\n    }\n    function assertDictionary(obj, context) {\n        if (obj !== undefined && !isDictionary(obj)) {\n            throw new TypeError(`${context} is not an object.`);\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-callback-functions\n    function assertFunction(x, context) {\n        if (typeof x !== 'function') {\n            throw new TypeError(`${context} is not a function.`);\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-object\n    function isObject(x) {\n        return (typeof x === 'object' && x !== null) || typeof x === 'function';\n    }\n    function assertObject(x, context) {\n        if (!isObject(x)) {\n            throw new TypeError(`${context} is not an object.`);\n        }\n    }\n    function assertRequiredArgument(x, position, context) {\n        if (x === undefined) {\n            throw new TypeError(`Parameter ${position} is required in '${context}'.`);\n        }\n    }\n    function assertRequiredField(x, field, context) {\n        if (x === undefined) {\n            throw new TypeError(`${field} is required in '${context}'.`);\n        }\n    }\n    // https://heycam.github.io/webidl/#idl-unrestricted-double\n    function convertUnrestrictedDouble(value) {\n        return Number(value);\n    }\n    function censorNegativeZero(x) {\n        return x === 0 ? 0 : x;\n    }\n    function integerPart(x) {\n        return censorNegativeZero(MathTrunc(x));\n    }\n    // https://heycam.github.io/webidl/#idl-unsigned-long-long\n    function convertUnsignedLongLongWithEnforceRange(value, context) {\n        const lowerBound = 0;\n        const upperBound = Number.MAX_SAFE_INTEGER;\n        let x = Number(value);\n        x = censorNegativeZero(x);\n        if (!NumberIsFinite(x)) {\n            throw new TypeError(`${context} is not a finite number`);\n        }\n        x = integerPart(x);\n        if (x < lowerBound || x > upperBound) {\n            throw new TypeError(`${context} is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`);\n        }\n        if (!NumberIsFinite(x) || x === 0) {\n            return 0;\n        }\n        // TODO Use BigInt if supported?\n        // let xBigInt = BigInt(integerPart(x));\n        // xBigInt = BigInt.asUintN(64, xBigInt);\n        // return Number(xBigInt);\n        return x;\n    }\n\n    function assertReadableStream(x, context) {\n        if (!IsReadableStream(x)) {\n            throw new TypeError(`${context} is not a ReadableStream.`);\n        }\n    }\n\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamDefaultReader(stream) {\n        return new ReadableStreamDefaultReader(stream);\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamAddReadRequest(stream, readRequest) {\n        stream._reader._readRequests.push(readRequest);\n    }\n    function ReadableStreamFulfillReadRequest(stream, chunk, done) {\n        const reader = stream._reader;\n        const readRequest = reader._readRequests.shift();\n        if (done) {\n            readRequest._closeSteps();\n        }\n        else {\n            readRequest._chunkSteps(chunk);\n        }\n    }\n    function ReadableStreamGetNumReadRequests(stream) {\n        return stream._reader._readRequests.length;\n    }\n    function ReadableStreamHasDefaultReader(stream) {\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return false;\n        }\n        if (!IsReadableStreamDefaultReader(reader)) {\n            return false;\n        }\n        return true;\n    }\n    /**\n     * A default reader vended by a {@link ReadableStream}.\n     *\n     * @public\n     */\n    class ReadableStreamDefaultReader {\n        constructor(stream) {\n            assertRequiredArgument(stream, 1, 'ReadableStreamDefaultReader');\n            assertReadableStream(stream, 'First parameter');\n            if (IsReadableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n            }\n            ReadableStreamReaderGenericInitialize(this, stream);\n            this._readRequests = new SimpleQueue();\n        }\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed,\n         * or rejected if the stream ever errors or the reader's lock is released before the stream finishes closing.\n         */\n        get closed() {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        }\n        /**\n         * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n         */\n        cancel(reason = undefined) {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('cancel'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('cancel'));\n            }\n            return ReadableStreamReaderGenericCancel(this, reason);\n        }\n        /**\n         * Returns a promise that allows access to the next chunk from the stream's internal queue, if available.\n         *\n         * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n         */\n        read() {\n            if (!IsReadableStreamDefaultReader(this)) {\n                return promiseRejectedWith(defaultReaderBrandCheckException('read'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('read from'));\n            }\n            let resolvePromise;\n            let rejectPromise;\n            const promise = newPromise((resolve, reject) => {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            const readRequest = {\n                _chunkSteps: chunk => resolvePromise({ value: chunk, done: false }),\n                _closeSteps: () => resolvePromise({ value: undefined, done: true }),\n                _errorSteps: e => rejectPromise(e)\n            };\n            ReadableStreamDefaultReaderRead(this, readRequest);\n            return promise;\n        }\n        /**\n         * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n         * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n         * from now on; otherwise, the reader will appear closed.\n         *\n         * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n         * the reader's {@link ReadableStreamDefaultReader.read | read()} method has not yet been settled. Attempting to\n         * do so will throw a `TypeError` and leave the reader locked to the stream.\n         */\n        releaseLock() {\n            if (!IsReadableStreamDefaultReader(this)) {\n                throw defaultReaderBrandCheckException('releaseLock');\n            }\n            if (this._ownerReadableStream === undefined) {\n                return;\n            }\n            if (this._readRequests.length > 0) {\n                throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n            }\n            ReadableStreamReaderGenericRelease(this);\n        }\n    }\n    Object.defineProperties(ReadableStreamDefaultReader.prototype, {\n        cancel: { enumerable: true },\n        read: { enumerable: true },\n        releaseLock: { enumerable: true },\n        closed: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamDefaultReader.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamDefaultReader',\n            configurable: true\n        });\n    }\n    // Abstract operations for the readers.\n    function IsReadableStreamDefaultReader(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readRequests')) {\n            return false;\n        }\n        return x instanceof ReadableStreamDefaultReader;\n    }\n    function ReadableStreamDefaultReaderRead(reader, readRequest) {\n        const stream = reader._ownerReadableStream;\n        stream._disturbed = true;\n        if (stream._state === 'closed') {\n            readRequest._closeSteps();\n        }\n        else if (stream._state === 'errored') {\n            readRequest._errorSteps(stream._storedError);\n        }\n        else {\n            stream._readableStreamController[PullSteps](readRequest);\n        }\n    }\n    // Helper functions for the ReadableStreamDefaultReader.\n    function defaultReaderBrandCheckException(name) {\n        return new TypeError(`ReadableStreamDefaultReader.prototype.${name} can only be used on a ReadableStreamDefaultReader`);\n    }\n\n    /// <reference lib=\"es2018.asynciterable\" />\n    /* eslint-disable @typescript-eslint/no-empty-function */\n    const AsyncIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf(async function* () { }).prototype);\n\n    /// <reference lib=\"es2018.asynciterable\" />\n    class ReadableStreamAsyncIteratorImpl {\n        constructor(reader, preventCancel) {\n            this._ongoingPromise = undefined;\n            this._isFinished = false;\n            this._reader = reader;\n            this._preventCancel = preventCancel;\n        }\n        next() {\n            const nextSteps = () => this._nextSteps();\n            this._ongoingPromise = this._ongoingPromise ?\n                transformPromiseWith(this._ongoingPromise, nextSteps, nextSteps) :\n                nextSteps();\n            return this._ongoingPromise;\n        }\n        return(value) {\n            const returnSteps = () => this._returnSteps(value);\n            return this._ongoingPromise ?\n                transformPromiseWith(this._ongoingPromise, returnSteps, returnSteps) :\n                returnSteps();\n        }\n        _nextSteps() {\n            if (this._isFinished) {\n                return Promise.resolve({ value: undefined, done: true });\n            }\n            const reader = this._reader;\n            if (reader._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('iterate'));\n            }\n            let resolvePromise;\n            let rejectPromise;\n            const promise = newPromise((resolve, reject) => {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            const readRequest = {\n                _chunkSteps: chunk => {\n                    this._ongoingPromise = undefined;\n                    // This needs to be delayed by one microtask, otherwise we stop pulling too early which breaks a test.\n                    // FIXME Is this a bug in the specification, or in the test?\n                    queueMicrotask(() => resolvePromise({ value: chunk, done: false }));\n                },\n                _closeSteps: () => {\n                    this._ongoingPromise = undefined;\n                    this._isFinished = true;\n                    ReadableStreamReaderGenericRelease(reader);\n                    resolvePromise({ value: undefined, done: true });\n                },\n                _errorSteps: reason => {\n                    this._ongoingPromise = undefined;\n                    this._isFinished = true;\n                    ReadableStreamReaderGenericRelease(reader);\n                    rejectPromise(reason);\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n            return promise;\n        }\n        _returnSteps(value) {\n            if (this._isFinished) {\n                return Promise.resolve({ value, done: true });\n            }\n            this._isFinished = true;\n            const reader = this._reader;\n            if (reader._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('finish iterating'));\n            }\n            if (!this._preventCancel) {\n                const result = ReadableStreamReaderGenericCancel(reader, value);\n                ReadableStreamReaderGenericRelease(reader);\n                return transformPromiseWith(result, () => ({ value, done: true }));\n            }\n            ReadableStreamReaderGenericRelease(reader);\n            return promiseResolvedWith({ value, done: true });\n        }\n    }\n    const ReadableStreamAsyncIteratorPrototype = {\n        next() {\n            if (!IsReadableStreamAsyncIterator(this)) {\n                return promiseRejectedWith(streamAsyncIteratorBrandCheckException('next'));\n            }\n            return this._asyncIteratorImpl.next();\n        },\n        return(value) {\n            if (!IsReadableStreamAsyncIterator(this)) {\n                return promiseRejectedWith(streamAsyncIteratorBrandCheckException('return'));\n            }\n            return this._asyncIteratorImpl.return(value);\n        }\n    };\n    if (AsyncIteratorPrototype !== undefined) {\n        Object.setPrototypeOf(ReadableStreamAsyncIteratorPrototype, AsyncIteratorPrototype);\n    }\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamAsyncIterator(stream, preventCancel) {\n        const reader = AcquireReadableStreamDefaultReader(stream);\n        const impl = new ReadableStreamAsyncIteratorImpl(reader, preventCancel);\n        const iterator = Object.create(ReadableStreamAsyncIteratorPrototype);\n        iterator._asyncIteratorImpl = impl;\n        return iterator;\n    }\n    function IsReadableStreamAsyncIterator(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_asyncIteratorImpl')) {\n            return false;\n        }\n        try {\n            // noinspection SuspiciousTypeOfGuard\n            return x._asyncIteratorImpl instanceof\n                ReadableStreamAsyncIteratorImpl;\n        }\n        catch (_a) {\n            return false;\n        }\n    }\n    // Helper functions for the ReadableStream.\n    function streamAsyncIteratorBrandCheckException(name) {\n        return new TypeError(`ReadableStreamAsyncIterator.${name} can only be used on a ReadableSteamAsyncIterator`);\n    }\n\n    /// <reference lib=\"es2015.core\" />\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isNaN#Polyfill\n    const NumberIsNaN = Number.isNaN || function (x) {\n        // eslint-disable-next-line no-self-compare\n        return x !== x;\n    };\n\n    function CreateArrayFromList(elements) {\n        // We use arrays to represent lists, so this is basically a no-op.\n        // Do a slice though just in case we happen to depend on the unique-ness.\n        return elements.slice();\n    }\n    function CopyDataBlockBytes(dest, destOffset, src, srcOffset, n) {\n        new Uint8Array(dest).set(new Uint8Array(src, srcOffset, n), destOffset);\n    }\n    // Not implemented correctly\n    function TransferArrayBuffer(O) {\n        return O;\n    }\n    // Not implemented correctly\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    function IsDetachedBuffer(O) {\n        return false;\n    }\n    function ArrayBufferSlice(buffer, begin, end) {\n        // ArrayBuffer.prototype.slice is not available on IE10\n        // https://www.caniuse.com/mdn-javascript_builtins_arraybuffer_slice\n        if (buffer.slice) {\n            return buffer.slice(begin, end);\n        }\n        const length = end - begin;\n        const slice = new ArrayBuffer(length);\n        CopyDataBlockBytes(slice, 0, buffer, begin, length);\n        return slice;\n    }\n\n    function IsNonNegativeNumber(v) {\n        if (typeof v !== 'number') {\n            return false;\n        }\n        if (NumberIsNaN(v)) {\n            return false;\n        }\n        if (v < 0) {\n            return false;\n        }\n        return true;\n    }\n    function CloneAsUint8Array(O) {\n        const buffer = ArrayBufferSlice(O.buffer, O.byteOffset, O.byteOffset + O.byteLength);\n        return new Uint8Array(buffer);\n    }\n\n    function DequeueValue(container) {\n        const pair = container._queue.shift();\n        container._queueTotalSize -= pair.size;\n        if (container._queueTotalSize < 0) {\n            container._queueTotalSize = 0;\n        }\n        return pair.value;\n    }\n    function EnqueueValueWithSize(container, value, size) {\n        if (!IsNonNegativeNumber(size) || size === Infinity) {\n            throw new RangeError('Size must be a finite, non-NaN, non-negative number.');\n        }\n        container._queue.push({ value, size });\n        container._queueTotalSize += size;\n    }\n    function PeekQueueValue(container) {\n        const pair = container._queue.peek();\n        return pair.value;\n    }\n    function ResetQueue(container) {\n        container._queue = new SimpleQueue();\n        container._queueTotalSize = 0;\n    }\n\n    /**\n     * A pull-into request in a {@link ReadableByteStreamController}.\n     *\n     * @public\n     */\n    class ReadableStreamBYOBRequest {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the view for writing in to, or `null` if the BYOB request has already been responded to.\n         */\n        get view() {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('view');\n            }\n            return this._view;\n        }\n        respond(bytesWritten) {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('respond');\n            }\n            assertRequiredArgument(bytesWritten, 1, 'respond');\n            bytesWritten = convertUnsignedLongLongWithEnforceRange(bytesWritten, 'First parameter');\n            if (this._associatedReadableByteStreamController === undefined) {\n                throw new TypeError('This BYOB request has been invalidated');\n            }\n            if (IsDetachedBuffer(this._view.buffer)) ;\n            ReadableByteStreamControllerRespond(this._associatedReadableByteStreamController, bytesWritten);\n        }\n        respondWithNewView(view) {\n            if (!IsReadableStreamBYOBRequest(this)) {\n                throw byobRequestBrandCheckException('respondWithNewView');\n            }\n            assertRequiredArgument(view, 1, 'respondWithNewView');\n            if (!ArrayBuffer.isView(view)) {\n                throw new TypeError('You can only respond with array buffer views');\n            }\n            if (this._associatedReadableByteStreamController === undefined) {\n                throw new TypeError('This BYOB request has been invalidated');\n            }\n            if (IsDetachedBuffer(view.buffer)) ;\n            ReadableByteStreamControllerRespondWithNewView(this._associatedReadableByteStreamController, view);\n        }\n    }\n    Object.defineProperties(ReadableStreamBYOBRequest.prototype, {\n        respond: { enumerable: true },\n        respondWithNewView: { enumerable: true },\n        view: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamBYOBRequest.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamBYOBRequest',\n            configurable: true\n        });\n    }\n    /**\n     * Allows control of a {@link ReadableStream | readable byte stream}'s state and internal queue.\n     *\n     * @public\n     */\n    class ReadableByteStreamController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the current BYOB pull request, or `null` if there isn't one.\n         */\n        get byobRequest() {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('byobRequest');\n            }\n            return ReadableByteStreamControllerGetBYOBRequest(this);\n        }\n        /**\n         * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n         * over-full. An underlying byte source ought to use this information to determine when and how to apply backpressure.\n         */\n        get desiredSize() {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('desiredSize');\n            }\n            return ReadableByteStreamControllerGetDesiredSize(this);\n        }\n        /**\n         * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n         * the stream, but once those are read, the stream will become closed.\n         */\n        close() {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('close');\n            }\n            if (this._closeRequested) {\n                throw new TypeError('The stream has already been closed; do not close it again!');\n            }\n            const state = this._controlledReadableByteStream._state;\n            if (state !== 'readable') {\n                throw new TypeError(`The stream (in ${state} state) is not in the readable state and cannot be closed`);\n            }\n            ReadableByteStreamControllerClose(this);\n        }\n        enqueue(chunk) {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('enqueue');\n            }\n            assertRequiredArgument(chunk, 1, 'enqueue');\n            if (!ArrayBuffer.isView(chunk)) {\n                throw new TypeError('chunk must be an array buffer view');\n            }\n            if (chunk.byteLength === 0) {\n                throw new TypeError('chunk must have non-zero byteLength');\n            }\n            if (chunk.buffer.byteLength === 0) {\n                throw new TypeError(`chunk's buffer must have non-zero byteLength`);\n            }\n            if (this._closeRequested) {\n                throw new TypeError('stream is closed or draining');\n            }\n            const state = this._controlledReadableByteStream._state;\n            if (state !== 'readable') {\n                throw new TypeError(`The stream (in ${state} state) is not in the readable state and cannot be enqueued to`);\n            }\n            ReadableByteStreamControllerEnqueue(this, chunk);\n        }\n        /**\n         * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n         */\n        error(e = undefined) {\n            if (!IsReadableByteStreamController(this)) {\n                throw byteStreamControllerBrandCheckException('error');\n            }\n            ReadableByteStreamControllerError(this, e);\n        }\n        /** @internal */\n        [CancelSteps](reason) {\n            ReadableByteStreamControllerClearPendingPullIntos(this);\n            ResetQueue(this);\n            const result = this._cancelAlgorithm(reason);\n            ReadableByteStreamControllerClearAlgorithms(this);\n            return result;\n        }\n        /** @internal */\n        [PullSteps](readRequest) {\n            const stream = this._controlledReadableByteStream;\n            if (this._queueTotalSize > 0) {\n                const entry = this._queue.shift();\n                this._queueTotalSize -= entry.byteLength;\n                ReadableByteStreamControllerHandleQueueDrain(this);\n                const view = new Uint8Array(entry.buffer, entry.byteOffset, entry.byteLength);\n                readRequest._chunkSteps(view);\n                return;\n            }\n            const autoAllocateChunkSize = this._autoAllocateChunkSize;\n            if (autoAllocateChunkSize !== undefined) {\n                let buffer;\n                try {\n                    buffer = new ArrayBuffer(autoAllocateChunkSize);\n                }\n                catch (bufferE) {\n                    readRequest._errorSteps(bufferE);\n                    return;\n                }\n                const pullIntoDescriptor = {\n                    buffer,\n                    bufferByteLength: autoAllocateChunkSize,\n                    byteOffset: 0,\n                    byteLength: autoAllocateChunkSize,\n                    bytesFilled: 0,\n                    elementSize: 1,\n                    viewConstructor: Uint8Array,\n                    readerType: 'default'\n                };\n                this._pendingPullIntos.push(pullIntoDescriptor);\n            }\n            ReadableStreamAddReadRequest(stream, readRequest);\n            ReadableByteStreamControllerCallPullIfNeeded(this);\n        }\n    }\n    Object.defineProperties(ReadableByteStreamController.prototype, {\n        close: { enumerable: true },\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        byobRequest: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableByteStreamController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableByteStreamController',\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableByteStreamController.\n    function IsReadableByteStreamController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableByteStream')) {\n            return false;\n        }\n        return x instanceof ReadableByteStreamController;\n    }\n    function IsReadableStreamBYOBRequest(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_associatedReadableByteStreamController')) {\n            return false;\n        }\n        return x instanceof ReadableStreamBYOBRequest;\n    }\n    function ReadableByteStreamControllerCallPullIfNeeded(controller) {\n        const shouldPull = ReadableByteStreamControllerShouldCallPull(controller);\n        if (!shouldPull) {\n            return;\n        }\n        if (controller._pulling) {\n            controller._pullAgain = true;\n            return;\n        }\n        controller._pulling = true;\n        // TODO: Test controller argument\n        const pullPromise = controller._pullAlgorithm();\n        uponPromise(pullPromise, () => {\n            controller._pulling = false;\n            if (controller._pullAgain) {\n                controller._pullAgain = false;\n                ReadableByteStreamControllerCallPullIfNeeded(controller);\n            }\n        }, e => {\n            ReadableByteStreamControllerError(controller, e);\n        });\n    }\n    function ReadableByteStreamControllerClearPendingPullIntos(controller) {\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        controller._pendingPullIntos = new SimpleQueue();\n    }\n    function ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor) {\n        let done = false;\n        if (stream._state === 'closed') {\n            done = true;\n        }\n        const filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n        if (pullIntoDescriptor.readerType === 'default') {\n            ReadableStreamFulfillReadRequest(stream, filledView, done);\n        }\n        else {\n            ReadableStreamFulfillReadIntoRequest(stream, filledView, done);\n        }\n    }\n    function ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor) {\n        const bytesFilled = pullIntoDescriptor.bytesFilled;\n        const elementSize = pullIntoDescriptor.elementSize;\n        return new pullIntoDescriptor.viewConstructor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, bytesFilled / elementSize);\n    }\n    function ReadableByteStreamControllerEnqueueChunkToQueue(controller, buffer, byteOffset, byteLength) {\n        controller._queue.push({ buffer, byteOffset, byteLength });\n        controller._queueTotalSize += byteLength;\n    }\n    function ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor) {\n        const elementSize = pullIntoDescriptor.elementSize;\n        const currentAlignedBytes = pullIntoDescriptor.bytesFilled - pullIntoDescriptor.bytesFilled % elementSize;\n        const maxBytesToCopy = Math.min(controller._queueTotalSize, pullIntoDescriptor.byteLength - pullIntoDescriptor.bytesFilled);\n        const maxBytesFilled = pullIntoDescriptor.bytesFilled + maxBytesToCopy;\n        const maxAlignedBytes = maxBytesFilled - maxBytesFilled % elementSize;\n        let totalBytesToCopyRemaining = maxBytesToCopy;\n        let ready = false;\n        if (maxAlignedBytes > currentAlignedBytes) {\n            totalBytesToCopyRemaining = maxAlignedBytes - pullIntoDescriptor.bytesFilled;\n            ready = true;\n        }\n        const queue = controller._queue;\n        while (totalBytesToCopyRemaining > 0) {\n            const headOfQueue = queue.peek();\n            const bytesToCopy = Math.min(totalBytesToCopyRemaining, headOfQueue.byteLength);\n            const destStart = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n            CopyDataBlockBytes(pullIntoDescriptor.buffer, destStart, headOfQueue.buffer, headOfQueue.byteOffset, bytesToCopy);\n            if (headOfQueue.byteLength === bytesToCopy) {\n                queue.shift();\n            }\n            else {\n                headOfQueue.byteOffset += bytesToCopy;\n                headOfQueue.byteLength -= bytesToCopy;\n            }\n            controller._queueTotalSize -= bytesToCopy;\n            ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesToCopy, pullIntoDescriptor);\n            totalBytesToCopyRemaining -= bytesToCopy;\n        }\n        return ready;\n    }\n    function ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, size, pullIntoDescriptor) {\n        pullIntoDescriptor.bytesFilled += size;\n    }\n    function ReadableByteStreamControllerHandleQueueDrain(controller) {\n        if (controller._queueTotalSize === 0 && controller._closeRequested) {\n            ReadableByteStreamControllerClearAlgorithms(controller);\n            ReadableStreamClose(controller._controlledReadableByteStream);\n        }\n        else {\n            ReadableByteStreamControllerCallPullIfNeeded(controller);\n        }\n    }\n    function ReadableByteStreamControllerInvalidateBYOBRequest(controller) {\n        if (controller._byobRequest === null) {\n            return;\n        }\n        controller._byobRequest._associatedReadableByteStreamController = undefined;\n        controller._byobRequest._view = null;\n        controller._byobRequest = null;\n    }\n    function ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller) {\n        while (controller._pendingPullIntos.length > 0) {\n            if (controller._queueTotalSize === 0) {\n                return;\n            }\n            const pullIntoDescriptor = controller._pendingPullIntos.peek();\n            if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n                ReadableByteStreamControllerShiftPendingPullInto(controller);\n                ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n            }\n        }\n    }\n    function ReadableByteStreamControllerPullInto(controller, view, readIntoRequest) {\n        const stream = controller._controlledReadableByteStream;\n        let elementSize = 1;\n        if (view.constructor !== DataView) {\n            elementSize = view.constructor.BYTES_PER_ELEMENT;\n        }\n        const ctor = view.constructor;\n        // try {\n        const buffer = TransferArrayBuffer(view.buffer);\n        // } catch (e) {\n        //   readIntoRequest._errorSteps(e);\n        //   return;\n        // }\n        const pullIntoDescriptor = {\n            buffer,\n            bufferByteLength: buffer.byteLength,\n            byteOffset: view.byteOffset,\n            byteLength: view.byteLength,\n            bytesFilled: 0,\n            elementSize,\n            viewConstructor: ctor,\n            readerType: 'byob'\n        };\n        if (controller._pendingPullIntos.length > 0) {\n            controller._pendingPullIntos.push(pullIntoDescriptor);\n            // No ReadableByteStreamControllerCallPullIfNeeded() call since:\n            // - No change happens on desiredSize\n            // - The source has already been notified of that there's at least 1 pending read(view)\n            ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n            return;\n        }\n        if (stream._state === 'closed') {\n            const emptyView = new ctor(pullIntoDescriptor.buffer, pullIntoDescriptor.byteOffset, 0);\n            readIntoRequest._closeSteps(emptyView);\n            return;\n        }\n        if (controller._queueTotalSize > 0) {\n            if (ReadableByteStreamControllerFillPullIntoDescriptorFromQueue(controller, pullIntoDescriptor)) {\n                const filledView = ReadableByteStreamControllerConvertPullIntoDescriptor(pullIntoDescriptor);\n                ReadableByteStreamControllerHandleQueueDrain(controller);\n                readIntoRequest._chunkSteps(filledView);\n                return;\n            }\n            if (controller._closeRequested) {\n                const e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n                ReadableByteStreamControllerError(controller, e);\n                readIntoRequest._errorSteps(e);\n                return;\n            }\n        }\n        controller._pendingPullIntos.push(pullIntoDescriptor);\n        ReadableStreamAddReadIntoRequest(stream, readIntoRequest);\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerRespondInClosedState(controller, firstDescriptor) {\n        const stream = controller._controlledReadableByteStream;\n        if (ReadableStreamHasBYOBReader(stream)) {\n            while (ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n                const pullIntoDescriptor = ReadableByteStreamControllerShiftPendingPullInto(controller);\n                ReadableByteStreamControllerCommitPullIntoDescriptor(stream, pullIntoDescriptor);\n            }\n        }\n    }\n    function ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, pullIntoDescriptor) {\n        ReadableByteStreamControllerFillHeadPullIntoDescriptor(controller, bytesWritten, pullIntoDescriptor);\n        if (pullIntoDescriptor.bytesFilled < pullIntoDescriptor.elementSize) {\n            return;\n        }\n        ReadableByteStreamControllerShiftPendingPullInto(controller);\n        const remainderSize = pullIntoDescriptor.bytesFilled % pullIntoDescriptor.elementSize;\n        if (remainderSize > 0) {\n            const end = pullIntoDescriptor.byteOffset + pullIntoDescriptor.bytesFilled;\n            const remainder = ArrayBufferSlice(pullIntoDescriptor.buffer, end - remainderSize, end);\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, remainder, 0, remainder.byteLength);\n        }\n        pullIntoDescriptor.bytesFilled -= remainderSize;\n        ReadableByteStreamControllerCommitPullIntoDescriptor(controller._controlledReadableByteStream, pullIntoDescriptor);\n        ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n    }\n    function ReadableByteStreamControllerRespondInternal(controller, bytesWritten) {\n        const firstDescriptor = controller._pendingPullIntos.peek();\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            ReadableByteStreamControllerRespondInClosedState(controller);\n        }\n        else {\n            ReadableByteStreamControllerRespondInReadableState(controller, bytesWritten, firstDescriptor);\n        }\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerShiftPendingPullInto(controller) {\n        const descriptor = controller._pendingPullIntos.shift();\n        return descriptor;\n    }\n    function ReadableByteStreamControllerShouldCallPull(controller) {\n        const stream = controller._controlledReadableByteStream;\n        if (stream._state !== 'readable') {\n            return false;\n        }\n        if (controller._closeRequested) {\n            return false;\n        }\n        if (!controller._started) {\n            return false;\n        }\n        if (ReadableStreamHasDefaultReader(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            return true;\n        }\n        if (ReadableStreamHasBYOBReader(stream) && ReadableStreamGetNumReadIntoRequests(stream) > 0) {\n            return true;\n        }\n        const desiredSize = ReadableByteStreamControllerGetDesiredSize(controller);\n        if (desiredSize > 0) {\n            return true;\n        }\n        return false;\n    }\n    function ReadableByteStreamControllerClearAlgorithms(controller) {\n        controller._pullAlgorithm = undefined;\n        controller._cancelAlgorithm = undefined;\n    }\n    // A client of ReadableByteStreamController may use these functions directly to bypass state check.\n    function ReadableByteStreamControllerClose(controller) {\n        const stream = controller._controlledReadableByteStream;\n        if (controller._closeRequested || stream._state !== 'readable') {\n            return;\n        }\n        if (controller._queueTotalSize > 0) {\n            controller._closeRequested = true;\n            return;\n        }\n        if (controller._pendingPullIntos.length > 0) {\n            const firstPendingPullInto = controller._pendingPullIntos.peek();\n            if (firstPendingPullInto.bytesFilled > 0) {\n                const e = new TypeError('Insufficient bytes to fill elements in the given buffer');\n                ReadableByteStreamControllerError(controller, e);\n                throw e;\n            }\n        }\n        ReadableByteStreamControllerClearAlgorithms(controller);\n        ReadableStreamClose(stream);\n    }\n    function ReadableByteStreamControllerEnqueue(controller, chunk) {\n        const stream = controller._controlledReadableByteStream;\n        if (controller._closeRequested || stream._state !== 'readable') {\n            return;\n        }\n        const buffer = chunk.buffer;\n        const byteOffset = chunk.byteOffset;\n        const byteLength = chunk.byteLength;\n        const transferredBuffer = TransferArrayBuffer(buffer);\n        if (controller._pendingPullIntos.length > 0) {\n            const firstPendingPullInto = controller._pendingPullIntos.peek();\n            if (IsDetachedBuffer(firstPendingPullInto.buffer)) ;\n            firstPendingPullInto.buffer = TransferArrayBuffer(firstPendingPullInto.buffer);\n        }\n        ReadableByteStreamControllerInvalidateBYOBRequest(controller);\n        if (ReadableStreamHasDefaultReader(stream)) {\n            if (ReadableStreamGetNumReadRequests(stream) === 0) {\n                ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n            }\n            else {\n                if (controller._pendingPullIntos.length > 0) {\n                    ReadableByteStreamControllerShiftPendingPullInto(controller);\n                }\n                const transferredView = new Uint8Array(transferredBuffer, byteOffset, byteLength);\n                ReadableStreamFulfillReadRequest(stream, transferredView, false);\n            }\n        }\n        else if (ReadableStreamHasBYOBReader(stream)) {\n            // TODO: Ideally in this branch detaching should happen only if the buffer is not consumed fully.\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n            ReadableByteStreamControllerProcessPullIntoDescriptorsUsingQueue(controller);\n        }\n        else {\n            ReadableByteStreamControllerEnqueueChunkToQueue(controller, transferredBuffer, byteOffset, byteLength);\n        }\n        ReadableByteStreamControllerCallPullIfNeeded(controller);\n    }\n    function ReadableByteStreamControllerError(controller, e) {\n        const stream = controller._controlledReadableByteStream;\n        if (stream._state !== 'readable') {\n            return;\n        }\n        ReadableByteStreamControllerClearPendingPullIntos(controller);\n        ResetQueue(controller);\n        ReadableByteStreamControllerClearAlgorithms(controller);\n        ReadableStreamError(stream, e);\n    }\n    function ReadableByteStreamControllerGetBYOBRequest(controller) {\n        if (controller._byobRequest === null && controller._pendingPullIntos.length > 0) {\n            const firstDescriptor = controller._pendingPullIntos.peek();\n            const view = new Uint8Array(firstDescriptor.buffer, firstDescriptor.byteOffset + firstDescriptor.bytesFilled, firstDescriptor.byteLength - firstDescriptor.bytesFilled);\n            const byobRequest = Object.create(ReadableStreamBYOBRequest.prototype);\n            SetUpReadableStreamBYOBRequest(byobRequest, controller, view);\n            controller._byobRequest = byobRequest;\n        }\n        return controller._byobRequest;\n    }\n    function ReadableByteStreamControllerGetDesiredSize(controller) {\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'errored') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    function ReadableByteStreamControllerRespond(controller, bytesWritten) {\n        const firstDescriptor = controller._pendingPullIntos.peek();\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            if (bytesWritten !== 0) {\n                throw new TypeError('bytesWritten must be 0 when calling respond() on a closed stream');\n            }\n        }\n        else {\n            if (bytesWritten === 0) {\n                throw new TypeError('bytesWritten must be greater than 0 when calling respond() on a readable stream');\n            }\n            if (firstDescriptor.bytesFilled + bytesWritten > firstDescriptor.byteLength) {\n                throw new RangeError('bytesWritten out of range');\n            }\n        }\n        firstDescriptor.buffer = TransferArrayBuffer(firstDescriptor.buffer);\n        ReadableByteStreamControllerRespondInternal(controller, bytesWritten);\n    }\n    function ReadableByteStreamControllerRespondWithNewView(controller, view) {\n        const firstDescriptor = controller._pendingPullIntos.peek();\n        const state = controller._controlledReadableByteStream._state;\n        if (state === 'closed') {\n            if (view.byteLength !== 0) {\n                throw new TypeError('The view\\'s length must be 0 when calling respondWithNewView() on a closed stream');\n            }\n        }\n        else {\n            if (view.byteLength === 0) {\n                throw new TypeError('The view\\'s length must be greater than 0 when calling respondWithNewView() on a readable stream');\n            }\n        }\n        if (firstDescriptor.byteOffset + firstDescriptor.bytesFilled !== view.byteOffset) {\n            throw new RangeError('The region specified by view does not match byobRequest');\n        }\n        if (firstDescriptor.bufferByteLength !== view.buffer.byteLength) {\n            throw new RangeError('The buffer of view has different capacity than byobRequest');\n        }\n        if (firstDescriptor.bytesFilled + view.byteLength > firstDescriptor.byteLength) {\n            throw new RangeError('The region specified by view is larger than byobRequest');\n        }\n        const viewByteLength = view.byteLength;\n        firstDescriptor.buffer = TransferArrayBuffer(view.buffer);\n        ReadableByteStreamControllerRespondInternal(controller, viewByteLength);\n    }\n    function SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize) {\n        controller._controlledReadableByteStream = stream;\n        controller._pullAgain = false;\n        controller._pulling = false;\n        controller._byobRequest = null;\n        // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n        controller._queue = controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._closeRequested = false;\n        controller._started = false;\n        controller._strategyHWM = highWaterMark;\n        controller._pullAlgorithm = pullAlgorithm;\n        controller._cancelAlgorithm = cancelAlgorithm;\n        controller._autoAllocateChunkSize = autoAllocateChunkSize;\n        controller._pendingPullIntos = new SimpleQueue();\n        stream._readableStreamController = controller;\n        const startResult = startAlgorithm();\n        uponPromise(promiseResolvedWith(startResult), () => {\n            controller._started = true;\n            ReadableByteStreamControllerCallPullIfNeeded(controller);\n        }, r => {\n            ReadableByteStreamControllerError(controller, r);\n        });\n    }\n    function SetUpReadableByteStreamControllerFromUnderlyingSource(stream, underlyingByteSource, highWaterMark) {\n        const controller = Object.create(ReadableByteStreamController.prototype);\n        let startAlgorithm = () => undefined;\n        let pullAlgorithm = () => promiseResolvedWith(undefined);\n        let cancelAlgorithm = () => promiseResolvedWith(undefined);\n        if (underlyingByteSource.start !== undefined) {\n            startAlgorithm = () => underlyingByteSource.start(controller);\n        }\n        if (underlyingByteSource.pull !== undefined) {\n            pullAlgorithm = () => underlyingByteSource.pull(controller);\n        }\n        if (underlyingByteSource.cancel !== undefined) {\n            cancelAlgorithm = reason => underlyingByteSource.cancel(reason);\n        }\n        const autoAllocateChunkSize = underlyingByteSource.autoAllocateChunkSize;\n        if (autoAllocateChunkSize === 0) {\n            throw new TypeError('autoAllocateChunkSize must be greater than 0');\n        }\n        SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, autoAllocateChunkSize);\n    }\n    function SetUpReadableStreamBYOBRequest(request, controller, view) {\n        request._associatedReadableByteStreamController = controller;\n        request._view = view;\n    }\n    // Helper functions for the ReadableStreamBYOBRequest.\n    function byobRequestBrandCheckException(name) {\n        return new TypeError(`ReadableStreamBYOBRequest.prototype.${name} can only be used on a ReadableStreamBYOBRequest`);\n    }\n    // Helper functions for the ReadableByteStreamController.\n    function byteStreamControllerBrandCheckException(name) {\n        return new TypeError(`ReadableByteStreamController.prototype.${name} can only be used on a ReadableByteStreamController`);\n    }\n\n    // Abstract operations for the ReadableStream.\n    function AcquireReadableStreamBYOBReader(stream) {\n        return new ReadableStreamBYOBReader(stream);\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamAddReadIntoRequest(stream, readIntoRequest) {\n        stream._reader._readIntoRequests.push(readIntoRequest);\n    }\n    function ReadableStreamFulfillReadIntoRequest(stream, chunk, done) {\n        const reader = stream._reader;\n        const readIntoRequest = reader._readIntoRequests.shift();\n        if (done) {\n            readIntoRequest._closeSteps(chunk);\n        }\n        else {\n            readIntoRequest._chunkSteps(chunk);\n        }\n    }\n    function ReadableStreamGetNumReadIntoRequests(stream) {\n        return stream._reader._readIntoRequests.length;\n    }\n    function ReadableStreamHasBYOBReader(stream) {\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return false;\n        }\n        if (!IsReadableStreamBYOBReader(reader)) {\n            return false;\n        }\n        return true;\n    }\n    /**\n     * A BYOB reader vended by a {@link ReadableStream}.\n     *\n     * @public\n     */\n    class ReadableStreamBYOBReader {\n        constructor(stream) {\n            assertRequiredArgument(stream, 1, 'ReadableStreamBYOBReader');\n            assertReadableStream(stream, 'First parameter');\n            if (IsReadableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive reading by another reader');\n            }\n            if (!IsReadableByteStreamController(stream._readableStreamController)) {\n                throw new TypeError('Cannot construct a ReadableStreamBYOBReader for a stream not constructed with a byte ' +\n                    'source');\n            }\n            ReadableStreamReaderGenericInitialize(this, stream);\n            this._readIntoRequests = new SimpleQueue();\n        }\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n         * the reader's lock is released before the stream finishes closing.\n         */\n        get closed() {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        }\n        /**\n         * If the reader is active, behaves the same as {@link ReadableStream.cancel | stream.cancel(reason)}.\n         */\n        cancel(reason = undefined) {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('cancel'));\n            }\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('cancel'));\n            }\n            return ReadableStreamReaderGenericCancel(this, reason);\n        }\n        /**\n         * Attempts to reads bytes into view, and returns a promise resolved with the result.\n         *\n         * If reading a chunk causes the queue to become empty, more data will be pulled from the underlying source.\n         */\n        read(view) {\n            if (!IsReadableStreamBYOBReader(this)) {\n                return promiseRejectedWith(byobReaderBrandCheckException('read'));\n            }\n            if (!ArrayBuffer.isView(view)) {\n                return promiseRejectedWith(new TypeError('view must be an array buffer view'));\n            }\n            if (view.byteLength === 0) {\n                return promiseRejectedWith(new TypeError('view must have non-zero byteLength'));\n            }\n            if (view.buffer.byteLength === 0) {\n                return promiseRejectedWith(new TypeError(`view's buffer must have non-zero byteLength`));\n            }\n            if (IsDetachedBuffer(view.buffer)) ;\n            if (this._ownerReadableStream === undefined) {\n                return promiseRejectedWith(readerLockException('read from'));\n            }\n            let resolvePromise;\n            let rejectPromise;\n            const promise = newPromise((resolve, reject) => {\n                resolvePromise = resolve;\n                rejectPromise = reject;\n            });\n            const readIntoRequest = {\n                _chunkSteps: chunk => resolvePromise({ value: chunk, done: false }),\n                _closeSteps: chunk => resolvePromise({ value: chunk, done: true }),\n                _errorSteps: e => rejectPromise(e)\n            };\n            ReadableStreamBYOBReaderRead(this, view, readIntoRequest);\n            return promise;\n        }\n        /**\n         * Releases the reader's lock on the corresponding stream. After the lock is released, the reader is no longer active.\n         * If the associated stream is errored when the lock is released, the reader will appear errored in the same way\n         * from now on; otherwise, the reader will appear closed.\n         *\n         * A reader's lock cannot be released while it still has a pending read request, i.e., if a promise returned by\n         * the reader's {@link ReadableStreamBYOBReader.read | read()} method has not yet been settled. Attempting to\n         * do so will throw a `TypeError` and leave the reader locked to the stream.\n         */\n        releaseLock() {\n            if (!IsReadableStreamBYOBReader(this)) {\n                throw byobReaderBrandCheckException('releaseLock');\n            }\n            if (this._ownerReadableStream === undefined) {\n                return;\n            }\n            if (this._readIntoRequests.length > 0) {\n                throw new TypeError('Tried to release a reader lock when that reader has pending read() calls un-settled');\n            }\n            ReadableStreamReaderGenericRelease(this);\n        }\n    }\n    Object.defineProperties(ReadableStreamBYOBReader.prototype, {\n        cancel: { enumerable: true },\n        read: { enumerable: true },\n        releaseLock: { enumerable: true },\n        closed: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamBYOBReader.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamBYOBReader',\n            configurable: true\n        });\n    }\n    // Abstract operations for the readers.\n    function IsReadableStreamBYOBReader(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readIntoRequests')) {\n            return false;\n        }\n        return x instanceof ReadableStreamBYOBReader;\n    }\n    function ReadableStreamBYOBReaderRead(reader, view, readIntoRequest) {\n        const stream = reader._ownerReadableStream;\n        stream._disturbed = true;\n        if (stream._state === 'errored') {\n            readIntoRequest._errorSteps(stream._storedError);\n        }\n        else {\n            ReadableByteStreamControllerPullInto(stream._readableStreamController, view, readIntoRequest);\n        }\n    }\n    // Helper functions for the ReadableStreamBYOBReader.\n    function byobReaderBrandCheckException(name) {\n        return new TypeError(`ReadableStreamBYOBReader.prototype.${name} can only be used on a ReadableStreamBYOBReader`);\n    }\n\n    function ExtractHighWaterMark(strategy, defaultHWM) {\n        const { highWaterMark } = strategy;\n        if (highWaterMark === undefined) {\n            return defaultHWM;\n        }\n        if (NumberIsNaN(highWaterMark) || highWaterMark < 0) {\n            throw new RangeError('Invalid highWaterMark');\n        }\n        return highWaterMark;\n    }\n    function ExtractSizeAlgorithm(strategy) {\n        const { size } = strategy;\n        if (!size) {\n            return () => 1;\n        }\n        return size;\n    }\n\n    function convertQueuingStrategy(init, context) {\n        assertDictionary(init, context);\n        const highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n        const size = init === null || init === void 0 ? void 0 : init.size;\n        return {\n            highWaterMark: highWaterMark === undefined ? undefined : convertUnrestrictedDouble(highWaterMark),\n            size: size === undefined ? undefined : convertQueuingStrategySize(size, `${context} has member 'size' that`)\n        };\n    }\n    function convertQueuingStrategySize(fn, context) {\n        assertFunction(fn, context);\n        return chunk => convertUnrestrictedDouble(fn(chunk));\n    }\n\n    function convertUnderlyingSink(original, context) {\n        assertDictionary(original, context);\n        const abort = original === null || original === void 0 ? void 0 : original.abort;\n        const close = original === null || original === void 0 ? void 0 : original.close;\n        const start = original === null || original === void 0 ? void 0 : original.start;\n        const type = original === null || original === void 0 ? void 0 : original.type;\n        const write = original === null || original === void 0 ? void 0 : original.write;\n        return {\n            abort: abort === undefined ?\n                undefined :\n                convertUnderlyingSinkAbortCallback(abort, original, `${context} has member 'abort' that`),\n            close: close === undefined ?\n                undefined :\n                convertUnderlyingSinkCloseCallback(close, original, `${context} has member 'close' that`),\n            start: start === undefined ?\n                undefined :\n                convertUnderlyingSinkStartCallback(start, original, `${context} has member 'start' that`),\n            write: write === undefined ?\n                undefined :\n                convertUnderlyingSinkWriteCallback(write, original, `${context} has member 'write' that`),\n            type\n        };\n    }\n    function convertUnderlyingSinkAbortCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (reason) => promiseCall(fn, original, [reason]);\n    }\n    function convertUnderlyingSinkCloseCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return () => promiseCall(fn, original, []);\n    }\n    function convertUnderlyingSinkStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => reflectCall(fn, original, [controller]);\n    }\n    function convertUnderlyingSinkWriteCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (chunk, controller) => promiseCall(fn, original, [chunk, controller]);\n    }\n\n    function assertWritableStream(x, context) {\n        if (!IsWritableStream(x)) {\n            throw new TypeError(`${context} is not a WritableStream.`);\n        }\n    }\n\n    function isAbortSignal(value) {\n        if (typeof value !== 'object' || value === null) {\n            return false;\n        }\n        try {\n            return typeof value.aborted === 'boolean';\n        }\n        catch (_a) {\n            // AbortSignal.prototype.aborted throws if its brand check fails\n            return false;\n        }\n    }\n    const supportsAbortController = typeof AbortController === 'function';\n    /**\n     * Construct a new AbortController, if supported by the platform.\n     *\n     * @internal\n     */\n    function createAbortController() {\n        if (supportsAbortController) {\n            return new AbortController();\n        }\n        return undefined;\n    }\n\n    /**\n     * A writable stream represents a destination for data, into which you can write.\n     *\n     * @public\n     */\n    class WritableStream {\n        constructor(rawUnderlyingSink = {}, rawStrategy = {}) {\n            if (rawUnderlyingSink === undefined) {\n                rawUnderlyingSink = null;\n            }\n            else {\n                assertObject(rawUnderlyingSink, 'First parameter');\n            }\n            const strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n            const underlyingSink = convertUnderlyingSink(rawUnderlyingSink, 'First parameter');\n            InitializeWritableStream(this);\n            const type = underlyingSink.type;\n            if (type !== undefined) {\n                throw new RangeError('Invalid type is specified');\n            }\n            const sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n            const highWaterMark = ExtractHighWaterMark(strategy, 1);\n            SetUpWritableStreamDefaultControllerFromUnderlyingSink(this, underlyingSink, highWaterMark, sizeAlgorithm);\n        }\n        /**\n         * Returns whether or not the writable stream is locked to a writer.\n         */\n        get locked() {\n            if (!IsWritableStream(this)) {\n                throw streamBrandCheckException$2('locked');\n            }\n            return IsWritableStreamLocked(this);\n        }\n        /**\n         * Aborts the stream, signaling that the producer can no longer successfully write to the stream and it is to be\n         * immediately moved to an errored state, with any queued-up writes discarded. This will also execute any abort\n         * mechanism of the underlying sink.\n         *\n         * The returned promise will fulfill if the stream shuts down successfully, or reject if the underlying sink signaled\n         * that there was an error doing so. Additionally, it will reject with a `TypeError` (without attempting to cancel\n         * the stream) if the stream is currently locked.\n         */\n        abort(reason = undefined) {\n            if (!IsWritableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$2('abort'));\n            }\n            if (IsWritableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot abort a stream that already has a writer'));\n            }\n            return WritableStreamAbort(this, reason);\n        }\n        /**\n         * Closes the stream. The underlying sink will finish processing any previously-written chunks, before invoking its\n         * close behavior. During this time any further attempts to write will fail (without erroring the stream).\n         *\n         * The method returns a promise that will fulfill if all remaining chunks are successfully written and the stream\n         * successfully closes, or rejects if an error is encountered during this process. Additionally, it will reject with\n         * a `TypeError` (without attempting to cancel the stream) if the stream is currently locked.\n         */\n        close() {\n            if (!IsWritableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$2('close'));\n            }\n            if (IsWritableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot close a stream that already has a writer'));\n            }\n            if (WritableStreamCloseQueuedOrInFlight(this)) {\n                return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n            }\n            return WritableStreamClose(this);\n        }\n        /**\n         * Creates a {@link WritableStreamDefaultWriter | writer} and locks the stream to the new writer. While the stream\n         * is locked, no other writer can be acquired until this one is released.\n         *\n         * This functionality is especially useful for creating abstractions that desire the ability to write to a stream\n         * without interruption or interleaving. By getting a writer for the stream, you can ensure nobody else can write at\n         * the same time, which would cause the resulting written data to be unpredictable and probably useless.\n         */\n        getWriter() {\n            if (!IsWritableStream(this)) {\n                throw streamBrandCheckException$2('getWriter');\n            }\n            return AcquireWritableStreamDefaultWriter(this);\n        }\n    }\n    Object.defineProperties(WritableStream.prototype, {\n        abort: { enumerable: true },\n        close: { enumerable: true },\n        getWriter: { enumerable: true },\n        locked: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStream',\n            configurable: true\n        });\n    }\n    // Abstract operations for the WritableStream.\n    function AcquireWritableStreamDefaultWriter(stream) {\n        return new WritableStreamDefaultWriter(stream);\n    }\n    // Throws if and only if startAlgorithm throws.\n    function CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark = 1, sizeAlgorithm = () => 1) {\n        const stream = Object.create(WritableStream.prototype);\n        InitializeWritableStream(stream);\n        const controller = Object.create(WritableStreamDefaultController.prototype);\n        SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n        return stream;\n    }\n    function InitializeWritableStream(stream) {\n        stream._state = 'writable';\n        // The error that will be reported by new method calls once the state becomes errored. Only set when [[state]] is\n        // 'erroring' or 'errored'. May be set to an undefined value.\n        stream._storedError = undefined;\n        stream._writer = undefined;\n        // Initialize to undefined first because the constructor of the controller checks this\n        // variable to validate the caller.\n        stream._writableStreamController = undefined;\n        // This queue is placed here instead of the writer class in order to allow for passing a writer to the next data\n        // producer without waiting for the queued writes to finish.\n        stream._writeRequests = new SimpleQueue();\n        // Write requests are removed from _writeRequests when write() is called on the underlying sink. This prevents\n        // them from being erroneously rejected on error. If a write() call is in-flight, the request is stored here.\n        stream._inFlightWriteRequest = undefined;\n        // The promise that was returned from writer.close(). Stored here because it may be fulfilled after the writer\n        // has been detached.\n        stream._closeRequest = undefined;\n        // Close request is removed from _closeRequest when close() is called on the underlying sink. This prevents it\n        // from being erroneously rejected on error. If a close() call is in-flight, the request is stored here.\n        stream._inFlightCloseRequest = undefined;\n        // The promise that was returned from writer.abort(). This may also be fulfilled after the writer has detached.\n        stream._pendingAbortRequest = undefined;\n        // The backpressure signal set by the controller.\n        stream._backpressure = false;\n    }\n    function IsWritableStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_writableStreamController')) {\n            return false;\n        }\n        return x instanceof WritableStream;\n    }\n    function IsWritableStreamLocked(stream) {\n        if (stream._writer === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamAbort(stream, reason) {\n        var _a;\n        if (stream._state === 'closed' || stream._state === 'errored') {\n            return promiseResolvedWith(undefined);\n        }\n        stream._writableStreamController._abortReason = reason;\n        (_a = stream._writableStreamController._abortController) === null || _a === void 0 ? void 0 : _a.abort();\n        // TypeScript narrows the type of `stream._state` down to 'writable' | 'erroring',\n        // but it doesn't know that signaling abort runs author code that might have changed the state.\n        // Widen the type again by casting to WritableStreamState.\n        const state = stream._state;\n        if (state === 'closed' || state === 'errored') {\n            return promiseResolvedWith(undefined);\n        }\n        if (stream._pendingAbortRequest !== undefined) {\n            return stream._pendingAbortRequest._promise;\n        }\n        let wasAlreadyErroring = false;\n        if (state === 'erroring') {\n            wasAlreadyErroring = true;\n            // reason will not be used, so don't keep a reference to it.\n            reason = undefined;\n        }\n        const promise = newPromise((resolve, reject) => {\n            stream._pendingAbortRequest = {\n                _promise: undefined,\n                _resolve: resolve,\n                _reject: reject,\n                _reason: reason,\n                _wasAlreadyErroring: wasAlreadyErroring\n            };\n        });\n        stream._pendingAbortRequest._promise = promise;\n        if (!wasAlreadyErroring) {\n            WritableStreamStartErroring(stream, reason);\n        }\n        return promise;\n    }\n    function WritableStreamClose(stream) {\n        const state = stream._state;\n        if (state === 'closed' || state === 'errored') {\n            return promiseRejectedWith(new TypeError(`The stream (in ${state} state) is not in the writable state and cannot be closed`));\n        }\n        const promise = newPromise((resolve, reject) => {\n            const closeRequest = {\n                _resolve: resolve,\n                _reject: reject\n            };\n            stream._closeRequest = closeRequest;\n        });\n        const writer = stream._writer;\n        if (writer !== undefined && stream._backpressure && state === 'writable') {\n            defaultWriterReadyPromiseResolve(writer);\n        }\n        WritableStreamDefaultControllerClose(stream._writableStreamController);\n        return promise;\n    }\n    // WritableStream API exposed for controllers.\n    function WritableStreamAddWriteRequest(stream) {\n        const promise = newPromise((resolve, reject) => {\n            const writeRequest = {\n                _resolve: resolve,\n                _reject: reject\n            };\n            stream._writeRequests.push(writeRequest);\n        });\n        return promise;\n    }\n    function WritableStreamDealWithRejection(stream, error) {\n        const state = stream._state;\n        if (state === 'writable') {\n            WritableStreamStartErroring(stream, error);\n            return;\n        }\n        WritableStreamFinishErroring(stream);\n    }\n    function WritableStreamStartErroring(stream, reason) {\n        const controller = stream._writableStreamController;\n        stream._state = 'erroring';\n        stream._storedError = reason;\n        const writer = stream._writer;\n        if (writer !== undefined) {\n            WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, reason);\n        }\n        if (!WritableStreamHasOperationMarkedInFlight(stream) && controller._started) {\n            WritableStreamFinishErroring(stream);\n        }\n    }\n    function WritableStreamFinishErroring(stream) {\n        stream._state = 'errored';\n        stream._writableStreamController[ErrorSteps]();\n        const storedError = stream._storedError;\n        stream._writeRequests.forEach(writeRequest => {\n            writeRequest._reject(storedError);\n        });\n        stream._writeRequests = new SimpleQueue();\n        if (stream._pendingAbortRequest === undefined) {\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n            return;\n        }\n        const abortRequest = stream._pendingAbortRequest;\n        stream._pendingAbortRequest = undefined;\n        if (abortRequest._wasAlreadyErroring) {\n            abortRequest._reject(storedError);\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n            return;\n        }\n        const promise = stream._writableStreamController[AbortSteps](abortRequest._reason);\n        uponPromise(promise, () => {\n            abortRequest._resolve();\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        }, (reason) => {\n            abortRequest._reject(reason);\n            WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream);\n        });\n    }\n    function WritableStreamFinishInFlightWrite(stream) {\n        stream._inFlightWriteRequest._resolve(undefined);\n        stream._inFlightWriteRequest = undefined;\n    }\n    function WritableStreamFinishInFlightWriteWithError(stream, error) {\n        stream._inFlightWriteRequest._reject(error);\n        stream._inFlightWriteRequest = undefined;\n        WritableStreamDealWithRejection(stream, error);\n    }\n    function WritableStreamFinishInFlightClose(stream) {\n        stream._inFlightCloseRequest._resolve(undefined);\n        stream._inFlightCloseRequest = undefined;\n        const state = stream._state;\n        if (state === 'erroring') {\n            // The error was too late to do anything, so it is ignored.\n            stream._storedError = undefined;\n            if (stream._pendingAbortRequest !== undefined) {\n                stream._pendingAbortRequest._resolve();\n                stream._pendingAbortRequest = undefined;\n            }\n        }\n        stream._state = 'closed';\n        const writer = stream._writer;\n        if (writer !== undefined) {\n            defaultWriterClosedPromiseResolve(writer);\n        }\n    }\n    function WritableStreamFinishInFlightCloseWithError(stream, error) {\n        stream._inFlightCloseRequest._reject(error);\n        stream._inFlightCloseRequest = undefined;\n        // Never execute sink abort() after sink close().\n        if (stream._pendingAbortRequest !== undefined) {\n            stream._pendingAbortRequest._reject(error);\n            stream._pendingAbortRequest = undefined;\n        }\n        WritableStreamDealWithRejection(stream, error);\n    }\n    // TODO(ricea): Fix alphabetical order.\n    function WritableStreamCloseQueuedOrInFlight(stream) {\n        if (stream._closeRequest === undefined && stream._inFlightCloseRequest === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamHasOperationMarkedInFlight(stream) {\n        if (stream._inFlightWriteRequest === undefined && stream._inFlightCloseRequest === undefined) {\n            return false;\n        }\n        return true;\n    }\n    function WritableStreamMarkCloseRequestInFlight(stream) {\n        stream._inFlightCloseRequest = stream._closeRequest;\n        stream._closeRequest = undefined;\n    }\n    function WritableStreamMarkFirstWriteRequestInFlight(stream) {\n        stream._inFlightWriteRequest = stream._writeRequests.shift();\n    }\n    function WritableStreamRejectCloseAndClosedPromiseIfNeeded(stream) {\n        if (stream._closeRequest !== undefined) {\n            stream._closeRequest._reject(stream._storedError);\n            stream._closeRequest = undefined;\n        }\n        const writer = stream._writer;\n        if (writer !== undefined) {\n            defaultWriterClosedPromiseReject(writer, stream._storedError);\n        }\n    }\n    function WritableStreamUpdateBackpressure(stream, backpressure) {\n        const writer = stream._writer;\n        if (writer !== undefined && backpressure !== stream._backpressure) {\n            if (backpressure) {\n                defaultWriterReadyPromiseReset(writer);\n            }\n            else {\n                defaultWriterReadyPromiseResolve(writer);\n            }\n        }\n        stream._backpressure = backpressure;\n    }\n    /**\n     * A default writer vended by a {@link WritableStream}.\n     *\n     * @public\n     */\n    class WritableStreamDefaultWriter {\n        constructor(stream) {\n            assertRequiredArgument(stream, 1, 'WritableStreamDefaultWriter');\n            assertWritableStream(stream, 'First parameter');\n            if (IsWritableStreamLocked(stream)) {\n                throw new TypeError('This stream has already been locked for exclusive writing by another writer');\n            }\n            this._ownerWritableStream = stream;\n            stream._writer = this;\n            const state = stream._state;\n            if (state === 'writable') {\n                if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._backpressure) {\n                    defaultWriterReadyPromiseInitialize(this);\n                }\n                else {\n                    defaultWriterReadyPromiseInitializeAsResolved(this);\n                }\n                defaultWriterClosedPromiseInitialize(this);\n            }\n            else if (state === 'erroring') {\n                defaultWriterReadyPromiseInitializeAsRejected(this, stream._storedError);\n                defaultWriterClosedPromiseInitialize(this);\n            }\n            else if (state === 'closed') {\n                defaultWriterReadyPromiseInitializeAsResolved(this);\n                defaultWriterClosedPromiseInitializeAsResolved(this);\n            }\n            else {\n                const storedError = stream._storedError;\n                defaultWriterReadyPromiseInitializeAsRejected(this, storedError);\n                defaultWriterClosedPromiseInitializeAsRejected(this, storedError);\n            }\n        }\n        /**\n         * Returns a promise that will be fulfilled when the stream becomes closed, or rejected if the stream ever errors or\n         * the writerâs lock is released before the stream finishes closing.\n         */\n        get closed() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('closed'));\n            }\n            return this._closedPromise;\n        }\n        /**\n         * Returns the desired size to fill the streamâs internal queue. It can be negative, if the queue is over-full.\n         * A producer can use this information to determine the right amount of data to write.\n         *\n         * It will be `null` if the stream cannot be successfully written to (due to either being errored, or having an abort\n         * queued up). It will return zero if the stream is closed. And the getter will throw an exception if invoked when\n         * the writerâs lock is released.\n         */\n        get desiredSize() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                throw defaultWriterBrandCheckException('desiredSize');\n            }\n            if (this._ownerWritableStream === undefined) {\n                throw defaultWriterLockException('desiredSize');\n            }\n            return WritableStreamDefaultWriterGetDesiredSize(this);\n        }\n        /**\n         * Returns a promise that will be fulfilled when the desired size to fill the streamâs internal queue transitions\n         * from non-positive to positive, signaling that it is no longer applying backpressure. Once the desired size dips\n         * back to zero or below, the getter will return a new promise that stays pending until the next transition.\n         *\n         * If the stream becomes errored or aborted, or the writerâs lock is released, the returned promise will become\n         * rejected.\n         */\n        get ready() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('ready'));\n            }\n            return this._readyPromise;\n        }\n        /**\n         * If the reader is active, behaves the same as {@link WritableStream.abort | stream.abort(reason)}.\n         */\n        abort(reason = undefined) {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('abort'));\n            }\n            if (this._ownerWritableStream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('abort'));\n            }\n            return WritableStreamDefaultWriterAbort(this, reason);\n        }\n        /**\n         * If the reader is active, behaves the same as {@link WritableStream.close | stream.close()}.\n         */\n        close() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('close'));\n            }\n            const stream = this._ownerWritableStream;\n            if (stream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('close'));\n            }\n            if (WritableStreamCloseQueuedOrInFlight(stream)) {\n                return promiseRejectedWith(new TypeError('Cannot close an already-closing stream'));\n            }\n            return WritableStreamDefaultWriterClose(this);\n        }\n        /**\n         * Releases the writerâs lock on the corresponding stream. After the lock is released, the writer is no longer active.\n         * If the associated stream is errored when the lock is released, the writer will appear errored in the same way from\n         * now on; otherwise, the writer will appear closed.\n         *\n         * Note that the lock can still be released even if some ongoing writes have not yet finished (i.e. even if the\n         * promises returned from previous calls to {@link WritableStreamDefaultWriter.write | write()} have not yet settled).\n         * Itâs not necessary to hold the lock on the writer for the duration of the write; the lock instead simply prevents\n         * other producers from writing in an interleaved manner.\n         */\n        releaseLock() {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                throw defaultWriterBrandCheckException('releaseLock');\n            }\n            const stream = this._ownerWritableStream;\n            if (stream === undefined) {\n                return;\n            }\n            WritableStreamDefaultWriterRelease(this);\n        }\n        write(chunk = undefined) {\n            if (!IsWritableStreamDefaultWriter(this)) {\n                return promiseRejectedWith(defaultWriterBrandCheckException('write'));\n            }\n            if (this._ownerWritableStream === undefined) {\n                return promiseRejectedWith(defaultWriterLockException('write to'));\n            }\n            return WritableStreamDefaultWriterWrite(this, chunk);\n        }\n    }\n    Object.defineProperties(WritableStreamDefaultWriter.prototype, {\n        abort: { enumerable: true },\n        close: { enumerable: true },\n        releaseLock: { enumerable: true },\n        write: { enumerable: true },\n        closed: { enumerable: true },\n        desiredSize: { enumerable: true },\n        ready: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStreamDefaultWriter.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStreamDefaultWriter',\n            configurable: true\n        });\n    }\n    // Abstract operations for the WritableStreamDefaultWriter.\n    function IsWritableStreamDefaultWriter(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_ownerWritableStream')) {\n            return false;\n        }\n        return x instanceof WritableStreamDefaultWriter;\n    }\n    // A client of WritableStreamDefaultWriter may use these functions directly to bypass state check.\n    function WritableStreamDefaultWriterAbort(writer, reason) {\n        const stream = writer._ownerWritableStream;\n        return WritableStreamAbort(stream, reason);\n    }\n    function WritableStreamDefaultWriterClose(writer) {\n        const stream = writer._ownerWritableStream;\n        return WritableStreamClose(stream);\n    }\n    function WritableStreamDefaultWriterCloseWithErrorPropagation(writer) {\n        const stream = writer._ownerWritableStream;\n        const state = stream._state;\n        if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n            return promiseResolvedWith(undefined);\n        }\n        if (state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        return WritableStreamDefaultWriterClose(writer);\n    }\n    function WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, error) {\n        if (writer._closedPromiseState === 'pending') {\n            defaultWriterClosedPromiseReject(writer, error);\n        }\n        else {\n            defaultWriterClosedPromiseResetToRejected(writer, error);\n        }\n    }\n    function WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, error) {\n        if (writer._readyPromiseState === 'pending') {\n            defaultWriterReadyPromiseReject(writer, error);\n        }\n        else {\n            defaultWriterReadyPromiseResetToRejected(writer, error);\n        }\n    }\n    function WritableStreamDefaultWriterGetDesiredSize(writer) {\n        const stream = writer._ownerWritableStream;\n        const state = stream._state;\n        if (state === 'errored' || state === 'erroring') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return WritableStreamDefaultControllerGetDesiredSize(stream._writableStreamController);\n    }\n    function WritableStreamDefaultWriterRelease(writer) {\n        const stream = writer._ownerWritableStream;\n        const releasedError = new TypeError(`Writer was released and can no longer be used to monitor the stream's closedness`);\n        WritableStreamDefaultWriterEnsureReadyPromiseRejected(writer, releasedError);\n        // The state transitions to \"errored\" before the sink abort() method runs, but the writer.closed promise is not\n        // rejected until afterwards. This means that simply testing state will not work.\n        WritableStreamDefaultWriterEnsureClosedPromiseRejected(writer, releasedError);\n        stream._writer = undefined;\n        writer._ownerWritableStream = undefined;\n    }\n    function WritableStreamDefaultWriterWrite(writer, chunk) {\n        const stream = writer._ownerWritableStream;\n        const controller = stream._writableStreamController;\n        const chunkSize = WritableStreamDefaultControllerGetChunkSize(controller, chunk);\n        if (stream !== writer._ownerWritableStream) {\n            return promiseRejectedWith(defaultWriterLockException('write to'));\n        }\n        const state = stream._state;\n        if (state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        if (WritableStreamCloseQueuedOrInFlight(stream) || state === 'closed') {\n            return promiseRejectedWith(new TypeError('The stream is closing or closed and cannot be written to'));\n        }\n        if (state === 'erroring') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        const promise = WritableStreamAddWriteRequest(stream);\n        WritableStreamDefaultControllerWrite(controller, chunk, chunkSize);\n        return promise;\n    }\n    const closeSentinel = {};\n    /**\n     * Allows control of a {@link WritableStream | writable stream}'s state and internal queue.\n     *\n     * @public\n     */\n    class WritableStreamDefaultController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * The reason which was passed to `WritableStream.abort(reason)` when the stream was aborted.\n         *\n         * @deprecated\n         *  This property has been removed from the specification, see https://github.com/whatwg/streams/pull/1177.\n         *  Use {@link WritableStreamDefaultController.signal}'s `reason` instead.\n         */\n        get abortReason() {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('abortReason');\n            }\n            return this._abortReason;\n        }\n        /**\n         * An `AbortSignal` that can be used to abort the pending write or close operation when the stream is aborted.\n         */\n        get signal() {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('signal');\n            }\n            if (this._abortController === undefined) {\n                // Older browsers or older Node versions may not support `AbortController` or `AbortSignal`.\n                // We don't want to bundle and ship an `AbortController` polyfill together with our polyfill,\n                // so instead we only implement support for `signal` if we find a global `AbortController` constructor.\n                throw new TypeError('WritableStreamDefaultController.prototype.signal is not supported');\n            }\n            return this._abortController.signal;\n        }\n        /**\n         * Closes the controlled writable stream, making all future interactions with it fail with the given error `e`.\n         *\n         * This method is rarely used, since usually it suffices to return a rejected promise from one of the underlying\n         * sink's methods. However, it can be useful for suddenly shutting down a stream in response to an event outside the\n         * normal lifecycle of interactions with the underlying sink.\n         */\n        error(e = undefined) {\n            if (!IsWritableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$2('error');\n            }\n            const state = this._controlledWritableStream._state;\n            if (state !== 'writable') {\n                // The stream is closed, errored or will be soon. The sink can't do anything useful if it gets an error here, so\n                // just treat it as a no-op.\n                return;\n            }\n            WritableStreamDefaultControllerError(this, e);\n        }\n        /** @internal */\n        [AbortSteps](reason) {\n            const result = this._abortAlgorithm(reason);\n            WritableStreamDefaultControllerClearAlgorithms(this);\n            return result;\n        }\n        /** @internal */\n        [ErrorSteps]() {\n            ResetQueue(this);\n        }\n    }\n    Object.defineProperties(WritableStreamDefaultController.prototype, {\n        abortReason: { enumerable: true },\n        signal: { enumerable: true },\n        error: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(WritableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'WritableStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Abstract operations implementing interface required by the WritableStream.\n    function IsWritableStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledWritableStream')) {\n            return false;\n        }\n        return x instanceof WritableStreamDefaultController;\n    }\n    function SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm) {\n        controller._controlledWritableStream = stream;\n        stream._writableStreamController = controller;\n        // Need to set the slots so that the assert doesn't fire. In the spec the slots already exist implicitly.\n        controller._queue = undefined;\n        controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._abortReason = undefined;\n        controller._abortController = createAbortController();\n        controller._started = false;\n        controller._strategySizeAlgorithm = sizeAlgorithm;\n        controller._strategyHWM = highWaterMark;\n        controller._writeAlgorithm = writeAlgorithm;\n        controller._closeAlgorithm = closeAlgorithm;\n        controller._abortAlgorithm = abortAlgorithm;\n        const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n        WritableStreamUpdateBackpressure(stream, backpressure);\n        const startResult = startAlgorithm();\n        const startPromise = promiseResolvedWith(startResult);\n        uponPromise(startPromise, () => {\n            controller._started = true;\n            WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n        }, r => {\n            controller._started = true;\n            WritableStreamDealWithRejection(stream, r);\n        });\n    }\n    function SetUpWritableStreamDefaultControllerFromUnderlyingSink(stream, underlyingSink, highWaterMark, sizeAlgorithm) {\n        const controller = Object.create(WritableStreamDefaultController.prototype);\n        let startAlgorithm = () => undefined;\n        let writeAlgorithm = () => promiseResolvedWith(undefined);\n        let closeAlgorithm = () => promiseResolvedWith(undefined);\n        let abortAlgorithm = () => promiseResolvedWith(undefined);\n        if (underlyingSink.start !== undefined) {\n            startAlgorithm = () => underlyingSink.start(controller);\n        }\n        if (underlyingSink.write !== undefined) {\n            writeAlgorithm = chunk => underlyingSink.write(chunk, controller);\n        }\n        if (underlyingSink.close !== undefined) {\n            closeAlgorithm = () => underlyingSink.close();\n        }\n        if (underlyingSink.abort !== undefined) {\n            abortAlgorithm = reason => underlyingSink.abort(reason);\n        }\n        SetUpWritableStreamDefaultController(stream, controller, startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, highWaterMark, sizeAlgorithm);\n    }\n    // ClearAlgorithms may be called twice. Erroring the same stream in multiple ways will often result in redundant calls.\n    function WritableStreamDefaultControllerClearAlgorithms(controller) {\n        controller._writeAlgorithm = undefined;\n        controller._closeAlgorithm = undefined;\n        controller._abortAlgorithm = undefined;\n        controller._strategySizeAlgorithm = undefined;\n    }\n    function WritableStreamDefaultControllerClose(controller) {\n        EnqueueValueWithSize(controller, closeSentinel, 0);\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }\n    function WritableStreamDefaultControllerGetChunkSize(controller, chunk) {\n        try {\n            return controller._strategySizeAlgorithm(chunk);\n        }\n        catch (chunkSizeE) {\n            WritableStreamDefaultControllerErrorIfNeeded(controller, chunkSizeE);\n            return 1;\n        }\n    }\n    function WritableStreamDefaultControllerGetDesiredSize(controller) {\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    function WritableStreamDefaultControllerWrite(controller, chunk, chunkSize) {\n        try {\n            EnqueueValueWithSize(controller, chunk, chunkSize);\n        }\n        catch (enqueueE) {\n            WritableStreamDefaultControllerErrorIfNeeded(controller, enqueueE);\n            return;\n        }\n        const stream = controller._controlledWritableStream;\n        if (!WritableStreamCloseQueuedOrInFlight(stream) && stream._state === 'writable') {\n            const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n            WritableStreamUpdateBackpressure(stream, backpressure);\n        }\n        WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n    }\n    // Abstract operations for the WritableStreamDefaultController.\n    function WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller) {\n        const stream = controller._controlledWritableStream;\n        if (!controller._started) {\n            return;\n        }\n        if (stream._inFlightWriteRequest !== undefined) {\n            return;\n        }\n        const state = stream._state;\n        if (state === 'erroring') {\n            WritableStreamFinishErroring(stream);\n            return;\n        }\n        if (controller._queue.length === 0) {\n            return;\n        }\n        const value = PeekQueueValue(controller);\n        if (value === closeSentinel) {\n            WritableStreamDefaultControllerProcessClose(controller);\n        }\n        else {\n            WritableStreamDefaultControllerProcessWrite(controller, value);\n        }\n    }\n    function WritableStreamDefaultControllerErrorIfNeeded(controller, error) {\n        if (controller._controlledWritableStream._state === 'writable') {\n            WritableStreamDefaultControllerError(controller, error);\n        }\n    }\n    function WritableStreamDefaultControllerProcessClose(controller) {\n        const stream = controller._controlledWritableStream;\n        WritableStreamMarkCloseRequestInFlight(stream);\n        DequeueValue(controller);\n        const sinkClosePromise = controller._closeAlgorithm();\n        WritableStreamDefaultControllerClearAlgorithms(controller);\n        uponPromise(sinkClosePromise, () => {\n            WritableStreamFinishInFlightClose(stream);\n        }, reason => {\n            WritableStreamFinishInFlightCloseWithError(stream, reason);\n        });\n    }\n    function WritableStreamDefaultControllerProcessWrite(controller, chunk) {\n        const stream = controller._controlledWritableStream;\n        WritableStreamMarkFirstWriteRequestInFlight(stream);\n        const sinkWritePromise = controller._writeAlgorithm(chunk);\n        uponPromise(sinkWritePromise, () => {\n            WritableStreamFinishInFlightWrite(stream);\n            const state = stream._state;\n            DequeueValue(controller);\n            if (!WritableStreamCloseQueuedOrInFlight(stream) && state === 'writable') {\n                const backpressure = WritableStreamDefaultControllerGetBackpressure(controller);\n                WritableStreamUpdateBackpressure(stream, backpressure);\n            }\n            WritableStreamDefaultControllerAdvanceQueueIfNeeded(controller);\n        }, reason => {\n            if (stream._state === 'writable') {\n                WritableStreamDefaultControllerClearAlgorithms(controller);\n            }\n            WritableStreamFinishInFlightWriteWithError(stream, reason);\n        });\n    }\n    function WritableStreamDefaultControllerGetBackpressure(controller) {\n        const desiredSize = WritableStreamDefaultControllerGetDesiredSize(controller);\n        return desiredSize <= 0;\n    }\n    // A client of WritableStreamDefaultController may use these functions directly to bypass state check.\n    function WritableStreamDefaultControllerError(controller, error) {\n        const stream = controller._controlledWritableStream;\n        WritableStreamDefaultControllerClearAlgorithms(controller);\n        WritableStreamStartErroring(stream, error);\n    }\n    // Helper functions for the WritableStream.\n    function streamBrandCheckException$2(name) {\n        return new TypeError(`WritableStream.prototype.${name} can only be used on a WritableStream`);\n    }\n    // Helper functions for the WritableStreamDefaultController.\n    function defaultControllerBrandCheckException$2(name) {\n        return new TypeError(`WritableStreamDefaultController.prototype.${name} can only be used on a WritableStreamDefaultController`);\n    }\n    // Helper functions for the WritableStreamDefaultWriter.\n    function defaultWriterBrandCheckException(name) {\n        return new TypeError(`WritableStreamDefaultWriter.prototype.${name} can only be used on a WritableStreamDefaultWriter`);\n    }\n    function defaultWriterLockException(name) {\n        return new TypeError('Cannot ' + name + ' a stream using a released writer');\n    }\n    function defaultWriterClosedPromiseInitialize(writer) {\n        writer._closedPromise = newPromise((resolve, reject) => {\n            writer._closedPromise_resolve = resolve;\n            writer._closedPromise_reject = reject;\n            writer._closedPromiseState = 'pending';\n        });\n    }\n    function defaultWriterClosedPromiseInitializeAsRejected(writer, reason) {\n        defaultWriterClosedPromiseInitialize(writer);\n        defaultWriterClosedPromiseReject(writer, reason);\n    }\n    function defaultWriterClosedPromiseInitializeAsResolved(writer) {\n        defaultWriterClosedPromiseInitialize(writer);\n        defaultWriterClosedPromiseResolve(writer);\n    }\n    function defaultWriterClosedPromiseReject(writer, reason) {\n        if (writer._closedPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(writer._closedPromise);\n        writer._closedPromise_reject(reason);\n        writer._closedPromise_resolve = undefined;\n        writer._closedPromise_reject = undefined;\n        writer._closedPromiseState = 'rejected';\n    }\n    function defaultWriterClosedPromiseResetToRejected(writer, reason) {\n        defaultWriterClosedPromiseInitializeAsRejected(writer, reason);\n    }\n    function defaultWriterClosedPromiseResolve(writer) {\n        if (writer._closedPromise_resolve === undefined) {\n            return;\n        }\n        writer._closedPromise_resolve(undefined);\n        writer._closedPromise_resolve = undefined;\n        writer._closedPromise_reject = undefined;\n        writer._closedPromiseState = 'resolved';\n    }\n    function defaultWriterReadyPromiseInitialize(writer) {\n        writer._readyPromise = newPromise((resolve, reject) => {\n            writer._readyPromise_resolve = resolve;\n            writer._readyPromise_reject = reject;\n        });\n        writer._readyPromiseState = 'pending';\n    }\n    function defaultWriterReadyPromiseInitializeAsRejected(writer, reason) {\n        defaultWriterReadyPromiseInitialize(writer);\n        defaultWriterReadyPromiseReject(writer, reason);\n    }\n    function defaultWriterReadyPromiseInitializeAsResolved(writer) {\n        defaultWriterReadyPromiseInitialize(writer);\n        defaultWriterReadyPromiseResolve(writer);\n    }\n    function defaultWriterReadyPromiseReject(writer, reason) {\n        if (writer._readyPromise_reject === undefined) {\n            return;\n        }\n        setPromiseIsHandledToTrue(writer._readyPromise);\n        writer._readyPromise_reject(reason);\n        writer._readyPromise_resolve = undefined;\n        writer._readyPromise_reject = undefined;\n        writer._readyPromiseState = 'rejected';\n    }\n    function defaultWriterReadyPromiseReset(writer) {\n        defaultWriterReadyPromiseInitialize(writer);\n    }\n    function defaultWriterReadyPromiseResetToRejected(writer, reason) {\n        defaultWriterReadyPromiseInitializeAsRejected(writer, reason);\n    }\n    function defaultWriterReadyPromiseResolve(writer) {\n        if (writer._readyPromise_resolve === undefined) {\n            return;\n        }\n        writer._readyPromise_resolve(undefined);\n        writer._readyPromise_resolve = undefined;\n        writer._readyPromise_reject = undefined;\n        writer._readyPromiseState = 'fulfilled';\n    }\n\n    /// <reference lib=\"dom\" />\n    const NativeDOMException = typeof DOMException !== 'undefined' ? DOMException : undefined;\n\n    /// <reference types=\"node\" />\n    function isDOMExceptionConstructor(ctor) {\n        if (!(typeof ctor === 'function' || typeof ctor === 'object')) {\n            return false;\n        }\n        try {\n            new ctor();\n            return true;\n        }\n        catch (_a) {\n            return false;\n        }\n    }\n    function createDOMExceptionPolyfill() {\n        // eslint-disable-next-line no-shadow\n        const ctor = function DOMException(message, name) {\n            this.message = message || '';\n            this.name = name || 'Error';\n            if (Error.captureStackTrace) {\n                Error.captureStackTrace(this, this.constructor);\n            }\n        };\n        ctor.prototype = Object.create(Error.prototype);\n        Object.defineProperty(ctor.prototype, 'constructor', { value: ctor, writable: true, configurable: true });\n        return ctor;\n    }\n    // eslint-disable-next-line no-redeclare\n    const DOMException$1 = isDOMExceptionConstructor(NativeDOMException) ? NativeDOMException : createDOMExceptionPolyfill();\n\n    function ReadableStreamPipeTo(source, dest, preventClose, preventAbort, preventCancel, signal) {\n        const reader = AcquireReadableStreamDefaultReader(source);\n        const writer = AcquireWritableStreamDefaultWriter(dest);\n        source._disturbed = true;\n        let shuttingDown = false;\n        // This is used to keep track of the spec's requirement that we wait for ongoing writes during shutdown.\n        let currentWrite = promiseResolvedWith(undefined);\n        return newPromise((resolve, reject) => {\n            let abortAlgorithm;\n            if (signal !== undefined) {\n                abortAlgorithm = () => {\n                    const error = new DOMException$1('Aborted', 'AbortError');\n                    const actions = [];\n                    if (!preventAbort) {\n                        actions.push(() => {\n                            if (dest._state === 'writable') {\n                                return WritableStreamAbort(dest, error);\n                            }\n                            return promiseResolvedWith(undefined);\n                        });\n                    }\n                    if (!preventCancel) {\n                        actions.push(() => {\n                            if (source._state === 'readable') {\n                                return ReadableStreamCancel(source, error);\n                            }\n                            return promiseResolvedWith(undefined);\n                        });\n                    }\n                    shutdownWithAction(() => Promise.all(actions.map(action => action())), true, error);\n                };\n                if (signal.aborted) {\n                    abortAlgorithm();\n                    return;\n                }\n                signal.addEventListener('abort', abortAlgorithm);\n            }\n            // Using reader and writer, read all chunks from this and write them to dest\n            // - Backpressure must be enforced\n            // - Shutdown must stop all activity\n            function pipeLoop() {\n                return newPromise((resolveLoop, rejectLoop) => {\n                    function next(done) {\n                        if (done) {\n                            resolveLoop();\n                        }\n                        else {\n                            // Use `PerformPromiseThen` instead of `uponPromise` to avoid\n                            // adding unnecessary `.catch(rethrowAssertionErrorRejection)` handlers\n                            PerformPromiseThen(pipeStep(), next, rejectLoop);\n                        }\n                    }\n                    next(false);\n                });\n            }\n            function pipeStep() {\n                if (shuttingDown) {\n                    return promiseResolvedWith(true);\n                }\n                return PerformPromiseThen(writer._readyPromise, () => {\n                    return newPromise((resolveRead, rejectRead) => {\n                        ReadableStreamDefaultReaderRead(reader, {\n                            _chunkSteps: chunk => {\n                                currentWrite = PerformPromiseThen(WritableStreamDefaultWriterWrite(writer, chunk), undefined, noop);\n                                resolveRead(false);\n                            },\n                            _closeSteps: () => resolveRead(true),\n                            _errorSteps: rejectRead\n                        });\n                    });\n                });\n            }\n            // Errors must be propagated forward\n            isOrBecomesErrored(source, reader._closedPromise, storedError => {\n                if (!preventAbort) {\n                    shutdownWithAction(() => WritableStreamAbort(dest, storedError), true, storedError);\n                }\n                else {\n                    shutdown(true, storedError);\n                }\n            });\n            // Errors must be propagated backward\n            isOrBecomesErrored(dest, writer._closedPromise, storedError => {\n                if (!preventCancel) {\n                    shutdownWithAction(() => ReadableStreamCancel(source, storedError), true, storedError);\n                }\n                else {\n                    shutdown(true, storedError);\n                }\n            });\n            // Closing must be propagated forward\n            isOrBecomesClosed(source, reader._closedPromise, () => {\n                if (!preventClose) {\n                    shutdownWithAction(() => WritableStreamDefaultWriterCloseWithErrorPropagation(writer));\n                }\n                else {\n                    shutdown();\n                }\n            });\n            // Closing must be propagated backward\n            if (WritableStreamCloseQueuedOrInFlight(dest) || dest._state === 'closed') {\n                const destClosed = new TypeError('the destination writable stream closed before all data could be piped to it');\n                if (!preventCancel) {\n                    shutdownWithAction(() => ReadableStreamCancel(source, destClosed), true, destClosed);\n                }\n                else {\n                    shutdown(true, destClosed);\n                }\n            }\n            setPromiseIsHandledToTrue(pipeLoop());\n            function waitForWritesToFinish() {\n                // Another write may have started while we were waiting on this currentWrite, so we have to be sure to wait\n                // for that too.\n                const oldCurrentWrite = currentWrite;\n                return PerformPromiseThen(currentWrite, () => oldCurrentWrite !== currentWrite ? waitForWritesToFinish() : undefined);\n            }\n            function isOrBecomesErrored(stream, promise, action) {\n                if (stream._state === 'errored') {\n                    action(stream._storedError);\n                }\n                else {\n                    uponRejection(promise, action);\n                }\n            }\n            function isOrBecomesClosed(stream, promise, action) {\n                if (stream._state === 'closed') {\n                    action();\n                }\n                else {\n                    uponFulfillment(promise, action);\n                }\n            }\n            function shutdownWithAction(action, originalIsError, originalError) {\n                if (shuttingDown) {\n                    return;\n                }\n                shuttingDown = true;\n                if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                    uponFulfillment(waitForWritesToFinish(), doTheRest);\n                }\n                else {\n                    doTheRest();\n                }\n                function doTheRest() {\n                    uponPromise(action(), () => finalize(originalIsError, originalError), newError => finalize(true, newError));\n                }\n            }\n            function shutdown(isError, error) {\n                if (shuttingDown) {\n                    return;\n                }\n                shuttingDown = true;\n                if (dest._state === 'writable' && !WritableStreamCloseQueuedOrInFlight(dest)) {\n                    uponFulfillment(waitForWritesToFinish(), () => finalize(isError, error));\n                }\n                else {\n                    finalize(isError, error);\n                }\n            }\n            function finalize(isError, error) {\n                WritableStreamDefaultWriterRelease(writer);\n                ReadableStreamReaderGenericRelease(reader);\n                if (signal !== undefined) {\n                    signal.removeEventListener('abort', abortAlgorithm);\n                }\n                if (isError) {\n                    reject(error);\n                }\n                else {\n                    resolve(undefined);\n                }\n            }\n        });\n    }\n\n    /**\n     * Allows control of a {@link ReadableStream | readable stream}'s state and internal queue.\n     *\n     * @public\n     */\n    class ReadableStreamDefaultController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the desired size to fill the controlled stream's internal queue. It can be negative, if the queue is\n         * over-full. An underlying source ought to use this information to determine when and how to apply backpressure.\n         */\n        get desiredSize() {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('desiredSize');\n            }\n            return ReadableStreamDefaultControllerGetDesiredSize(this);\n        }\n        /**\n         * Closes the controlled readable stream. Consumers will still be able to read any previously-enqueued chunks from\n         * the stream, but once those are read, the stream will become closed.\n         */\n        close() {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('close');\n            }\n            if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n                throw new TypeError('The stream is not in a state that permits close');\n            }\n            ReadableStreamDefaultControllerClose(this);\n        }\n        enqueue(chunk = undefined) {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('enqueue');\n            }\n            if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(this)) {\n                throw new TypeError('The stream is not in a state that permits enqueue');\n            }\n            return ReadableStreamDefaultControllerEnqueue(this, chunk);\n        }\n        /**\n         * Errors the controlled readable stream, making all future interactions with it fail with the given error `e`.\n         */\n        error(e = undefined) {\n            if (!IsReadableStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException$1('error');\n            }\n            ReadableStreamDefaultControllerError(this, e);\n        }\n        /** @internal */\n        [CancelSteps](reason) {\n            ResetQueue(this);\n            const result = this._cancelAlgorithm(reason);\n            ReadableStreamDefaultControllerClearAlgorithms(this);\n            return result;\n        }\n        /** @internal */\n        [PullSteps](readRequest) {\n            const stream = this._controlledReadableStream;\n            if (this._queue.length > 0) {\n                const chunk = DequeueValue(this);\n                if (this._closeRequested && this._queue.length === 0) {\n                    ReadableStreamDefaultControllerClearAlgorithms(this);\n                    ReadableStreamClose(stream);\n                }\n                else {\n                    ReadableStreamDefaultControllerCallPullIfNeeded(this);\n                }\n                readRequest._chunkSteps(chunk);\n            }\n            else {\n                ReadableStreamAddReadRequest(stream, readRequest);\n                ReadableStreamDefaultControllerCallPullIfNeeded(this);\n            }\n        }\n    }\n    Object.defineProperties(ReadableStreamDefaultController.prototype, {\n        close: { enumerable: true },\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableStreamDefaultController.\n    function IsReadableStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledReadableStream')) {\n            return false;\n        }\n        return x instanceof ReadableStreamDefaultController;\n    }\n    function ReadableStreamDefaultControllerCallPullIfNeeded(controller) {\n        const shouldPull = ReadableStreamDefaultControllerShouldCallPull(controller);\n        if (!shouldPull) {\n            return;\n        }\n        if (controller._pulling) {\n            controller._pullAgain = true;\n            return;\n        }\n        controller._pulling = true;\n        const pullPromise = controller._pullAlgorithm();\n        uponPromise(pullPromise, () => {\n            controller._pulling = false;\n            if (controller._pullAgain) {\n                controller._pullAgain = false;\n                ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n            }\n        }, e => {\n            ReadableStreamDefaultControllerError(controller, e);\n        });\n    }\n    function ReadableStreamDefaultControllerShouldCallPull(controller) {\n        const stream = controller._controlledReadableStream;\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return false;\n        }\n        if (!controller._started) {\n            return false;\n        }\n        if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            return true;\n        }\n        const desiredSize = ReadableStreamDefaultControllerGetDesiredSize(controller);\n        if (desiredSize > 0) {\n            return true;\n        }\n        return false;\n    }\n    function ReadableStreamDefaultControllerClearAlgorithms(controller) {\n        controller._pullAlgorithm = undefined;\n        controller._cancelAlgorithm = undefined;\n        controller._strategySizeAlgorithm = undefined;\n    }\n    // A client of ReadableStreamDefaultController may use these functions directly to bypass state check.\n    function ReadableStreamDefaultControllerClose(controller) {\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return;\n        }\n        const stream = controller._controlledReadableStream;\n        controller._closeRequested = true;\n        if (controller._queue.length === 0) {\n            ReadableStreamDefaultControllerClearAlgorithms(controller);\n            ReadableStreamClose(stream);\n        }\n    }\n    function ReadableStreamDefaultControllerEnqueue(controller, chunk) {\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(controller)) {\n            return;\n        }\n        const stream = controller._controlledReadableStream;\n        if (IsReadableStreamLocked(stream) && ReadableStreamGetNumReadRequests(stream) > 0) {\n            ReadableStreamFulfillReadRequest(stream, chunk, false);\n        }\n        else {\n            let chunkSize;\n            try {\n                chunkSize = controller._strategySizeAlgorithm(chunk);\n            }\n            catch (chunkSizeE) {\n                ReadableStreamDefaultControllerError(controller, chunkSizeE);\n                throw chunkSizeE;\n            }\n            try {\n                EnqueueValueWithSize(controller, chunk, chunkSize);\n            }\n            catch (enqueueE) {\n                ReadableStreamDefaultControllerError(controller, enqueueE);\n                throw enqueueE;\n            }\n        }\n        ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n    }\n    function ReadableStreamDefaultControllerError(controller, e) {\n        const stream = controller._controlledReadableStream;\n        if (stream._state !== 'readable') {\n            return;\n        }\n        ResetQueue(controller);\n        ReadableStreamDefaultControllerClearAlgorithms(controller);\n        ReadableStreamError(stream, e);\n    }\n    function ReadableStreamDefaultControllerGetDesiredSize(controller) {\n        const state = controller._controlledReadableStream._state;\n        if (state === 'errored') {\n            return null;\n        }\n        if (state === 'closed') {\n            return 0;\n        }\n        return controller._strategyHWM - controller._queueTotalSize;\n    }\n    // This is used in the implementation of TransformStream.\n    function ReadableStreamDefaultControllerHasBackpressure(controller) {\n        if (ReadableStreamDefaultControllerShouldCallPull(controller)) {\n            return false;\n        }\n        return true;\n    }\n    function ReadableStreamDefaultControllerCanCloseOrEnqueue(controller) {\n        const state = controller._controlledReadableStream._state;\n        if (!controller._closeRequested && state === 'readable') {\n            return true;\n        }\n        return false;\n    }\n    function SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm) {\n        controller._controlledReadableStream = stream;\n        controller._queue = undefined;\n        controller._queueTotalSize = undefined;\n        ResetQueue(controller);\n        controller._started = false;\n        controller._closeRequested = false;\n        controller._pullAgain = false;\n        controller._pulling = false;\n        controller._strategySizeAlgorithm = sizeAlgorithm;\n        controller._strategyHWM = highWaterMark;\n        controller._pullAlgorithm = pullAlgorithm;\n        controller._cancelAlgorithm = cancelAlgorithm;\n        stream._readableStreamController = controller;\n        const startResult = startAlgorithm();\n        uponPromise(promiseResolvedWith(startResult), () => {\n            controller._started = true;\n            ReadableStreamDefaultControllerCallPullIfNeeded(controller);\n        }, r => {\n            ReadableStreamDefaultControllerError(controller, r);\n        });\n    }\n    function SetUpReadableStreamDefaultControllerFromUnderlyingSource(stream, underlyingSource, highWaterMark, sizeAlgorithm) {\n        const controller = Object.create(ReadableStreamDefaultController.prototype);\n        let startAlgorithm = () => undefined;\n        let pullAlgorithm = () => promiseResolvedWith(undefined);\n        let cancelAlgorithm = () => promiseResolvedWith(undefined);\n        if (underlyingSource.start !== undefined) {\n            startAlgorithm = () => underlyingSource.start(controller);\n        }\n        if (underlyingSource.pull !== undefined) {\n            pullAlgorithm = () => underlyingSource.pull(controller);\n        }\n        if (underlyingSource.cancel !== undefined) {\n            cancelAlgorithm = reason => underlyingSource.cancel(reason);\n        }\n        SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n    }\n    // Helper functions for the ReadableStreamDefaultController.\n    function defaultControllerBrandCheckException$1(name) {\n        return new TypeError(`ReadableStreamDefaultController.prototype.${name} can only be used on a ReadableStreamDefaultController`);\n    }\n\n    function ReadableStreamTee(stream, cloneForBranch2) {\n        if (IsReadableByteStreamController(stream._readableStreamController)) {\n            return ReadableByteStreamTee(stream);\n        }\n        return ReadableStreamDefaultTee(stream);\n    }\n    function ReadableStreamDefaultTee(stream, cloneForBranch2) {\n        const reader = AcquireReadableStreamDefaultReader(stream);\n        let reading = false;\n        let readAgain = false;\n        let canceled1 = false;\n        let canceled2 = false;\n        let reason1;\n        let reason2;\n        let branch1;\n        let branch2;\n        let resolveCancelPromise;\n        const cancelPromise = newPromise(resolve => {\n            resolveCancelPromise = resolve;\n        });\n        function pullAlgorithm() {\n            if (reading) {\n                readAgain = true;\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            const readRequest = {\n                _chunkSteps: chunk => {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(() => {\n                        readAgain = false;\n                        const chunk1 = chunk;\n                        const chunk2 = chunk;\n                        // There is no way to access the cloning code right now in the reference implementation.\n                        // If we add one then we'll need an implementation for serializable objects.\n                        // if (!canceled2 && cloneForBranch2) {\n                        //   chunk2 = StructuredDeserialize(StructuredSerialize(chunk2));\n                        // }\n                        if (!canceled1) {\n                            ReadableStreamDefaultControllerEnqueue(branch1._readableStreamController, chunk1);\n                        }\n                        if (!canceled2) {\n                            ReadableStreamDefaultControllerEnqueue(branch2._readableStreamController, chunk2);\n                        }\n                        reading = false;\n                        if (readAgain) {\n                            pullAlgorithm();\n                        }\n                    });\n                },\n                _closeSteps: () => {\n                    reading = false;\n                    if (!canceled1) {\n                        ReadableStreamDefaultControllerClose(branch1._readableStreamController);\n                    }\n                    if (!canceled2) {\n                        ReadableStreamDefaultControllerClose(branch2._readableStreamController);\n                    }\n                    if (!canceled1 || !canceled2) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: () => {\n                    reading = false;\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n            return promiseResolvedWith(undefined);\n        }\n        function cancel1Algorithm(reason) {\n            canceled1 = true;\n            reason1 = reason;\n            if (canceled2) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function cancel2Algorithm(reason) {\n            canceled2 = true;\n            reason2 = reason;\n            if (canceled1) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function startAlgorithm() {\n            // do nothing\n        }\n        branch1 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel1Algorithm);\n        branch2 = CreateReadableStream(startAlgorithm, pullAlgorithm, cancel2Algorithm);\n        uponRejection(reader._closedPromise, (r) => {\n            ReadableStreamDefaultControllerError(branch1._readableStreamController, r);\n            ReadableStreamDefaultControllerError(branch2._readableStreamController, r);\n            if (!canceled1 || !canceled2) {\n                resolveCancelPromise(undefined);\n            }\n        });\n        return [branch1, branch2];\n    }\n    function ReadableByteStreamTee(stream) {\n        let reader = AcquireReadableStreamDefaultReader(stream);\n        let reading = false;\n        let readAgainForBranch1 = false;\n        let readAgainForBranch2 = false;\n        let canceled1 = false;\n        let canceled2 = false;\n        let reason1;\n        let reason2;\n        let branch1;\n        let branch2;\n        let resolveCancelPromise;\n        const cancelPromise = newPromise(resolve => {\n            resolveCancelPromise = resolve;\n        });\n        function forwardReaderError(thisReader) {\n            uponRejection(thisReader._closedPromise, r => {\n                if (thisReader !== reader) {\n                    return;\n                }\n                ReadableByteStreamControllerError(branch1._readableStreamController, r);\n                ReadableByteStreamControllerError(branch2._readableStreamController, r);\n                if (!canceled1 || !canceled2) {\n                    resolveCancelPromise(undefined);\n                }\n            });\n        }\n        function pullWithDefaultReader() {\n            if (IsReadableStreamBYOBReader(reader)) {\n                ReadableStreamReaderGenericRelease(reader);\n                reader = AcquireReadableStreamDefaultReader(stream);\n                forwardReaderError(reader);\n            }\n            const readRequest = {\n                _chunkSteps: chunk => {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(() => {\n                        readAgainForBranch1 = false;\n                        readAgainForBranch2 = false;\n                        const chunk1 = chunk;\n                        let chunk2 = chunk;\n                        if (!canceled1 && !canceled2) {\n                            try {\n                                chunk2 = CloneAsUint8Array(chunk);\n                            }\n                            catch (cloneE) {\n                                ReadableByteStreamControllerError(branch1._readableStreamController, cloneE);\n                                ReadableByteStreamControllerError(branch2._readableStreamController, cloneE);\n                                resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n                                return;\n                            }\n                        }\n                        if (!canceled1) {\n                            ReadableByteStreamControllerEnqueue(branch1._readableStreamController, chunk1);\n                        }\n                        if (!canceled2) {\n                            ReadableByteStreamControllerEnqueue(branch2._readableStreamController, chunk2);\n                        }\n                        reading = false;\n                        if (readAgainForBranch1) {\n                            pull1Algorithm();\n                        }\n                        else if (readAgainForBranch2) {\n                            pull2Algorithm();\n                        }\n                    });\n                },\n                _closeSteps: () => {\n                    reading = false;\n                    if (!canceled1) {\n                        ReadableByteStreamControllerClose(branch1._readableStreamController);\n                    }\n                    if (!canceled2) {\n                        ReadableByteStreamControllerClose(branch2._readableStreamController);\n                    }\n                    if (branch1._readableStreamController._pendingPullIntos.length > 0) {\n                        ReadableByteStreamControllerRespond(branch1._readableStreamController, 0);\n                    }\n                    if (branch2._readableStreamController._pendingPullIntos.length > 0) {\n                        ReadableByteStreamControllerRespond(branch2._readableStreamController, 0);\n                    }\n                    if (!canceled1 || !canceled2) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: () => {\n                    reading = false;\n                }\n            };\n            ReadableStreamDefaultReaderRead(reader, readRequest);\n        }\n        function pullWithBYOBReader(view, forBranch2) {\n            if (IsReadableStreamDefaultReader(reader)) {\n                ReadableStreamReaderGenericRelease(reader);\n                reader = AcquireReadableStreamBYOBReader(stream);\n                forwardReaderError(reader);\n            }\n            const byobBranch = forBranch2 ? branch2 : branch1;\n            const otherBranch = forBranch2 ? branch1 : branch2;\n            const readIntoRequest = {\n                _chunkSteps: chunk => {\n                    // This needs to be delayed a microtask because it takes at least a microtask to detect errors (using\n                    // reader._closedPromise below), and we want errors in stream to error both branches immediately. We cannot let\n                    // successful synchronously-available reads get ahead of asynchronously-available errors.\n                    queueMicrotask(() => {\n                        readAgainForBranch1 = false;\n                        readAgainForBranch2 = false;\n                        const byobCanceled = forBranch2 ? canceled2 : canceled1;\n                        const otherCanceled = forBranch2 ? canceled1 : canceled2;\n                        if (!otherCanceled) {\n                            let clonedChunk;\n                            try {\n                                clonedChunk = CloneAsUint8Array(chunk);\n                            }\n                            catch (cloneE) {\n                                ReadableByteStreamControllerError(byobBranch._readableStreamController, cloneE);\n                                ReadableByteStreamControllerError(otherBranch._readableStreamController, cloneE);\n                                resolveCancelPromise(ReadableStreamCancel(stream, cloneE));\n                                return;\n                            }\n                            if (!byobCanceled) {\n                                ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                            }\n                            ReadableByteStreamControllerEnqueue(otherBranch._readableStreamController, clonedChunk);\n                        }\n                        else if (!byobCanceled) {\n                            ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                        }\n                        reading = false;\n                        if (readAgainForBranch1) {\n                            pull1Algorithm();\n                        }\n                        else if (readAgainForBranch2) {\n                            pull2Algorithm();\n                        }\n                    });\n                },\n                _closeSteps: chunk => {\n                    reading = false;\n                    const byobCanceled = forBranch2 ? canceled2 : canceled1;\n                    const otherCanceled = forBranch2 ? canceled1 : canceled2;\n                    if (!byobCanceled) {\n                        ReadableByteStreamControllerClose(byobBranch._readableStreamController);\n                    }\n                    if (!otherCanceled) {\n                        ReadableByteStreamControllerClose(otherBranch._readableStreamController);\n                    }\n                    if (chunk !== undefined) {\n                        if (!byobCanceled) {\n                            ReadableByteStreamControllerRespondWithNewView(byobBranch._readableStreamController, chunk);\n                        }\n                        if (!otherCanceled && otherBranch._readableStreamController._pendingPullIntos.length > 0) {\n                            ReadableByteStreamControllerRespond(otherBranch._readableStreamController, 0);\n                        }\n                    }\n                    if (!byobCanceled || !otherCanceled) {\n                        resolveCancelPromise(undefined);\n                    }\n                },\n                _errorSteps: () => {\n                    reading = false;\n                }\n            };\n            ReadableStreamBYOBReaderRead(reader, view, readIntoRequest);\n        }\n        function pull1Algorithm() {\n            if (reading) {\n                readAgainForBranch1 = true;\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            const byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch1._readableStreamController);\n            if (byobRequest === null) {\n                pullWithDefaultReader();\n            }\n            else {\n                pullWithBYOBReader(byobRequest._view, false);\n            }\n            return promiseResolvedWith(undefined);\n        }\n        function pull2Algorithm() {\n            if (reading) {\n                readAgainForBranch2 = true;\n                return promiseResolvedWith(undefined);\n            }\n            reading = true;\n            const byobRequest = ReadableByteStreamControllerGetBYOBRequest(branch2._readableStreamController);\n            if (byobRequest === null) {\n                pullWithDefaultReader();\n            }\n            else {\n                pullWithBYOBReader(byobRequest._view, true);\n            }\n            return promiseResolvedWith(undefined);\n        }\n        function cancel1Algorithm(reason) {\n            canceled1 = true;\n            reason1 = reason;\n            if (canceled2) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function cancel2Algorithm(reason) {\n            canceled2 = true;\n            reason2 = reason;\n            if (canceled1) {\n                const compositeReason = CreateArrayFromList([reason1, reason2]);\n                const cancelResult = ReadableStreamCancel(stream, compositeReason);\n                resolveCancelPromise(cancelResult);\n            }\n            return cancelPromise;\n        }\n        function startAlgorithm() {\n            return;\n        }\n        branch1 = CreateReadableByteStream(startAlgorithm, pull1Algorithm, cancel1Algorithm);\n        branch2 = CreateReadableByteStream(startAlgorithm, pull2Algorithm, cancel2Algorithm);\n        forwardReaderError(reader);\n        return [branch1, branch2];\n    }\n\n    function convertUnderlyingDefaultOrByteSource(source, context) {\n        assertDictionary(source, context);\n        const original = source;\n        const autoAllocateChunkSize = original === null || original === void 0 ? void 0 : original.autoAllocateChunkSize;\n        const cancel = original === null || original === void 0 ? void 0 : original.cancel;\n        const pull = original === null || original === void 0 ? void 0 : original.pull;\n        const start = original === null || original === void 0 ? void 0 : original.start;\n        const type = original === null || original === void 0 ? void 0 : original.type;\n        return {\n            autoAllocateChunkSize: autoAllocateChunkSize === undefined ?\n                undefined :\n                convertUnsignedLongLongWithEnforceRange(autoAllocateChunkSize, `${context} has member 'autoAllocateChunkSize' that`),\n            cancel: cancel === undefined ?\n                undefined :\n                convertUnderlyingSourceCancelCallback(cancel, original, `${context} has member 'cancel' that`),\n            pull: pull === undefined ?\n                undefined :\n                convertUnderlyingSourcePullCallback(pull, original, `${context} has member 'pull' that`),\n            start: start === undefined ?\n                undefined :\n                convertUnderlyingSourceStartCallback(start, original, `${context} has member 'start' that`),\n            type: type === undefined ? undefined : convertReadableStreamType(type, `${context} has member 'type' that`)\n        };\n    }\n    function convertUnderlyingSourceCancelCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (reason) => promiseCall(fn, original, [reason]);\n    }\n    function convertUnderlyingSourcePullCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => promiseCall(fn, original, [controller]);\n    }\n    function convertUnderlyingSourceStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => reflectCall(fn, original, [controller]);\n    }\n    function convertReadableStreamType(type, context) {\n        type = `${type}`;\n        if (type !== 'bytes') {\n            throw new TypeError(`${context} '${type}' is not a valid enumeration value for ReadableStreamType`);\n        }\n        return type;\n    }\n\n    function convertReaderOptions(options, context) {\n        assertDictionary(options, context);\n        const mode = options === null || options === void 0 ? void 0 : options.mode;\n        return {\n            mode: mode === undefined ? undefined : convertReadableStreamReaderMode(mode, `${context} has member 'mode' that`)\n        };\n    }\n    function convertReadableStreamReaderMode(mode, context) {\n        mode = `${mode}`;\n        if (mode !== 'byob') {\n            throw new TypeError(`${context} '${mode}' is not a valid enumeration value for ReadableStreamReaderMode`);\n        }\n        return mode;\n    }\n\n    function convertIteratorOptions(options, context) {\n        assertDictionary(options, context);\n        const preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n        return { preventCancel: Boolean(preventCancel) };\n    }\n\n    function convertPipeOptions(options, context) {\n        assertDictionary(options, context);\n        const preventAbort = options === null || options === void 0 ? void 0 : options.preventAbort;\n        const preventCancel = options === null || options === void 0 ? void 0 : options.preventCancel;\n        const preventClose = options === null || options === void 0 ? void 0 : options.preventClose;\n        const signal = options === null || options === void 0 ? void 0 : options.signal;\n        if (signal !== undefined) {\n            assertAbortSignal(signal, `${context} has member 'signal' that`);\n        }\n        return {\n            preventAbort: Boolean(preventAbort),\n            preventCancel: Boolean(preventCancel),\n            preventClose: Boolean(preventClose),\n            signal\n        };\n    }\n    function assertAbortSignal(signal, context) {\n        if (!isAbortSignal(signal)) {\n            throw new TypeError(`${context} is not an AbortSignal.`);\n        }\n    }\n\n    function convertReadableWritablePair(pair, context) {\n        assertDictionary(pair, context);\n        const readable = pair === null || pair === void 0 ? void 0 : pair.readable;\n        assertRequiredField(readable, 'readable', 'ReadableWritablePair');\n        assertReadableStream(readable, `${context} has member 'readable' that`);\n        const writable = pair === null || pair === void 0 ? void 0 : pair.writable;\n        assertRequiredField(writable, 'writable', 'ReadableWritablePair');\n        assertWritableStream(writable, `${context} has member 'writable' that`);\n        return { readable, writable };\n    }\n\n    /**\n     * A readable stream represents a source of data, from which you can read.\n     *\n     * @public\n     */\n    class ReadableStream {\n        constructor(rawUnderlyingSource = {}, rawStrategy = {}) {\n            if (rawUnderlyingSource === undefined) {\n                rawUnderlyingSource = null;\n            }\n            else {\n                assertObject(rawUnderlyingSource, 'First parameter');\n            }\n            const strategy = convertQueuingStrategy(rawStrategy, 'Second parameter');\n            const underlyingSource = convertUnderlyingDefaultOrByteSource(rawUnderlyingSource, 'First parameter');\n            InitializeReadableStream(this);\n            if (underlyingSource.type === 'bytes') {\n                if (strategy.size !== undefined) {\n                    throw new RangeError('The strategy for a byte stream cannot have a size function');\n                }\n                const highWaterMark = ExtractHighWaterMark(strategy, 0);\n                SetUpReadableByteStreamControllerFromUnderlyingSource(this, underlyingSource, highWaterMark);\n            }\n            else {\n                const sizeAlgorithm = ExtractSizeAlgorithm(strategy);\n                const highWaterMark = ExtractHighWaterMark(strategy, 1);\n                SetUpReadableStreamDefaultControllerFromUnderlyingSource(this, underlyingSource, highWaterMark, sizeAlgorithm);\n            }\n        }\n        /**\n         * Whether or not the readable stream is locked to a {@link ReadableStreamDefaultReader | reader}.\n         */\n        get locked() {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('locked');\n            }\n            return IsReadableStreamLocked(this);\n        }\n        /**\n         * Cancels the stream, signaling a loss of interest in the stream by a consumer.\n         *\n         * The supplied `reason` argument will be given to the underlying source's {@link UnderlyingSource.cancel | cancel()}\n         * method, which might or might not use it.\n         */\n        cancel(reason = undefined) {\n            if (!IsReadableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$1('cancel'));\n            }\n            if (IsReadableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('Cannot cancel a stream that already has a reader'));\n            }\n            return ReadableStreamCancel(this, reason);\n        }\n        getReader(rawOptions = undefined) {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('getReader');\n            }\n            const options = convertReaderOptions(rawOptions, 'First parameter');\n            if (options.mode === undefined) {\n                return AcquireReadableStreamDefaultReader(this);\n            }\n            return AcquireReadableStreamBYOBReader(this);\n        }\n        pipeThrough(rawTransform, rawOptions = {}) {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('pipeThrough');\n            }\n            assertRequiredArgument(rawTransform, 1, 'pipeThrough');\n            const transform = convertReadableWritablePair(rawTransform, 'First parameter');\n            const options = convertPipeOptions(rawOptions, 'Second parameter');\n            if (IsReadableStreamLocked(this)) {\n                throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked ReadableStream');\n            }\n            if (IsWritableStreamLocked(transform.writable)) {\n                throw new TypeError('ReadableStream.prototype.pipeThrough cannot be used on a locked WritableStream');\n            }\n            const promise = ReadableStreamPipeTo(this, transform.writable, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n            setPromiseIsHandledToTrue(promise);\n            return transform.readable;\n        }\n        pipeTo(destination, rawOptions = {}) {\n            if (!IsReadableStream(this)) {\n                return promiseRejectedWith(streamBrandCheckException$1('pipeTo'));\n            }\n            if (destination === undefined) {\n                return promiseRejectedWith(`Parameter 1 is required in 'pipeTo'.`);\n            }\n            if (!IsWritableStream(destination)) {\n                return promiseRejectedWith(new TypeError(`ReadableStream.prototype.pipeTo's first argument must be a WritableStream`));\n            }\n            let options;\n            try {\n                options = convertPipeOptions(rawOptions, 'Second parameter');\n            }\n            catch (e) {\n                return promiseRejectedWith(e);\n            }\n            if (IsReadableStreamLocked(this)) {\n                return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked ReadableStream'));\n            }\n            if (IsWritableStreamLocked(destination)) {\n                return promiseRejectedWith(new TypeError('ReadableStream.prototype.pipeTo cannot be used on a locked WritableStream'));\n            }\n            return ReadableStreamPipeTo(this, destination, options.preventClose, options.preventAbort, options.preventCancel, options.signal);\n        }\n        /**\n         * Tees this readable stream, returning a two-element array containing the two resulting branches as\n         * new {@link ReadableStream} instances.\n         *\n         * Teeing a stream will lock it, preventing any other consumer from acquiring a reader.\n         * To cancel the stream, cancel both of the resulting branches; a composite cancellation reason will then be\n         * propagated to the stream's underlying source.\n         *\n         * Note that the chunks seen in each branch will be the same object. If the chunks are not immutable,\n         * this could allow interference between the two branches.\n         */\n        tee() {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('tee');\n            }\n            const branches = ReadableStreamTee(this);\n            return CreateArrayFromList(branches);\n        }\n        values(rawOptions = undefined) {\n            if (!IsReadableStream(this)) {\n                throw streamBrandCheckException$1('values');\n            }\n            const options = convertIteratorOptions(rawOptions, 'First parameter');\n            return AcquireReadableStreamAsyncIterator(this, options.preventCancel);\n        }\n    }\n    Object.defineProperties(ReadableStream.prototype, {\n        cancel: { enumerable: true },\n        getReader: { enumerable: true },\n        pipeThrough: { enumerable: true },\n        pipeTo: { enumerable: true },\n        tee: { enumerable: true },\n        values: { enumerable: true },\n        locked: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ReadableStream',\n            configurable: true\n        });\n    }\n    if (typeof SymbolPolyfill.asyncIterator === 'symbol') {\n        Object.defineProperty(ReadableStream.prototype, SymbolPolyfill.asyncIterator, {\n            value: ReadableStream.prototype.values,\n            writable: true,\n            configurable: true\n        });\n    }\n    // Abstract operations for the ReadableStream.\n    // Throws if and only if startAlgorithm throws.\n    function CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark = 1, sizeAlgorithm = () => 1) {\n        const stream = Object.create(ReadableStream.prototype);\n        InitializeReadableStream(stream);\n        const controller = Object.create(ReadableStreamDefaultController.prototype);\n        SetUpReadableStreamDefaultController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, highWaterMark, sizeAlgorithm);\n        return stream;\n    }\n    // Throws if and only if startAlgorithm throws.\n    function CreateReadableByteStream(startAlgorithm, pullAlgorithm, cancelAlgorithm) {\n        const stream = Object.create(ReadableStream.prototype);\n        InitializeReadableStream(stream);\n        const controller = Object.create(ReadableByteStreamController.prototype);\n        SetUpReadableByteStreamController(stream, controller, startAlgorithm, pullAlgorithm, cancelAlgorithm, 0, undefined);\n        return stream;\n    }\n    function InitializeReadableStream(stream) {\n        stream._state = 'readable';\n        stream._reader = undefined;\n        stream._storedError = undefined;\n        stream._disturbed = false;\n    }\n    function IsReadableStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_readableStreamController')) {\n            return false;\n        }\n        return x instanceof ReadableStream;\n    }\n    function IsReadableStreamLocked(stream) {\n        if (stream._reader === undefined) {\n            return false;\n        }\n        return true;\n    }\n    // ReadableStream API exposed for controllers.\n    function ReadableStreamCancel(stream, reason) {\n        stream._disturbed = true;\n        if (stream._state === 'closed') {\n            return promiseResolvedWith(undefined);\n        }\n        if (stream._state === 'errored') {\n            return promiseRejectedWith(stream._storedError);\n        }\n        ReadableStreamClose(stream);\n        const reader = stream._reader;\n        if (reader !== undefined && IsReadableStreamBYOBReader(reader)) {\n            reader._readIntoRequests.forEach(readIntoRequest => {\n                readIntoRequest._closeSteps(undefined);\n            });\n            reader._readIntoRequests = new SimpleQueue();\n        }\n        const sourceCancelPromise = stream._readableStreamController[CancelSteps](reason);\n        return transformPromiseWith(sourceCancelPromise, noop);\n    }\n    function ReadableStreamClose(stream) {\n        stream._state = 'closed';\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return;\n        }\n        defaultReaderClosedPromiseResolve(reader);\n        if (IsReadableStreamDefaultReader(reader)) {\n            reader._readRequests.forEach(readRequest => {\n                readRequest._closeSteps();\n            });\n            reader._readRequests = new SimpleQueue();\n        }\n    }\n    function ReadableStreamError(stream, e) {\n        stream._state = 'errored';\n        stream._storedError = e;\n        const reader = stream._reader;\n        if (reader === undefined) {\n            return;\n        }\n        defaultReaderClosedPromiseReject(reader, e);\n        if (IsReadableStreamDefaultReader(reader)) {\n            reader._readRequests.forEach(readRequest => {\n                readRequest._errorSteps(e);\n            });\n            reader._readRequests = new SimpleQueue();\n        }\n        else {\n            reader._readIntoRequests.forEach(readIntoRequest => {\n                readIntoRequest._errorSteps(e);\n            });\n            reader._readIntoRequests = new SimpleQueue();\n        }\n    }\n    // Helper functions for the ReadableStream.\n    function streamBrandCheckException$1(name) {\n        return new TypeError(`ReadableStream.prototype.${name} can only be used on a ReadableStream`);\n    }\n\n    function convertQueuingStrategyInit(init, context) {\n        assertDictionary(init, context);\n        const highWaterMark = init === null || init === void 0 ? void 0 : init.highWaterMark;\n        assertRequiredField(highWaterMark, 'highWaterMark', 'QueuingStrategyInit');\n        return {\n            highWaterMark: convertUnrestrictedDouble(highWaterMark)\n        };\n    }\n\n    // The size function must not have a prototype property nor be a constructor\n    const byteLengthSizeFunction = (chunk) => {\n        return chunk.byteLength;\n    };\n    try {\n        Object.defineProperty(byteLengthSizeFunction, 'name', {\n            value: 'size',\n            configurable: true\n        });\n    }\n    catch (_a) {\n        // This property is non-configurable in older browsers, so ignore if this throws.\n        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/name#browser_compatibility\n    }\n    /**\n     * A queuing strategy that counts the number of bytes in each chunk.\n     *\n     * @public\n     */\n    class ByteLengthQueuingStrategy {\n        constructor(options) {\n            assertRequiredArgument(options, 1, 'ByteLengthQueuingStrategy');\n            options = convertQueuingStrategyInit(options, 'First parameter');\n            this._byteLengthQueuingStrategyHighWaterMark = options.highWaterMark;\n        }\n        /**\n         * Returns the high water mark provided to the constructor.\n         */\n        get highWaterMark() {\n            if (!IsByteLengthQueuingStrategy(this)) {\n                throw byteLengthBrandCheckException('highWaterMark');\n            }\n            return this._byteLengthQueuingStrategyHighWaterMark;\n        }\n        /**\n         * Measures the size of `chunk` by returning the value of its `byteLength` property.\n         */\n        get size() {\n            if (!IsByteLengthQueuingStrategy(this)) {\n                throw byteLengthBrandCheckException('size');\n            }\n            return byteLengthSizeFunction;\n        }\n    }\n    Object.defineProperties(ByteLengthQueuingStrategy.prototype, {\n        highWaterMark: { enumerable: true },\n        size: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(ByteLengthQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n            value: 'ByteLengthQueuingStrategy',\n            configurable: true\n        });\n    }\n    // Helper functions for the ByteLengthQueuingStrategy.\n    function byteLengthBrandCheckException(name) {\n        return new TypeError(`ByteLengthQueuingStrategy.prototype.${name} can only be used on a ByteLengthQueuingStrategy`);\n    }\n    function IsByteLengthQueuingStrategy(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_byteLengthQueuingStrategyHighWaterMark')) {\n            return false;\n        }\n        return x instanceof ByteLengthQueuingStrategy;\n    }\n\n    // The size function must not have a prototype property nor be a constructor\n    const countSizeFunction = () => {\n        return 1;\n    };\n    try {\n        Object.defineProperty(countSizeFunction, 'name', {\n            value: 'size',\n            configurable: true\n        });\n    }\n    catch (_a) {\n        // This property is non-configurable in older browsers, so ignore if this throws.\n        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/name#browser_compatibility\n    }\n    /**\n     * A queuing strategy that counts the number of chunks.\n     *\n     * @public\n     */\n    class CountQueuingStrategy {\n        constructor(options) {\n            assertRequiredArgument(options, 1, 'CountQueuingStrategy');\n            options = convertQueuingStrategyInit(options, 'First parameter');\n            this._countQueuingStrategyHighWaterMark = options.highWaterMark;\n        }\n        /**\n         * Returns the high water mark provided to the constructor.\n         */\n        get highWaterMark() {\n            if (!IsCountQueuingStrategy(this)) {\n                throw countBrandCheckException('highWaterMark');\n            }\n            return this._countQueuingStrategyHighWaterMark;\n        }\n        /**\n         * Measures the size of `chunk` by always returning 1.\n         * This ensures that the total queue size is a count of the number of chunks in the queue.\n         */\n        get size() {\n            if (!IsCountQueuingStrategy(this)) {\n                throw countBrandCheckException('size');\n            }\n            return countSizeFunction;\n        }\n    }\n    Object.defineProperties(CountQueuingStrategy.prototype, {\n        highWaterMark: { enumerable: true },\n        size: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(CountQueuingStrategy.prototype, SymbolPolyfill.toStringTag, {\n            value: 'CountQueuingStrategy',\n            configurable: true\n        });\n    }\n    // Helper functions for the CountQueuingStrategy.\n    function countBrandCheckException(name) {\n        return new TypeError(`CountQueuingStrategy.prototype.${name} can only be used on a CountQueuingStrategy`);\n    }\n    function IsCountQueuingStrategy(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_countQueuingStrategyHighWaterMark')) {\n            return false;\n        }\n        return x instanceof CountQueuingStrategy;\n    }\n\n    function convertTransformer(original, context) {\n        assertDictionary(original, context);\n        const flush = original === null || original === void 0 ? void 0 : original.flush;\n        const readableType = original === null || original === void 0 ? void 0 : original.readableType;\n        const start = original === null || original === void 0 ? void 0 : original.start;\n        const transform = original === null || original === void 0 ? void 0 : original.transform;\n        const writableType = original === null || original === void 0 ? void 0 : original.writableType;\n        return {\n            flush: flush === undefined ?\n                undefined :\n                convertTransformerFlushCallback(flush, original, `${context} has member 'flush' that`),\n            readableType,\n            start: start === undefined ?\n                undefined :\n                convertTransformerStartCallback(start, original, `${context} has member 'start' that`),\n            transform: transform === undefined ?\n                undefined :\n                convertTransformerTransformCallback(transform, original, `${context} has member 'transform' that`),\n            writableType\n        };\n    }\n    function convertTransformerFlushCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => promiseCall(fn, original, [controller]);\n    }\n    function convertTransformerStartCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (controller) => reflectCall(fn, original, [controller]);\n    }\n    function convertTransformerTransformCallback(fn, original, context) {\n        assertFunction(fn, context);\n        return (chunk, controller) => promiseCall(fn, original, [chunk, controller]);\n    }\n\n    // Class TransformStream\n    /**\n     * A transform stream consists of a pair of streams: a {@link WritableStream | writable stream},\n     * known as its writable side, and a {@link ReadableStream | readable stream}, known as its readable side.\n     * In a manner specific to the transform stream in question, writes to the writable side result in new data being\n     * made available for reading from the readable side.\n     *\n     * @public\n     */\n    class TransformStream {\n        constructor(rawTransformer = {}, rawWritableStrategy = {}, rawReadableStrategy = {}) {\n            if (rawTransformer === undefined) {\n                rawTransformer = null;\n            }\n            const writableStrategy = convertQueuingStrategy(rawWritableStrategy, 'Second parameter');\n            const readableStrategy = convertQueuingStrategy(rawReadableStrategy, 'Third parameter');\n            const transformer = convertTransformer(rawTransformer, 'First parameter');\n            if (transformer.readableType !== undefined) {\n                throw new RangeError('Invalid readableType specified');\n            }\n            if (transformer.writableType !== undefined) {\n                throw new RangeError('Invalid writableType specified');\n            }\n            const readableHighWaterMark = ExtractHighWaterMark(readableStrategy, 0);\n            const readableSizeAlgorithm = ExtractSizeAlgorithm(readableStrategy);\n            const writableHighWaterMark = ExtractHighWaterMark(writableStrategy, 1);\n            const writableSizeAlgorithm = ExtractSizeAlgorithm(writableStrategy);\n            let startPromise_resolve;\n            const startPromise = newPromise(resolve => {\n                startPromise_resolve = resolve;\n            });\n            InitializeTransformStream(this, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n            SetUpTransformStreamDefaultControllerFromTransformer(this, transformer);\n            if (transformer.start !== undefined) {\n                startPromise_resolve(transformer.start(this._transformStreamController));\n            }\n            else {\n                startPromise_resolve(undefined);\n            }\n        }\n        /**\n         * The readable side of the transform stream.\n         */\n        get readable() {\n            if (!IsTransformStream(this)) {\n                throw streamBrandCheckException('readable');\n            }\n            return this._readable;\n        }\n        /**\n         * The writable side of the transform stream.\n         */\n        get writable() {\n            if (!IsTransformStream(this)) {\n                throw streamBrandCheckException('writable');\n            }\n            return this._writable;\n        }\n    }\n    Object.defineProperties(TransformStream.prototype, {\n        readable: { enumerable: true },\n        writable: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(TransformStream.prototype, SymbolPolyfill.toStringTag, {\n            value: 'TransformStream',\n            configurable: true\n        });\n    }\n    function InitializeTransformStream(stream, startPromise, writableHighWaterMark, writableSizeAlgorithm, readableHighWaterMark, readableSizeAlgorithm) {\n        function startAlgorithm() {\n            return startPromise;\n        }\n        function writeAlgorithm(chunk) {\n            return TransformStreamDefaultSinkWriteAlgorithm(stream, chunk);\n        }\n        function abortAlgorithm(reason) {\n            return TransformStreamDefaultSinkAbortAlgorithm(stream, reason);\n        }\n        function closeAlgorithm() {\n            return TransformStreamDefaultSinkCloseAlgorithm(stream);\n        }\n        stream._writable = CreateWritableStream(startAlgorithm, writeAlgorithm, closeAlgorithm, abortAlgorithm, writableHighWaterMark, writableSizeAlgorithm);\n        function pullAlgorithm() {\n            return TransformStreamDefaultSourcePullAlgorithm(stream);\n        }\n        function cancelAlgorithm(reason) {\n            TransformStreamErrorWritableAndUnblockWrite(stream, reason);\n            return promiseResolvedWith(undefined);\n        }\n        stream._readable = CreateReadableStream(startAlgorithm, pullAlgorithm, cancelAlgorithm, readableHighWaterMark, readableSizeAlgorithm);\n        // The [[backpressure]] slot is set to undefined so that it can be initialised by TransformStreamSetBackpressure.\n        stream._backpressure = undefined;\n        stream._backpressureChangePromise = undefined;\n        stream._backpressureChangePromise_resolve = undefined;\n        TransformStreamSetBackpressure(stream, true);\n        stream._transformStreamController = undefined;\n    }\n    function IsTransformStream(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_transformStreamController')) {\n            return false;\n        }\n        return x instanceof TransformStream;\n    }\n    // This is a no-op if both sides are already errored.\n    function TransformStreamError(stream, e) {\n        ReadableStreamDefaultControllerError(stream._readable._readableStreamController, e);\n        TransformStreamErrorWritableAndUnblockWrite(stream, e);\n    }\n    function TransformStreamErrorWritableAndUnblockWrite(stream, e) {\n        TransformStreamDefaultControllerClearAlgorithms(stream._transformStreamController);\n        WritableStreamDefaultControllerErrorIfNeeded(stream._writable._writableStreamController, e);\n        if (stream._backpressure) {\n            // Pretend that pull() was called to permit any pending write() calls to complete. TransformStreamSetBackpressure()\n            // cannot be called from enqueue() or pull() once the ReadableStream is errored, so this will will be the final time\n            // _backpressure is set.\n            TransformStreamSetBackpressure(stream, false);\n        }\n    }\n    function TransformStreamSetBackpressure(stream, backpressure) {\n        // Passes also when called during construction.\n        if (stream._backpressureChangePromise !== undefined) {\n            stream._backpressureChangePromise_resolve();\n        }\n        stream._backpressureChangePromise = newPromise(resolve => {\n            stream._backpressureChangePromise_resolve = resolve;\n        });\n        stream._backpressure = backpressure;\n    }\n    // Class TransformStreamDefaultController\n    /**\n     * Allows control of the {@link ReadableStream} and {@link WritableStream} of the associated {@link TransformStream}.\n     *\n     * @public\n     */\n    class TransformStreamDefaultController {\n        constructor() {\n            throw new TypeError('Illegal constructor');\n        }\n        /**\n         * Returns the desired size to fill the readable sideâs internal queue. It can be negative, if the queue is over-full.\n         */\n        get desiredSize() {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('desiredSize');\n            }\n            const readableController = this._controlledTransformStream._readable._readableStreamController;\n            return ReadableStreamDefaultControllerGetDesiredSize(readableController);\n        }\n        enqueue(chunk = undefined) {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('enqueue');\n            }\n            TransformStreamDefaultControllerEnqueue(this, chunk);\n        }\n        /**\n         * Errors both the readable side and the writable side of the controlled transform stream, making all future\n         * interactions with it fail with the given error `e`. Any chunks queued for transformation will be discarded.\n         */\n        error(reason = undefined) {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('error');\n            }\n            TransformStreamDefaultControllerError(this, reason);\n        }\n        /**\n         * Closes the readable side and errors the writable side of the controlled transform stream. This is useful when the\n         * transformer only needs to consume a portion of the chunks written to the writable side.\n         */\n        terminate() {\n            if (!IsTransformStreamDefaultController(this)) {\n                throw defaultControllerBrandCheckException('terminate');\n            }\n            TransformStreamDefaultControllerTerminate(this);\n        }\n    }\n    Object.defineProperties(TransformStreamDefaultController.prototype, {\n        enqueue: { enumerable: true },\n        error: { enumerable: true },\n        terminate: { enumerable: true },\n        desiredSize: { enumerable: true }\n    });\n    if (typeof SymbolPolyfill.toStringTag === 'symbol') {\n        Object.defineProperty(TransformStreamDefaultController.prototype, SymbolPolyfill.toStringTag, {\n            value: 'TransformStreamDefaultController',\n            configurable: true\n        });\n    }\n    // Transform Stream Default Controller Abstract Operations\n    function IsTransformStreamDefaultController(x) {\n        if (!typeIsObject(x)) {\n            return false;\n        }\n        if (!Object.prototype.hasOwnProperty.call(x, '_controlledTransformStream')) {\n            return false;\n        }\n        return x instanceof TransformStreamDefaultController;\n    }\n    function SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm) {\n        controller._controlledTransformStream = stream;\n        stream._transformStreamController = controller;\n        controller._transformAlgorithm = transformAlgorithm;\n        controller._flushAlgorithm = flushAlgorithm;\n    }\n    function SetUpTransformStreamDefaultControllerFromTransformer(stream, transformer) {\n        const controller = Object.create(TransformStreamDefaultController.prototype);\n        let transformAlgorithm = (chunk) => {\n            try {\n                TransformStreamDefaultControllerEnqueue(controller, chunk);\n                return promiseResolvedWith(undefined);\n            }\n            catch (transformResultE) {\n                return promiseRejectedWith(transformResultE);\n            }\n        };\n        let flushAlgorithm = () => promiseResolvedWith(undefined);\n        if (transformer.transform !== undefined) {\n            transformAlgorithm = chunk => transformer.transform(chunk, controller);\n        }\n        if (transformer.flush !== undefined) {\n            flushAlgorithm = () => transformer.flush(controller);\n        }\n        SetUpTransformStreamDefaultController(stream, controller, transformAlgorithm, flushAlgorithm);\n    }\n    function TransformStreamDefaultControllerClearAlgorithms(controller) {\n        controller._transformAlgorithm = undefined;\n        controller._flushAlgorithm = undefined;\n    }\n    function TransformStreamDefaultControllerEnqueue(controller, chunk) {\n        const stream = controller._controlledTransformStream;\n        const readableController = stream._readable._readableStreamController;\n        if (!ReadableStreamDefaultControllerCanCloseOrEnqueue(readableController)) {\n            throw new TypeError('Readable side is not in a state that permits enqueue');\n        }\n        // We throttle transform invocations based on the backpressure of the ReadableStream, but we still\n        // accept TransformStreamDefaultControllerEnqueue() calls.\n        try {\n            ReadableStreamDefaultControllerEnqueue(readableController, chunk);\n        }\n        catch (e) {\n            // This happens when readableStrategy.size() throws.\n            TransformStreamErrorWritableAndUnblockWrite(stream, e);\n            throw stream._readable._storedError;\n        }\n        const backpressure = ReadableStreamDefaultControllerHasBackpressure(readableController);\n        if (backpressure !== stream._backpressure) {\n            TransformStreamSetBackpressure(stream, true);\n        }\n    }\n    function TransformStreamDefaultControllerError(controller, e) {\n        TransformStreamError(controller._controlledTransformStream, e);\n    }\n    function TransformStreamDefaultControllerPerformTransform(controller, chunk) {\n        const transformPromise = controller._transformAlgorithm(chunk);\n        return transformPromiseWith(transformPromise, undefined, r => {\n            TransformStreamError(controller._controlledTransformStream, r);\n            throw r;\n        });\n    }\n    function TransformStreamDefaultControllerTerminate(controller) {\n        const stream = controller._controlledTransformStream;\n        const readableController = stream._readable._readableStreamController;\n        ReadableStreamDefaultControllerClose(readableController);\n        const error = new TypeError('TransformStream terminated');\n        TransformStreamErrorWritableAndUnblockWrite(stream, error);\n    }\n    // TransformStreamDefaultSink Algorithms\n    function TransformStreamDefaultSinkWriteAlgorithm(stream, chunk) {\n        const controller = stream._transformStreamController;\n        if (stream._backpressure) {\n            const backpressureChangePromise = stream._backpressureChangePromise;\n            return transformPromiseWith(backpressureChangePromise, () => {\n                const writable = stream._writable;\n                const state = writable._state;\n                if (state === 'erroring') {\n                    throw writable._storedError;\n                }\n                return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n            });\n        }\n        return TransformStreamDefaultControllerPerformTransform(controller, chunk);\n    }\n    function TransformStreamDefaultSinkAbortAlgorithm(stream, reason) {\n        // abort() is not called synchronously, so it is possible for abort() to be called when the stream is already\n        // errored.\n        TransformStreamError(stream, reason);\n        return promiseResolvedWith(undefined);\n    }\n    function TransformStreamDefaultSinkCloseAlgorithm(stream) {\n        // stream._readable cannot change after construction, so caching it across a call to user code is safe.\n        const readable = stream._readable;\n        const controller = stream._transformStreamController;\n        const flushPromise = controller._flushAlgorithm();\n        TransformStreamDefaultControllerClearAlgorithms(controller);\n        // Return a promise that is fulfilled with undefined on success.\n        return transformPromiseWith(flushPromise, () => {\n            if (readable._state === 'errored') {\n                throw readable._storedError;\n            }\n            ReadableStreamDefaultControllerClose(readable._readableStreamController);\n        }, r => {\n            TransformStreamError(stream, r);\n            throw readable._storedError;\n        });\n    }\n    // TransformStreamDefaultSource Algorithms\n    function TransformStreamDefaultSourcePullAlgorithm(stream) {\n        // Invariant. Enforced by the promises returned by start() and pull().\n        TransformStreamSetBackpressure(stream, false);\n        // Prevent the next pull() call until there is backpressure.\n        return stream._backpressureChangePromise;\n    }\n    // Helper functions for the TransformStreamDefaultController.\n    function defaultControllerBrandCheckException(name) {\n        return new TypeError(`TransformStreamDefaultController.prototype.${name} can only be used on a TransformStreamDefaultController`);\n    }\n    // Helper functions for the TransformStream.\n    function streamBrandCheckException(name) {\n        return new TypeError(`TransformStream.prototype.${name} can only be used on a TransformStream`);\n    }\n\n    exports.ByteLengthQueuingStrategy = ByteLengthQueuingStrategy;\n    exports.CountQueuingStrategy = CountQueuingStrategy;\n    exports.ReadableByteStreamController = ReadableByteStreamController;\n    exports.ReadableStream = ReadableStream;\n    exports.ReadableStreamBYOBReader = ReadableStreamBYOBReader;\n    exports.ReadableStreamBYOBRequest = ReadableStreamBYOBRequest;\n    exports.ReadableStreamDefaultController = ReadableStreamDefaultController;\n    exports.ReadableStreamDefaultReader = ReadableStreamDefaultReader;\n    exports.TransformStream = TransformStream;\n    exports.TransformStreamDefaultController = TransformStreamDefaultController;\n    exports.WritableStream = WritableStream;\n    exports.WritableStreamDefaultController = WritableStreamDefaultController;\n    exports.WritableStreamDefaultWriter = WritableStreamDefaultWriter;\n\n    Object.defineProperty(exports, '__esModule', { value: true });\n\n})));\n//# sourceMappingURL=ponyfill.es2018.js.map\n\n\n//# sourceURL=webpack://next-work/./node_modules/web-streams-polyfill/dist/ponyfill.es2018.js?");

/***/ }),

/***/ "buffer":
/*!*************************!*\
  !*** external "buffer" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("buffer");

/***/ }),

/***/ "crypto":
/*!*************************!*\
  !*** external "crypto" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("crypto");

/***/ }),

/***/ "node:buffer":
/*!******************************!*\
  !*** external "node:buffer" ***!
  \******************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:buffer");

/***/ }),

/***/ "node:fs":
/*!**************************!*\
  !*** external "node:fs" ***!
  \**************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:fs");

/***/ }),

/***/ "node:http":
/*!****************************!*\
  !*** external "node:http" ***!
  \****************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:http");

/***/ }),

/***/ "node:https":
/*!*****************************!*\
  !*** external "node:https" ***!
  \*****************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:https");

/***/ }),

/***/ "node:net":
/*!***************************!*\
  !*** external "node:net" ***!
  \***************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:net");

/***/ }),

/***/ "node:path":
/*!****************************!*\
  !*** external "node:path" ***!
  \****************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:path");

/***/ }),

/***/ "node:process":
/*!*******************************!*\
  !*** external "node:process" ***!
  \*******************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:process");

/***/ }),

/***/ "node:stream":
/*!******************************!*\
  !*** external "node:stream" ***!
  \******************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:stream");

/***/ }),

/***/ "node:stream/web":
/*!**********************************!*\
  !*** external "node:stream/web" ***!
  \**********************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:stream/web");

/***/ }),

/***/ "node:url":
/*!***************************!*\
  !*** external "node:url" ***!
  \***************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:url");

/***/ }),

/***/ "node:util":
/*!****************************!*\
  !*** external "node:util" ***!
  \****************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:util");

/***/ }),

/***/ "node:zlib":
/*!****************************!*\
  !*** external "node:zlib" ***!
  \****************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:zlib");

/***/ }),

/***/ "worker_threads":
/*!*********************************!*\
  !*** external "worker_threads" ***!
  \*********************************/
/***/ ((module) => {

"use strict";
module.exports = require("worker_threads");

/***/ }),

/***/ "./node_modules/fetch-blob/streams.cjs":
/*!*********************************************!*\
  !*** ./node_modules/fetch-blob/streams.cjs ***!
  \*********************************************/
/***/ ((__unused_webpack_module, __unused_webpack_exports, __webpack_require__) => {

eval("/* c8 ignore start */\n// 64 KiB (same size chrome slice theirs blob into Uint8array's)\nconst POOL_SIZE = 65536\n\nif (!globalThis.ReadableStream) {\n  // `node:stream/web` got introduced in v16.5.0 as experimental\n  // and it's preferred over the polyfilled version. So we also\n  // suppress the warning that gets emitted by NodeJS for using it.\n  try {\n    const process = __webpack_require__(/*! node:process */ \"node:process\")\n    const { emitWarning } = process\n    try {\n      process.emitWarning = () => {}\n      Object.assign(globalThis, __webpack_require__(/*! node:stream/web */ \"node:stream/web\"))\n      process.emitWarning = emitWarning\n    } catch (error) {\n      process.emitWarning = emitWarning\n      throw error\n    }\n  } catch (error) {\n    // fallback to polyfill implementation\n    Object.assign(globalThis, __webpack_require__(/*! web-streams-polyfill/dist/ponyfill.es2018.js */ \"./node_modules/web-streams-polyfill/dist/ponyfill.es2018.js\"))\n  }\n}\n\ntry {\n  // Don't use node: prefix for this, require+node: is not supported until node v14.14\n  // Only `import()` can use prefix in 12.20 and later\n  const { Blob } = __webpack_require__(/*! buffer */ \"buffer\")\n  if (Blob && !Blob.prototype.stream) {\n    Blob.prototype.stream = function name (params) {\n      let position = 0\n      const blob = this\n\n      return new ReadableStream({\n        type: 'bytes',\n        async pull (ctrl) {\n          const chunk = blob.slice(position, Math.min(blob.size, position + POOL_SIZE))\n          const buffer = await chunk.arrayBuffer()\n          position += buffer.byteLength\n          ctrl.enqueue(new Uint8Array(buffer))\n\n          if (position === blob.size) {\n            ctrl.close()\n          }\n        }\n      })\n    }\n  }\n} catch (error) {}\n/* c8 ignore end */\n\n\n//# sourceURL=webpack://next-work/./node_modules/fetch-blob/streams.cjs?");

/***/ }),

/***/ "./node_modules/data-uri-to-buffer/dist/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/data-uri-to-buffer/dist/index.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"dataUriToBuffer\": () => (/* binding */ dataUriToBuffer),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/**\n * Returns a `Buffer` instance from the given data URI `uri`.\n *\n * @param {String} uri Data URI to turn into a Buffer instance\n * @returns {Buffer} Buffer instance from Data URI\n * @api public\n */\nfunction dataUriToBuffer(uri) {\n    if (!/^data:/i.test(uri)) {\n        throw new TypeError('`uri` does not appear to be a Data URI (must begin with \"data:\")');\n    }\n    // strip newlines\n    uri = uri.replace(/\\r?\\n/g, '');\n    // split the URI up into the \"metadata\" and the \"data\" portions\n    const firstComma = uri.indexOf(',');\n    if (firstComma === -1 || firstComma <= 4) {\n        throw new TypeError('malformed data: URI');\n    }\n    // remove the \"data:\" scheme and parse the metadata\n    const meta = uri.substring(5, firstComma).split(';');\n    let charset = '';\n    let base64 = false;\n    const type = meta[0] || 'text/plain';\n    let typeFull = type;\n    for (let i = 1; i < meta.length; i++) {\n        if (meta[i] === 'base64') {\n            base64 = true;\n        }\n        else if (meta[i]) {\n            typeFull += `;${meta[i]}`;\n            if (meta[i].indexOf('charset=') === 0) {\n                charset = meta[i].substring(8);\n            }\n        }\n    }\n    // defaults to US-ASCII only if type is not provided\n    if (!meta[0] && !charset.length) {\n        typeFull += ';charset=US-ASCII';\n        charset = 'US-ASCII';\n    }\n    // get the encoded data portion and decode URI-encoded chars\n    const encoding = base64 ? 'base64' : 'ascii';\n    const data = unescape(uri.substring(firstComma + 1));\n    const buffer = Buffer.from(data, encoding);\n    // set `.type` and `.typeFull` properties to MIME type\n    buffer.type = type;\n    buffer.typeFull = typeFull;\n    // set the `.charset` property\n    buffer.charset = charset;\n    return buffer;\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (dataUriToBuffer);\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://next-work/./node_modules/data-uri-to-buffer/dist/index.js?");

/***/ }),

/***/ "./node_modules/decode-uri-component/index.js":
/*!****************************************************!*\
  !*** ./node_modules/decode-uri-component/index.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ decodeUriComponent)\n/* harmony export */ });\nconst token = '%[a-f0-9]{2}';\nconst singleMatcher = new RegExp('(' + token + ')|([^%]+?)', 'gi');\nconst multiMatcher = new RegExp('(' + token + ')+', 'gi');\n\nfunction decodeComponents(components, split) {\n\ttry {\n\t\t// Try to decode the entire string first\n\t\treturn [decodeURIComponent(components.join(''))];\n\t} catch {\n\t\t// Do nothing\n\t}\n\n\tif (components.length === 1) {\n\t\treturn components;\n\t}\n\n\tsplit = split || 1;\n\n\t// Split the array in 2 parts\n\tconst left = components.slice(0, split);\n\tconst right = components.slice(split);\n\n\treturn Array.prototype.concat.call([], decodeComponents(left), decodeComponents(right));\n}\n\nfunction decode(input) {\n\ttry {\n\t\treturn decodeURIComponent(input);\n\t} catch {\n\t\tlet tokens = input.match(singleMatcher) || [];\n\n\t\tfor (let i = 1; i < tokens.length; i++) {\n\t\t\tinput = decodeComponents(tokens, i).join('');\n\n\t\t\ttokens = input.match(singleMatcher) || [];\n\t\t}\n\n\t\treturn input;\n\t}\n}\n\nfunction customDecodeURIComponent(input) {\n\t// Keep track of all the replacements and prefill the map with the `BOM`\n\tconst replaceMap = {\n\t\t'%FE%FF': '\\uFFFD\\uFFFD',\n\t\t'%FF%FE': '\\uFFFD\\uFFFD',\n\t};\n\n\tlet match = multiMatcher.exec(input);\n\twhile (match) {\n\t\ttry {\n\t\t\t// Decode as big chunks as possible\n\t\t\treplaceMap[match[0]] = decodeURIComponent(match[0]);\n\t\t} catch {\n\t\t\tconst result = decode(match[0]);\n\n\t\t\tif (result !== match[0]) {\n\t\t\t\treplaceMap[match[0]] = result;\n\t\t\t}\n\t\t}\n\n\t\tmatch = multiMatcher.exec(input);\n\t}\n\n\t// Add `%C2` at the end of the map to make sure it does not replace the combinator before everything else\n\treplaceMap['%C2'] = '\\uFFFD';\n\n\tconst entries = Object.keys(replaceMap);\n\n\tfor (const key of entries) {\n\t\t// Replace all decoded components\n\t\tinput = input.replace(new RegExp(key, 'g'), replaceMap[key]);\n\t}\n\n\treturn input;\n}\n\nfunction decodeUriComponent(encodedURI) {\n\tif (typeof encodedURI !== 'string') {\n\t\tthrow new TypeError('Expected `encodedURI` to be of type `string`, got `' + typeof encodedURI + '`');\n\t}\n\n\ttry {\n\t\t// Try the built in decoder first\n\t\treturn decodeURIComponent(encodedURI);\n\t} catch {\n\t\t// Fallback to a more advanced decoder\n\t\treturn customDecodeURIComponent(encodedURI);\n\t}\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/decode-uri-component/index.js?");

/***/ }),

/***/ "./node_modules/fetch-blob/file.js":
/*!*****************************************!*\
  !*** ./node_modules/fetch-blob/file.js ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"File\": () => (/* binding */ File),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./index.js */ \"./node_modules/fetch-blob/index.js\");\n\n\nconst _File = class File extends _index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  #lastModified = 0\n  #name = ''\n\n  /**\n   * @param {*[]} fileBits\n   * @param {string} fileName\n   * @param {{lastModified?: number, type?: string}} options\n   */// @ts-ignore\n  constructor (fileBits, fileName, options = {}) {\n    if (arguments.length < 2) {\n      throw new TypeError(`Failed to construct 'File': 2 arguments required, but only ${arguments.length} present.`)\n    }\n    super(fileBits, options)\n\n    if (options === null) options = {}\n\n    // Simulate WebIDL type casting for NaN value in lastModified option.\n    const lastModified = options.lastModified === undefined ? Date.now() : Number(options.lastModified)\n    if (!Number.isNaN(lastModified)) {\n      this.#lastModified = lastModified\n    }\n\n    this.#name = String(fileName)\n  }\n\n  get name () {\n    return this.#name\n  }\n\n  get lastModified () {\n    return this.#lastModified\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'File'\n  }\n\n  static [Symbol.hasInstance] (object) {\n    return !!object && object instanceof _index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] &&\n      /^(File)$/.test(object[Symbol.toStringTag])\n  }\n}\n\n/** @type {typeof globalThis.File} */// @ts-ignore\nconst File = _File\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (File);\n\n\n//# sourceURL=webpack://next-work/./node_modules/fetch-blob/file.js?");

/***/ }),

/***/ "./node_modules/fetch-blob/from.js":
/*!*****************************************!*\
  !*** ./node_modules/fetch-blob/from.js ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Blob\": () => (/* reexport safe */ _index_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]),\n/* harmony export */   \"File\": () => (/* reexport safe */ _file_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]),\n/* harmony export */   \"blobFrom\": () => (/* binding */ blobFrom),\n/* harmony export */   \"blobFromSync\": () => (/* binding */ blobFromSync),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   \"fileFrom\": () => (/* binding */ fileFrom),\n/* harmony export */   \"fileFromSync\": () => (/* binding */ fileFromSync)\n/* harmony export */ });\n/* harmony import */ var node_fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:fs */ \"node:fs\");\n/* harmony import */ var node_path__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:path */ \"node:path\");\n/* harmony import */ var node_domexception__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! node-domexception */ \"./node_modules/node-domexception/index.js\");\n/* harmony import */ var _file_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./file.js */ \"./node_modules/fetch-blob/file.js\");\n/* harmony import */ var _index_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./index.js */ \"./node_modules/fetch-blob/index.js\");\n\n\n\n\n\n\n\nconst { stat } = node_fs__WEBPACK_IMPORTED_MODULE_0__.promises\n\n/**\n * @param {string} path filepath on the disk\n * @param {string} [type] mimetype to use\n */\nconst blobFromSync = (path, type) => fromBlob((0,node_fs__WEBPACK_IMPORTED_MODULE_0__.statSync)(path), path, type)\n\n/**\n * @param {string} path filepath on the disk\n * @param {string} [type] mimetype to use\n * @returns {Promise<Blob>}\n */\nconst blobFrom = (path, type) => stat(path).then(stat => fromBlob(stat, path, type))\n\n/**\n * @param {string} path filepath on the disk\n * @param {string} [type] mimetype to use\n * @returns {Promise<File>}\n */\nconst fileFrom = (path, type) => stat(path).then(stat => fromFile(stat, path, type))\n\n/**\n * @param {string} path filepath on the disk\n * @param {string} [type] mimetype to use\n */\nconst fileFromSync = (path, type) => fromFile((0,node_fs__WEBPACK_IMPORTED_MODULE_0__.statSync)(path), path, type)\n\n// @ts-ignore\nconst fromBlob = (stat, path, type = '') => new _index_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]([new BlobDataItem({\n  path,\n  size: stat.size,\n  lastModified: stat.mtimeMs,\n  start: 0\n})], { type })\n\n// @ts-ignore\nconst fromFile = (stat, path, type = '') => new _file_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]([new BlobDataItem({\n  path,\n  size: stat.size,\n  lastModified: stat.mtimeMs,\n  start: 0\n})], (0,node_path__WEBPACK_IMPORTED_MODULE_1__.basename)(path), { type, lastModified: stat.mtimeMs })\n\n/**\n * This is a blob backed up by a file on the disk\n * with minium requirement. Its wrapped around a Blob as a blobPart\n * so you have no direct access to this.\n *\n * @private\n */\nclass BlobDataItem {\n  #path\n  #start\n\n  constructor (options) {\n    this.#path = options.path\n    this.#start = options.start\n    this.size = options.size\n    this.lastModified = options.lastModified\n  }\n\n  /**\n   * Slicing arguments is first validated and formatted\n   * to not be out of range by Blob.prototype.slice\n   */\n  slice (start, end) {\n    return new BlobDataItem({\n      path: this.#path,\n      lastModified: this.lastModified,\n      size: end - start,\n      start: this.#start + start\n    })\n  }\n\n  async * stream () {\n    const { mtimeMs } = await stat(this.#path)\n    if (mtimeMs > this.lastModified) {\n      throw new node_domexception__WEBPACK_IMPORTED_MODULE_2__('The requested file could not be read, typically due to permission problems that have occurred after a reference to a file was acquired.', 'NotReadableError')\n    }\n    yield * (0,node_fs__WEBPACK_IMPORTED_MODULE_0__.createReadStream)(this.#path, {\n      start: this.#start,\n      end: this.#start + this.size - 1\n    })\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'Blob'\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (blobFromSync);\n\n\n\n//# sourceURL=webpack://next-work/./node_modules/fetch-blob/from.js?");

/***/ }),

/***/ "./node_modules/fetch-blob/index.js":
/*!******************************************!*\
  !*** ./node_modules/fetch-blob/index.js ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Blob\": () => (/* binding */ Blob),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _streams_cjs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./streams.cjs */ \"./node_modules/fetch-blob/streams.cjs\");\n/*! fetch-blob. MIT License. Jimmy WÃ¤rting <https://jimmy.warting.se/opensource> */\n\n// TODO (jimmywarting): in the feature use conditional loading with top level await (requires 14.x)\n// Node has recently added whatwg stream into core\n\n\n\n// 64 KiB (same size chrome slice theirs blob into Uint8array's)\nconst POOL_SIZE = 65536\n\n/** @param {(Blob | Uint8Array)[]} parts */\nasync function * toIterator (parts, clone = true) {\n  for (const part of parts) {\n    if ('stream' in part) {\n      yield * (/** @type {AsyncIterableIterator<Uint8Array>} */ (part.stream()))\n    } else if (ArrayBuffer.isView(part)) {\n      if (clone) {\n        let position = part.byteOffset\n        const end = part.byteOffset + part.byteLength\n        while (position !== end) {\n          const size = Math.min(end - position, POOL_SIZE)\n          const chunk = part.buffer.slice(position, position + size)\n          position += chunk.byteLength\n          yield new Uint8Array(chunk)\n        }\n      } else {\n        yield part\n      }\n    /* c8 ignore next 10 */\n    } else {\n      // For blobs that have arrayBuffer but no stream method (nodes buffer.Blob)\n      let position = 0, b = (/** @type {Blob} */ (part))\n      while (position !== b.size) {\n        const chunk = b.slice(position, Math.min(b.size, position + POOL_SIZE))\n        const buffer = await chunk.arrayBuffer()\n        position += buffer.byteLength\n        yield new Uint8Array(buffer)\n      }\n    }\n  }\n}\n\nconst _Blob = class Blob {\n  /** @type {Array.<(Blob|Uint8Array)>} */\n  #parts = []\n  #type = ''\n  #size = 0\n  #endings = 'transparent'\n\n  /**\n   * The Blob() constructor returns a new Blob object. The content\n   * of the blob consists of the concatenation of the values given\n   * in the parameter array.\n   *\n   * @param {*} blobParts\n   * @param {{ type?: string, endings?: string }} [options]\n   */\n  constructor (blobParts = [], options = {}) {\n    if (typeof blobParts !== 'object' || blobParts === null) {\n      throw new TypeError('Failed to construct \\'Blob\\': The provided value cannot be converted to a sequence.')\n    }\n\n    if (typeof blobParts[Symbol.iterator] !== 'function') {\n      throw new TypeError('Failed to construct \\'Blob\\': The object must have a callable @@iterator property.')\n    }\n\n    if (typeof options !== 'object' && typeof options !== 'function') {\n      throw new TypeError('Failed to construct \\'Blob\\': parameter 2 cannot convert to dictionary.')\n    }\n\n    if (options === null) options = {}\n\n    const encoder = new TextEncoder()\n    for (const element of blobParts) {\n      let part\n      if (ArrayBuffer.isView(element)) {\n        part = new Uint8Array(element.buffer.slice(element.byteOffset, element.byteOffset + element.byteLength))\n      } else if (element instanceof ArrayBuffer) {\n        part = new Uint8Array(element.slice(0))\n      } else if (element instanceof Blob) {\n        part = element\n      } else {\n        part = encoder.encode(`${element}`)\n      }\n\n      this.#size += ArrayBuffer.isView(part) ? part.byteLength : part.size\n      this.#parts.push(part)\n    }\n\n    this.#endings = `${options.endings === undefined ? 'transparent' : options.endings}`\n    const type = options.type === undefined ? '' : String(options.type)\n    this.#type = /^[\\x20-\\x7E]*$/.test(type) ? type : ''\n  }\n\n  /**\n   * The Blob interface's size property returns the\n   * size of the Blob in bytes.\n   */\n  get size () {\n    return this.#size\n  }\n\n  /**\n   * The type property of a Blob object returns the MIME type of the file.\n   */\n  get type () {\n    return this.#type\n  }\n\n  /**\n   * The text() method in the Blob interface returns a Promise\n   * that resolves with a string containing the contents of\n   * the blob, interpreted as UTF-8.\n   *\n   * @return {Promise<string>}\n   */\n  async text () {\n    // More optimized than using this.arrayBuffer()\n    // that requires twice as much ram\n    const decoder = new TextDecoder()\n    let str = ''\n    for await (const part of toIterator(this.#parts, false)) {\n      str += decoder.decode(part, { stream: true })\n    }\n    // Remaining\n    str += decoder.decode()\n    return str\n  }\n\n  /**\n   * The arrayBuffer() method in the Blob interface returns a\n   * Promise that resolves with the contents of the blob as\n   * binary data contained in an ArrayBuffer.\n   *\n   * @return {Promise<ArrayBuffer>}\n   */\n  async arrayBuffer () {\n    // Easier way... Just a unnecessary overhead\n    // const view = new Uint8Array(this.size);\n    // await this.stream().getReader({mode: 'byob'}).read(view);\n    // return view.buffer;\n\n    const data = new Uint8Array(this.size)\n    let offset = 0\n    for await (const chunk of toIterator(this.#parts, false)) {\n      data.set(chunk, offset)\n      offset += chunk.length\n    }\n\n    return data.buffer\n  }\n\n  stream () {\n    const it = toIterator(this.#parts, true)\n\n    return new globalThis.ReadableStream({\n      // @ts-ignore\n      type: 'bytes',\n      async pull (ctrl) {\n        const chunk = await it.next()\n        chunk.done ? ctrl.close() : ctrl.enqueue(chunk.value)\n      },\n\n      async cancel () {\n        await it.return()\n      }\n    })\n  }\n\n  /**\n   * The Blob interface's slice() method creates and returns a\n   * new Blob object which contains data from a subset of the\n   * blob on which it's called.\n   *\n   * @param {number} [start]\n   * @param {number} [end]\n   * @param {string} [type]\n   */\n  slice (start = 0, end = this.size, type = '') {\n    const { size } = this\n\n    let relativeStart = start < 0 ? Math.max(size + start, 0) : Math.min(start, size)\n    let relativeEnd = end < 0 ? Math.max(size + end, 0) : Math.min(end, size)\n\n    const span = Math.max(relativeEnd - relativeStart, 0)\n    const parts = this.#parts\n    const blobParts = []\n    let added = 0\n\n    for (const part of parts) {\n      // don't add the overflow to new blobParts\n      if (added >= span) {\n        break\n      }\n\n      const size = ArrayBuffer.isView(part) ? part.byteLength : part.size\n      if (relativeStart && size <= relativeStart) {\n        // Skip the beginning and change the relative\n        // start & end position as we skip the unwanted parts\n        relativeStart -= size\n        relativeEnd -= size\n      } else {\n        let chunk\n        if (ArrayBuffer.isView(part)) {\n          chunk = part.subarray(relativeStart, Math.min(size, relativeEnd))\n          added += chunk.byteLength\n        } else {\n          chunk = part.slice(relativeStart, Math.min(size, relativeEnd))\n          added += chunk.size\n        }\n        relativeEnd -= size\n        blobParts.push(chunk)\n        relativeStart = 0 // All next sequential parts should start at 0\n      }\n    }\n\n    const blob = new Blob([], { type: String(type).toLowerCase() })\n    blob.#size = span\n    blob.#parts = blobParts\n\n    return blob\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'Blob'\n  }\n\n  static [Symbol.hasInstance] (object) {\n    return (\n      object &&\n      typeof object === 'object' &&\n      typeof object.constructor === 'function' &&\n      (\n        typeof object.stream === 'function' ||\n        typeof object.arrayBuffer === 'function'\n      ) &&\n      /^(Blob|File)$/.test(object[Symbol.toStringTag])\n    )\n  }\n}\n\nObject.defineProperties(_Blob.prototype, {\n  size: { enumerable: true },\n  type: { enumerable: true },\n  slice: { enumerable: true }\n})\n\n/** @type {typeof globalThis.Blob} */\nconst Blob = _Blob\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Blob);\n\n\n//# sourceURL=webpack://next-work/./node_modules/fetch-blob/index.js?");

/***/ }),

/***/ "./node_modules/filter-obj/index.js":
/*!******************************************!*\
  !*** ./node_modules/filter-obj/index.js ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"excludeKeys\": () => (/* binding */ excludeKeys),\n/* harmony export */   \"includeKeys\": () => (/* binding */ includeKeys)\n/* harmony export */ });\nfunction includeKeys(object, predicate) {\n\tconst result = {};\n\n\tif (Array.isArray(predicate)) {\n\t\tfor (const key of predicate) {\n\t\t\tconst descriptor = Object.getOwnPropertyDescriptor(object, key);\n\t\t\tif (descriptor?.enumerable) {\n\t\t\t\tObject.defineProperty(result, key, descriptor);\n\t\t\t}\n\t\t}\n\t} else {\n\t\t// `Reflect.ownKeys()` is required to retrieve symbol properties\n\t\tfor (const key of Reflect.ownKeys(object)) {\n\t\t\tconst descriptor = Object.getOwnPropertyDescriptor(object, key);\n\t\t\tif (descriptor.enumerable) {\n\t\t\t\tconst value = object[key];\n\t\t\t\tif (predicate(key, value, object)) {\n\t\t\t\t\tObject.defineProperty(result, key, descriptor);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}\n\nfunction excludeKeys(object, predicate) {\n\tif (Array.isArray(predicate)) {\n\t\tconst set = new Set(predicate);\n\t\treturn includeKeys(object, key => !set.has(key));\n\t}\n\n\treturn includeKeys(object, (key, value, object) => !predicate(key, value, object));\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/filter-obj/index.js?");

/***/ }),

/***/ "./node_modules/formdata-polyfill/esm.min.js":
/*!***************************************************!*\
  !*** ./node_modules/formdata-polyfill/esm.min.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"File\": () => (/* binding */ File),\n/* harmony export */   \"FormData\": () => (/* binding */ FormData),\n/* harmony export */   \"formDataToBlob\": () => (/* binding */ formDataToBlob)\n/* harmony export */ });\n/* harmony import */ var fetch_blob__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fetch-blob */ \"./node_modules/fetch-blob/index.js\");\n/* harmony import */ var fetch_blob_file_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! fetch-blob/file.js */ \"./node_modules/fetch-blob/file.js\");\n/*! formdata-polyfill. MIT License. Jimmy WÃ¤rting <https://jimmy.warting.se/opensource> */\n\n\n\n\nvar {toStringTag:t,iterator:i,hasInstance:h}=Symbol,\nr=Math.random,\nm='append,set,get,getAll,delete,keys,values,entries,forEach,constructor'.split(','),\nf=(a,b,c)=>(a+='',/^(Blob|File)$/.test(b && b[t])?[(c=c!==void 0?c+'':b[t]=='File'?b.name:'blob',a),b.name!==c||b[t]=='blob'?new fetch_blob_file_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]([b],c,b):b]:[a,b+'']),\ne=(c,f)=>(f?c:c.replace(/\\r?\\n|\\r/g,'\\r\\n')).replace(/\\n/g,'%0A').replace(/\\r/g,'%0D').replace(/\"/g,'%22'),\nx=(n, a, e)=>{if(a.length<e){throw new TypeError(`Failed to execute '${n}' on 'FormData': ${e} arguments required, but only ${a.length} present.`)}}\n\nconst File = fetch_blob_file_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]\n\n/** @type {typeof globalThis.FormData} */\nconst FormData = class FormData {\n#d=[];\nconstructor(...a){if(a.length)throw new TypeError(`Failed to construct 'FormData': parameter 1 is not of type 'HTMLFormElement'.`)}\nget [t]() {return 'FormData'}\n[i](){return this.entries()}\nstatic [h](o) {return o&&typeof o==='object'&&o[t]==='FormData'&&!m.some(m=>typeof o[m]!='function')}\nappend(...a){x('append',arguments,2);this.#d.push(f(...a))}\ndelete(a){x('delete',arguments,1);a+='';this.#d=this.#d.filter(([b])=>b!==a)}\nget(a){x('get',arguments,1);a+='';for(var b=this.#d,l=b.length,c=0;c<l;c++)if(b[c][0]===a)return b[c][1];return null}\ngetAll(a,b){x('getAll',arguments,1);b=[];a+='';this.#d.forEach(c=>c[0]===a&&b.push(c[1]));return b}\nhas(a){x('has',arguments,1);a+='';return this.#d.some(b=>b[0]===a)}\nforEach(a,b){x('forEach',arguments,1);for(var [c,d]of this)a.call(b,d,c,this)}\nset(...a){x('set',arguments,2);var b=[],c=!0;a=f(...a);this.#d.forEach(d=>{d[0]===a[0]?c&&(c=!b.push(a)):b.push(d)});c&&b.push(a);this.#d=b}\n*entries(){yield*this.#d}\n*keys(){for(var[a]of this)yield a}\n*values(){for(var[,a]of this)yield a}}\n\n/** @param {FormData} F */\nfunction formDataToBlob (F,B=fetch_blob__WEBPACK_IMPORTED_MODULE_0__[\"default\"]){\nvar b=`${r()}${r()}`.replace(/\\./g, '').slice(-28).padStart(32, '-'),c=[],p=`--${b}\\r\\nContent-Disposition: form-data; name=\"`\nF.forEach((v,n)=>typeof v=='string'\n?c.push(p+e(n)+`\"\\r\\n\\r\\n${v.replace(/\\r(?!\\n)|(?<!\\r)\\n/g, '\\r\\n')}\\r\\n`)\n:c.push(p+e(n)+`\"; filename=\"${e(v.name, 1)}\"\\r\\nContent-Type: ${v.type||\"application/octet-stream\"}\\r\\n\\r\\n`, v, '\\r\\n'))\nc.push(`--${b}--`)\nreturn new B(c,{type:\"multipart/form-data; boundary=\"+b})}\n\n\n//# sourceURL=webpack://next-work/./node_modules/formdata-polyfill/esm.min.js?");

/***/ }),

/***/ "./node_modules/nanoid/index.js":
/*!**************************************!*\
  !*** ./node_modules/nanoid/index.js ***!
  \**************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"customAlphabet\": () => (/* binding */ customAlphabet),\n/* harmony export */   \"customRandom\": () => (/* binding */ customRandom),\n/* harmony export */   \"nanoid\": () => (/* binding */ nanoid),\n/* harmony export */   \"random\": () => (/* binding */ random),\n/* harmony export */   \"urlAlphabet\": () => (/* reexport safe */ _url_alphabet_index_js__WEBPACK_IMPORTED_MODULE_1__.urlAlphabet)\n/* harmony export */ });\n/* harmony import */ var crypto__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! crypto */ \"crypto\");\n/* harmony import */ var _url_alphabet_index_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./url-alphabet/index.js */ \"./node_modules/nanoid/url-alphabet/index.js\");\n\n\n\nconst POOL_SIZE_MULTIPLIER = 128\nlet pool, poolOffset\nlet fillPool = bytes => {\n  if (!pool || pool.length < bytes) {\n    pool = Buffer.allocUnsafe(bytes * POOL_SIZE_MULTIPLIER)\n    ;(0,crypto__WEBPACK_IMPORTED_MODULE_0__.randomFillSync)(pool)\n    poolOffset = 0\n  } else if (poolOffset + bytes > pool.length) {\n    (0,crypto__WEBPACK_IMPORTED_MODULE_0__.randomFillSync)(pool)\n    poolOffset = 0\n  }\n  poolOffset += bytes\n}\nlet random = bytes => {\n  fillPool((bytes -= 0))\n  return pool.subarray(poolOffset - bytes, poolOffset)\n}\nlet customRandom = (alphabet, defaultSize, getRandom) => {\n  let mask = (2 << (31 - Math.clz32((alphabet.length - 1) | 1))) - 1\n  let step = Math.ceil((1.6 * mask * defaultSize) / alphabet.length)\n  return (size = defaultSize) => {\n    let id = ''\n    while (true) {\n      let bytes = getRandom(step)\n      let i = step\n      while (i--) {\n        id += alphabet[bytes[i] & mask] || ''\n        if (id.length === size) return id\n      }\n    }\n  }\n}\nlet customAlphabet = (alphabet, size = 21) =>\n  customRandom(alphabet, size, random)\nlet nanoid = (size = 21) => {\n  fillPool((size -= 0))\n  let id = ''\n  for (let i = poolOffset - size; i < poolOffset; i++) {\n    id += _url_alphabet_index_js__WEBPACK_IMPORTED_MODULE_1__.urlAlphabet[pool[i] & 63]\n  }\n  return id\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/nanoid/index.js?");

/***/ }),

/***/ "./node_modules/nanoid/url-alphabet/index.js":
/*!***************************************************!*\
  !*** ./node_modules/nanoid/url-alphabet/index.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"urlAlphabet\": () => (/* binding */ urlAlphabet)\n/* harmony export */ });\nconst urlAlphabet =\n  'useandom-26T198340PX75pxJACKVERYMINDBUSHWOLF_GQZbfghjklqvwyzrict'\n\n\n//# sourceURL=webpack://next-work/./node_modules/nanoid/url-alphabet/index.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/body.js":
/*!*********************************************!*\
  !*** ./node_modules/node-fetch/src/body.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"clone\": () => (/* binding */ clone),\n/* harmony export */   \"default\": () => (/* binding */ Body),\n/* harmony export */   \"extractContentType\": () => (/* binding */ extractContentType),\n/* harmony export */   \"getTotalBytes\": () => (/* binding */ getTotalBytes),\n/* harmony export */   \"writeToStream\": () => (/* binding */ writeToStream)\n/* harmony export */ });\n/* harmony import */ var node_stream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:stream */ \"node:stream\");\n/* harmony import */ var node_util__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:util */ \"node:util\");\n/* harmony import */ var node_buffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! node:buffer */ \"node:buffer\");\n/* harmony import */ var fetch_blob__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! fetch-blob */ \"./node_modules/fetch-blob/index.js\");\n/* harmony import */ var formdata_polyfill_esm_min_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! formdata-polyfill/esm.min.js */ \"./node_modules/formdata-polyfill/esm.min.js\");\n/* harmony import */ var _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./errors/fetch-error.js */ \"./node_modules/node-fetch/src/errors/fetch-error.js\");\n/* harmony import */ var _errors_base_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./errors/base.js */ \"./node_modules/node-fetch/src/errors/base.js\");\n/* harmony import */ var _utils_is_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./utils/is.js */ \"./node_modules/node-fetch/src/utils/is.js\");\n\n/**\n * Body.js\n *\n * Body interface provides common methods for Request and Response\n */\n\n\n\n\n\n\n\n\n\n\n\n\nconst pipeline = (0,node_util__WEBPACK_IMPORTED_MODULE_1__.promisify)(node_stream__WEBPACK_IMPORTED_MODULE_0__.pipeline);\nconst INTERNALS = Symbol('Body internals');\n\n/**\n * Body mixin\n *\n * Ref: https://fetch.spec.whatwg.org/#body\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nclass Body {\n\tconstructor(body, {\n\t\tsize = 0\n\t} = {}) {\n\t\tlet boundary = null;\n\n\t\tif (body === null) {\n\t\t\t// Body is undefined or null\n\t\t\tbody = null;\n\t\t} else if ((0,_utils_is_js__WEBPACK_IMPORTED_MODULE_5__.isURLSearchParameters)(body)) {\n\t\t\t// Body is a URLSearchParams\n\t\t\tbody = node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.from(body.toString());\n\t\t} else if ((0,_utils_is_js__WEBPACK_IMPORTED_MODULE_5__.isBlob)(body)) {\n\t\t\t// Body is blob\n\t\t} else if (node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.isBuffer(body)) {\n\t\t\t// Body is Buffer\n\t\t} else if (node_util__WEBPACK_IMPORTED_MODULE_1__.types.isAnyArrayBuffer(body)) {\n\t\t\t// Body is ArrayBuffer\n\t\t\tbody = node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.from(body);\n\t\t} else if (ArrayBuffer.isView(body)) {\n\t\t\t// Body is ArrayBufferView\n\t\t\tbody = node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.from(body.buffer, body.byteOffset, body.byteLength);\n\t\t} else if (body instanceof node_stream__WEBPACK_IMPORTED_MODULE_0__) {\n\t\t\t// Body is stream\n\t\t} else if (body instanceof formdata_polyfill_esm_min_js__WEBPACK_IMPORTED_MODULE_4__.FormData) {\n\t\t\t// Body is FormData\n\t\t\tbody = (0,formdata_polyfill_esm_min_js__WEBPACK_IMPORTED_MODULE_4__.formDataToBlob)(body);\n\t\t\tboundary = body.type.split('=')[1];\n\t\t} else {\n\t\t\t// None of the above\n\t\t\t// coerce to string then buffer\n\t\t\tbody = node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.from(String(body));\n\t\t}\n\n\t\tlet stream = body;\n\n\t\tif (node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.isBuffer(body)) {\n\t\t\tstream = node_stream__WEBPACK_IMPORTED_MODULE_0__.Readable.from(body);\n\t\t} else if ((0,_utils_is_js__WEBPACK_IMPORTED_MODULE_5__.isBlob)(body)) {\n\t\t\tstream = node_stream__WEBPACK_IMPORTED_MODULE_0__.Readable.from(body.stream());\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\tbody,\n\t\t\tstream,\n\t\t\tboundary,\n\t\t\tdisturbed: false,\n\t\t\terror: null\n\t\t};\n\t\tthis.size = size;\n\n\t\tif (body instanceof node_stream__WEBPACK_IMPORTED_MODULE_0__) {\n\t\t\tbody.on('error', error_ => {\n\t\t\t\tconst error = error_ instanceof _errors_base_js__WEBPACK_IMPORTED_MODULE_6__.FetchBaseError ?\n\t\t\t\t\terror_ :\n\t\t\t\t\tnew _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_7__.FetchError(`Invalid response body while trying to fetch ${this.url}: ${error_.message}`, 'system', error_);\n\t\t\t\tthis[INTERNALS].error = error;\n\t\t\t});\n\t\t}\n\t}\n\n\tget body() {\n\t\treturn this[INTERNALS].stream;\n\t}\n\n\tget bodyUsed() {\n\t\treturn this[INTERNALS].disturbed;\n\t}\n\n\t/**\n\t * Decode response as ArrayBuffer\n\t *\n\t * @return  Promise\n\t */\n\tasync arrayBuffer() {\n\t\tconst {buffer, byteOffset, byteLength} = await consumeBody(this);\n\t\treturn buffer.slice(byteOffset, byteOffset + byteLength);\n\t}\n\n\tasync formData() {\n\t\tconst ct = this.headers.get('content-type');\n\n\t\tif (ct.startsWith('application/x-www-form-urlencoded')) {\n\t\t\tconst formData = new formdata_polyfill_esm_min_js__WEBPACK_IMPORTED_MODULE_4__.FormData();\n\t\t\tconst parameters = new URLSearchParams(await this.text());\n\n\t\t\tfor (const [name, value] of parameters) {\n\t\t\t\tformData.append(name, value);\n\t\t\t}\n\n\t\t\treturn formData;\n\t\t}\n\n\t\tconst {toFormData} = await __webpack_require__.e(/*! import() */ \"node_modules_node-fetch_src_utils_multipart-parser_js\").then(__webpack_require__.bind(__webpack_require__, /*! ./utils/multipart-parser.js */ \"./node_modules/node-fetch/src/utils/multipart-parser.js\"));\n\t\treturn toFormData(this.body, ct);\n\t}\n\n\t/**\n\t * Return raw response as Blob\n\t *\n\t * @return Promise\n\t */\n\tasync blob() {\n\t\tconst ct = (this.headers && this.headers.get('content-type')) || (this[INTERNALS].body && this[INTERNALS].body.type) || '';\n\t\tconst buf = await this.arrayBuffer();\n\n\t\treturn new fetch_blob__WEBPACK_IMPORTED_MODULE_3__[\"default\"]([buf], {\n\t\t\ttype: ct\n\t\t});\n\t}\n\n\t/**\n\t * Decode response as json\n\t *\n\t * @return  Promise\n\t */\n\tasync json() {\n\t\tconst text = await this.text();\n\t\treturn JSON.parse(text);\n\t}\n\n\t/**\n\t * Decode response as text\n\t *\n\t * @return  Promise\n\t */\n\tasync text() {\n\t\tconst buffer = await consumeBody(this);\n\t\treturn new TextDecoder().decode(buffer);\n\t}\n\n\t/**\n\t * Decode response as buffer (non-spec api)\n\t *\n\t * @return  Promise\n\t */\n\tbuffer() {\n\t\treturn consumeBody(this);\n\t}\n}\n\nBody.prototype.buffer = (0,node_util__WEBPACK_IMPORTED_MODULE_1__.deprecate)(Body.prototype.buffer, 'Please use \\'response.arrayBuffer()\\' instead of \\'response.buffer()\\'', 'node-fetch#buffer');\n\n// In browsers, all properties are enumerable.\nObject.defineProperties(Body.prototype, {\n\tbody: {enumerable: true},\n\tbodyUsed: {enumerable: true},\n\tarrayBuffer: {enumerable: true},\n\tblob: {enumerable: true},\n\tjson: {enumerable: true},\n\ttext: {enumerable: true},\n\tdata: {get: (0,node_util__WEBPACK_IMPORTED_MODULE_1__.deprecate)(() => {},\n\t\t'data doesn\\'t exist, use json(), text(), arrayBuffer(), or body instead',\n\t\t'https://github.com/node-fetch/node-fetch/issues/1000 (response)')}\n});\n\n/**\n * Consume and convert an entire Body to a Buffer.\n *\n * Ref: https://fetch.spec.whatwg.org/#concept-body-consume-body\n *\n * @return Promise\n */\nasync function consumeBody(data) {\n\tif (data[INTERNALS].disturbed) {\n\t\tthrow new TypeError(`body used already for: ${data.url}`);\n\t}\n\n\tdata[INTERNALS].disturbed = true;\n\n\tif (data[INTERNALS].error) {\n\t\tthrow data[INTERNALS].error;\n\t}\n\n\tconst {body} = data;\n\n\t// Body is null\n\tif (body === null) {\n\t\treturn node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.alloc(0);\n\t}\n\n\t/* c8 ignore next 3 */\n\tif (!(body instanceof node_stream__WEBPACK_IMPORTED_MODULE_0__)) {\n\t\treturn node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.alloc(0);\n\t}\n\n\t// Body is stream\n\t// get ready to actually consume the body\n\tconst accum = [];\n\tlet accumBytes = 0;\n\n\ttry {\n\t\tfor await (const chunk of body) {\n\t\t\tif (data.size > 0 && accumBytes + chunk.length > data.size) {\n\t\t\t\tconst error = new _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_7__.FetchError(`content size at ${data.url} over limit: ${data.size}`, 'max-size');\n\t\t\t\tbody.destroy(error);\n\t\t\t\tthrow error;\n\t\t\t}\n\n\t\t\taccumBytes += chunk.length;\n\t\t\taccum.push(chunk);\n\t\t}\n\t} catch (error) {\n\t\tconst error_ = error instanceof _errors_base_js__WEBPACK_IMPORTED_MODULE_6__.FetchBaseError ? error : new _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_7__.FetchError(`Invalid response body while trying to fetch ${data.url}: ${error.message}`, 'system', error);\n\t\tthrow error_;\n\t}\n\n\tif (body.readableEnded === true || body._readableState.ended === true) {\n\t\ttry {\n\t\t\tif (accum.every(c => typeof c === 'string')) {\n\t\t\t\treturn node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.from(accum.join(''));\n\t\t\t}\n\n\t\t\treturn node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.concat(accum, accumBytes);\n\t\t} catch (error) {\n\t\t\tthrow new _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_7__.FetchError(`Could not create Buffer from response body for ${data.url}: ${error.message}`, 'system', error);\n\t\t}\n\t} else {\n\t\tthrow new _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_7__.FetchError(`Premature close of server response while trying to fetch ${data.url}`);\n\t}\n}\n\n/**\n * Clone body given Res/Req instance\n *\n * @param   Mixed   instance       Response or Request instance\n * @param   String  highWaterMark  highWaterMark for both PassThrough body streams\n * @return  Mixed\n */\nconst clone = (instance, highWaterMark) => {\n\tlet p1;\n\tlet p2;\n\tlet {body} = instance[INTERNALS];\n\n\t// Don't allow cloning a used body\n\tif (instance.bodyUsed) {\n\t\tthrow new Error('cannot clone body after it is used');\n\t}\n\n\t// Check that body is a stream and not form-data object\n\t// note: we can't clone the form-data object without having it as a dependency\n\tif ((body instanceof node_stream__WEBPACK_IMPORTED_MODULE_0__) && (typeof body.getBoundary !== 'function')) {\n\t\t// Tee instance body\n\t\tp1 = new node_stream__WEBPACK_IMPORTED_MODULE_0__.PassThrough({highWaterMark});\n\t\tp2 = new node_stream__WEBPACK_IMPORTED_MODULE_0__.PassThrough({highWaterMark});\n\t\tbody.pipe(p1);\n\t\tbody.pipe(p2);\n\t\t// Set instance body to teed body and return the other teed body\n\t\tinstance[INTERNALS].stream = p1;\n\t\tbody = p2;\n\t}\n\n\treturn body;\n};\n\nconst getNonSpecFormDataBoundary = (0,node_util__WEBPACK_IMPORTED_MODULE_1__.deprecate)(\n\tbody => body.getBoundary(),\n\t'form-data doesn\\'t follow the spec and requires special treatment. Use alternative package',\n\t'https://github.com/node-fetch/node-fetch/issues/1167'\n);\n\n/**\n * Performs the operation \"extract a `Content-Type` value from |object|\" as\n * specified in the specification:\n * https://fetch.spec.whatwg.org/#concept-bodyinit-extract\n *\n * This function assumes that instance.body is present.\n *\n * @param {any} body Any options.body input\n * @returns {string | null}\n */\nconst extractContentType = (body, request) => {\n\t// Body is null or undefined\n\tif (body === null) {\n\t\treturn null;\n\t}\n\n\t// Body is string\n\tif (typeof body === 'string') {\n\t\treturn 'text/plain;charset=UTF-8';\n\t}\n\n\t// Body is a URLSearchParams\n\tif ((0,_utils_is_js__WEBPACK_IMPORTED_MODULE_5__.isURLSearchParameters)(body)) {\n\t\treturn 'application/x-www-form-urlencoded;charset=UTF-8';\n\t}\n\n\t// Body is blob\n\tif ((0,_utils_is_js__WEBPACK_IMPORTED_MODULE_5__.isBlob)(body)) {\n\t\treturn body.type || null;\n\t}\n\n\t// Body is a Buffer (Buffer, ArrayBuffer or ArrayBufferView)\n\tif (node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.isBuffer(body) || node_util__WEBPACK_IMPORTED_MODULE_1__.types.isAnyArrayBuffer(body) || ArrayBuffer.isView(body)) {\n\t\treturn null;\n\t}\n\n\tif (body instanceof formdata_polyfill_esm_min_js__WEBPACK_IMPORTED_MODULE_4__.FormData) {\n\t\treturn `multipart/form-data; boundary=${request[INTERNALS].boundary}`;\n\t}\n\n\t// Detect form data input from form-data module\n\tif (body && typeof body.getBoundary === 'function') {\n\t\treturn `multipart/form-data;boundary=${getNonSpecFormDataBoundary(body)}`;\n\t}\n\n\t// Body is stream - can't really do much about this\n\tif (body instanceof node_stream__WEBPACK_IMPORTED_MODULE_0__) {\n\t\treturn null;\n\t}\n\n\t// Body constructor defaults other things to string\n\treturn 'text/plain;charset=UTF-8';\n};\n\n/**\n * The Fetch Standard treats this as if \"total bytes\" is a property on the body.\n * For us, we have to explicitly get it with a function.\n *\n * ref: https://fetch.spec.whatwg.org/#concept-body-total-bytes\n *\n * @param {any} obj.body Body object from the Body instance.\n * @returns {number | null}\n */\nconst getTotalBytes = request => {\n\tconst {body} = request[INTERNALS];\n\n\t// Body is null or undefined\n\tif (body === null) {\n\t\treturn 0;\n\t}\n\n\t// Body is Blob\n\tif ((0,_utils_is_js__WEBPACK_IMPORTED_MODULE_5__.isBlob)(body)) {\n\t\treturn body.size;\n\t}\n\n\t// Body is Buffer\n\tif (node_buffer__WEBPACK_IMPORTED_MODULE_2__.Buffer.isBuffer(body)) {\n\t\treturn body.length;\n\t}\n\n\t// Detect form data input from form-data module\n\tif (body && typeof body.getLengthSync === 'function') {\n\t\treturn body.hasKnownLength && body.hasKnownLength() ? body.getLengthSync() : null;\n\t}\n\n\t// Body is stream\n\treturn null;\n};\n\n/**\n * Write a Body to a Node.js WritableStream (e.g. http.Request) object.\n *\n * @param {Stream.Writable} dest The stream to write to.\n * @param obj.body Body object from the Body instance.\n * @returns {Promise<void>}\n */\nconst writeToStream = async (dest, {body}) => {\n\tif (body === null) {\n\t\t// Body is null\n\t\tdest.end();\n\t} else {\n\t\t// Body is stream\n\t\tawait pipeline(body, dest);\n\t}\n};\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/body.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/errors/abort-error.js":
/*!***********************************************************!*\
  !*** ./node_modules/node-fetch/src/errors/abort-error.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AbortError\": () => (/* binding */ AbortError)\n/* harmony export */ });\n/* harmony import */ var _base_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base.js */ \"./node_modules/node-fetch/src/errors/base.js\");\n\n\n/**\n * AbortError interface for cancelled requests\n */\nclass AbortError extends _base_js__WEBPACK_IMPORTED_MODULE_0__.FetchBaseError {\n\tconstructor(message, type = 'aborted') {\n\t\tsuper(message, type);\n\t}\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/errors/abort-error.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/errors/base.js":
/*!****************************************************!*\
  !*** ./node_modules/node-fetch/src/errors/base.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FetchBaseError\": () => (/* binding */ FetchBaseError)\n/* harmony export */ });\nclass FetchBaseError extends Error {\n\tconstructor(message, type) {\n\t\tsuper(message);\n\t\t// Hide custom error implementation details from end-users\n\t\tError.captureStackTrace(this, this.constructor);\n\n\t\tthis.type = type;\n\t}\n\n\tget name() {\n\t\treturn this.constructor.name;\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/errors/base.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/errors/fetch-error.js":
/*!***********************************************************!*\
  !*** ./node_modules/node-fetch/src/errors/fetch-error.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FetchError\": () => (/* binding */ FetchError)\n/* harmony export */ });\n/* harmony import */ var _base_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base.js */ \"./node_modules/node-fetch/src/errors/base.js\");\n\n\n\n/**\n * @typedef {{ address?: string, code: string, dest?: string, errno: number, info?: object, message: string, path?: string, port?: number, syscall: string}} SystemError\n*/\n\n/**\n * FetchError interface for operational errors\n */\nclass FetchError extends _base_js__WEBPACK_IMPORTED_MODULE_0__.FetchBaseError {\n\t/**\n\t * @param  {string} message -      Error message for human\n\t * @param  {string} [type] -        Error type for machine\n\t * @param  {SystemError} [systemError] - For Node.js system error\n\t */\n\tconstructor(message, type, systemError) {\n\t\tsuper(message, type);\n\t\t// When err.type is `system`, err.erroredSysCall contains system error and err.code contains system error code\n\t\tif (systemError) {\n\t\t\t// eslint-disable-next-line no-multi-assign\n\t\t\tthis.code = this.errno = systemError.code;\n\t\t\tthis.erroredSysCall = systemError.syscall;\n\t\t}\n\t}\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/errors/fetch-error.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/headers.js":
/*!************************************************!*\
  !*** ./node_modules/node-fetch/src/headers.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Headers),\n/* harmony export */   \"fromRawHeaders\": () => (/* binding */ fromRawHeaders)\n/* harmony export */ });\n/* harmony import */ var node_util__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:util */ \"node:util\");\n/* harmony import */ var node_http__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:http */ \"node:http\");\n/**\n * Headers.js\n *\n * Headers class offers convenient helpers\n */\n\n\n\n\n/* c8 ignore next 9 */\nconst validateHeaderName = typeof node_http__WEBPACK_IMPORTED_MODULE_1__.validateHeaderName === 'function' ?\n\tnode_http__WEBPACK_IMPORTED_MODULE_1__.validateHeaderName :\n\tname => {\n\t\tif (!/^[\\^`\\-\\w!#$%&'*+.|~]+$/.test(name)) {\n\t\t\tconst error = new TypeError(`Header name must be a valid HTTP token [${name}]`);\n\t\t\tObject.defineProperty(error, 'code', {value: 'ERR_INVALID_HTTP_TOKEN'});\n\t\t\tthrow error;\n\t\t}\n\t};\n\n/* c8 ignore next 9 */\nconst validateHeaderValue = typeof node_http__WEBPACK_IMPORTED_MODULE_1__.validateHeaderValue === 'function' ?\n\tnode_http__WEBPACK_IMPORTED_MODULE_1__.validateHeaderValue :\n\t(name, value) => {\n\t\tif (/[^\\t\\u0020-\\u007E\\u0080-\\u00FF]/.test(value)) {\n\t\t\tconst error = new TypeError(`Invalid character in header content [\"${name}\"]`);\n\t\t\tObject.defineProperty(error, 'code', {value: 'ERR_INVALID_CHAR'});\n\t\t\tthrow error;\n\t\t}\n\t};\n\n/**\n * @typedef {Headers | Record<string, string> | Iterable<readonly [string, string]> | Iterable<Iterable<string>>} HeadersInit\n */\n\n/**\n * This Fetch API interface allows you to perform various actions on HTTP request and response headers.\n * These actions include retrieving, setting, adding to, and removing.\n * A Headers object has an associated header list, which is initially empty and consists of zero or more name and value pairs.\n * You can add to this using methods like append() (see Examples.)\n * In all methods of this interface, header names are matched by case-insensitive byte sequence.\n *\n */\nclass Headers extends URLSearchParams {\n\t/**\n\t * Headers class\n\t *\n\t * @constructor\n\t * @param {HeadersInit} [init] - Response headers\n\t */\n\tconstructor(init) {\n\t\t// Validate and normalize init object in [name, value(s)][]\n\t\t/** @type {string[][]} */\n\t\tlet result = [];\n\t\tif (init instanceof Headers) {\n\t\t\tconst raw = init.raw();\n\t\t\tfor (const [name, values] of Object.entries(raw)) {\n\t\t\t\tresult.push(...values.map(value => [name, value]));\n\t\t\t}\n\t\t} else if (init == null) { // eslint-disable-line no-eq-null, eqeqeq\n\t\t\t// No op\n\t\t} else if (typeof init === 'object' && !node_util__WEBPACK_IMPORTED_MODULE_0__.types.isBoxedPrimitive(init)) {\n\t\t\tconst method = init[Symbol.iterator];\n\t\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\t\tif (method == null) {\n\t\t\t\t// Record<ByteString, ByteString>\n\t\t\t\tresult.push(...Object.entries(init));\n\t\t\t} else {\n\t\t\t\tif (typeof method !== 'function') {\n\t\t\t\t\tthrow new TypeError('Header pairs must be iterable');\n\t\t\t\t}\n\n\t\t\t\t// Sequence<sequence<ByteString>>\n\t\t\t\t// Note: per spec we have to first exhaust the lists then process them\n\t\t\t\tresult = [...init]\n\t\t\t\t\t.map(pair => {\n\t\t\t\t\t\tif (\n\t\t\t\t\t\t\ttypeof pair !== 'object' || node_util__WEBPACK_IMPORTED_MODULE_0__.types.isBoxedPrimitive(pair)\n\t\t\t\t\t\t) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be an iterable object');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t}).map(pair => {\n\t\t\t\t\t\tif (pair.length !== 2) {\n\t\t\t\t\t\t\tthrow new TypeError('Each header pair must be a name/value tuple');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn [...pair];\n\t\t\t\t\t});\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new TypeError('Failed to construct \\'Headers\\': The provided value is not of type \\'(sequence<sequence<ByteString>> or record<ByteString, ByteString>)');\n\t\t}\n\n\t\t// Validate and lowercase\n\t\tresult =\n\t\t\tresult.length > 0 ?\n\t\t\t\tresult.map(([name, value]) => {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn [String(name).toLowerCase(), String(value)];\n\t\t\t\t}) :\n\t\t\t\tundefined;\n\n\t\tsuper(result);\n\n\t\t// Returning a Proxy that will lowercase key names, validate parameters and sort keys\n\t\t// eslint-disable-next-line no-constructor-return\n\t\treturn new Proxy(this, {\n\t\t\tget(target, p, receiver) {\n\t\t\t\tswitch (p) {\n\t\t\t\t\tcase 'append':\n\t\t\t\t\tcase 'set':\n\t\t\t\t\t\treturn (name, value) => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\ttarget,\n\t\t\t\t\t\t\t\tString(name).toLowerCase(),\n\t\t\t\t\t\t\t\tString(value)\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'delete':\n\t\t\t\t\tcase 'has':\n\t\t\t\t\tcase 'getAll':\n\t\t\t\t\t\treturn name => {\n\t\t\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\t\t\treturn URLSearchParams.prototype[p].call(\n\t\t\t\t\t\t\t\ttarget,\n\t\t\t\t\t\t\t\tString(name).toLowerCase()\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\n\t\t\t\t\tcase 'keys':\n\t\t\t\t\t\treturn () => {\n\t\t\t\t\t\t\ttarget.sort();\n\t\t\t\t\t\t\treturn new Set(URLSearchParams.prototype.keys.call(target)).keys();\n\t\t\t\t\t\t};\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn Reflect.get(target, p, receiver);\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\t/* c8 ignore next */\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn this.constructor.name;\n\t}\n\n\ttoString() {\n\t\treturn Object.prototype.toString.call(this);\n\t}\n\n\tget(name) {\n\t\tconst values = this.getAll(name);\n\t\tif (values.length === 0) {\n\t\t\treturn null;\n\t\t}\n\n\t\tlet value = values.join(', ');\n\t\tif (/^content-encoding$/i.test(name)) {\n\t\t\tvalue = value.toLowerCase();\n\t\t}\n\n\t\treturn value;\n\t}\n\n\tforEach(callback, thisArg = undefined) {\n\t\tfor (const name of this.keys()) {\n\t\t\tReflect.apply(callback, thisArg, [this.get(name), name, this]);\n\t\t}\n\t}\n\n\t* values() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield this.get(name);\n\t\t}\n\t}\n\n\t/**\n\t * @type {() => IterableIterator<[string, string]>}\n\t */\n\t* entries() {\n\t\tfor (const name of this.keys()) {\n\t\t\tyield [name, this.get(name)];\n\t\t}\n\t}\n\n\t[Symbol.iterator]() {\n\t\treturn this.entries();\n\t}\n\n\t/**\n\t * Node-fetch non-spec method\n\t * returning all headers and their values as array\n\t * @returns {Record<string, string[]>}\n\t */\n\traw() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tresult[key] = this.getAll(key);\n\t\t\treturn result;\n\t\t}, {});\n\t}\n\n\t/**\n\t * For better console.log(headers) and also to convert Headers into Node.js Request compatible format\n\t */\n\t[Symbol.for('nodejs.util.inspect.custom')]() {\n\t\treturn [...this.keys()].reduce((result, key) => {\n\t\t\tconst values = this.getAll(key);\n\t\t\t// Http.request() only supports string as Host header.\n\t\t\t// This hack makes specifying custom Host header possible.\n\t\t\tif (key === 'host') {\n\t\t\t\tresult[key] = values[0];\n\t\t\t} else {\n\t\t\t\tresult[key] = values.length > 1 ? values : values[0];\n\t\t\t}\n\n\t\t\treturn result;\n\t\t}, {});\n\t}\n}\n\n/**\n * Re-shaping object for Web IDL tests\n * Only need to do it for overridden methods\n */\nObject.defineProperties(\n\tHeaders.prototype,\n\t['get', 'entries', 'forEach', 'values'].reduce((result, property) => {\n\t\tresult[property] = {enumerable: true};\n\t\treturn result;\n\t}, {})\n);\n\n/**\n * Create a Headers object from an http.IncomingMessage.rawHeaders, ignoring those that do\n * not conform to HTTP grammar productions.\n * @param {import('http').IncomingMessage['rawHeaders']} headers\n */\nfunction fromRawHeaders(headers = []) {\n\treturn new Headers(\n\t\theaders\n\t\t\t// Split into pairs\n\t\t\t.reduce((result, value, index, array) => {\n\t\t\t\tif (index % 2 === 0) {\n\t\t\t\t\tresult.push(array.slice(index, index + 2));\n\t\t\t\t}\n\n\t\t\t\treturn result;\n\t\t\t}, [])\n\t\t\t.filter(([name, value]) => {\n\t\t\t\ttry {\n\t\t\t\t\tvalidateHeaderName(name);\n\t\t\t\t\tvalidateHeaderValue(name, String(value));\n\t\t\t\t\treturn true;\n\t\t\t\t} catch {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t})\n\n\t);\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/headers.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/index.js":
/*!**********************************************!*\
  !*** ./node_modules/node-fetch/src/index.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AbortError\": () => (/* reexport safe */ _errors_abort_error_js__WEBPACK_IMPORTED_MODULE_12__.AbortError),\n/* harmony export */   \"Blob\": () => (/* reexport safe */ fetch_blob_from_js__WEBPACK_IMPORTED_MODULE_7__.Blob),\n/* harmony export */   \"FetchError\": () => (/* reexport safe */ _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_11__.FetchError),\n/* harmony export */   \"File\": () => (/* reexport safe */ fetch_blob_from_js__WEBPACK_IMPORTED_MODULE_7__.File),\n/* harmony export */   \"FormData\": () => (/* reexport safe */ formdata_polyfill_esm_min_js__WEBPACK_IMPORTED_MODULE_6__.FormData),\n/* harmony export */   \"Headers\": () => (/* reexport safe */ _headers_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"]),\n/* harmony export */   \"Request\": () => (/* reexport safe */ _request_js__WEBPACK_IMPORTED_MODULE_9__[\"default\"]),\n/* harmony export */   \"Response\": () => (/* reexport safe */ _response_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"]),\n/* harmony export */   \"blobFrom\": () => (/* reexport safe */ fetch_blob_from_js__WEBPACK_IMPORTED_MODULE_7__.blobFrom),\n/* harmony export */   \"blobFromSync\": () => (/* reexport safe */ fetch_blob_from_js__WEBPACK_IMPORTED_MODULE_7__.blobFromSync),\n/* harmony export */   \"default\": () => (/* binding */ fetch),\n/* harmony export */   \"fileFrom\": () => (/* reexport safe */ fetch_blob_from_js__WEBPACK_IMPORTED_MODULE_7__.fileFrom),\n/* harmony export */   \"fileFromSync\": () => (/* reexport safe */ fetch_blob_from_js__WEBPACK_IMPORTED_MODULE_7__.fileFromSync),\n/* harmony export */   \"isRedirect\": () => (/* reexport safe */ _utils_is_redirect_js__WEBPACK_IMPORTED_MODULE_13__.isRedirect)\n/* harmony export */ });\n/* harmony import */ var node_http__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:http */ \"node:http\");\n/* harmony import */ var node_https__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:https */ \"node:https\");\n/* harmony import */ var node_zlib__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! node:zlib */ \"node:zlib\");\n/* harmony import */ var node_stream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! node:stream */ \"node:stream\");\n/* harmony import */ var node_buffer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! node:buffer */ \"node:buffer\");\n/* harmony import */ var data_uri_to_buffer__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! data-uri-to-buffer */ \"./node_modules/data-uri-to-buffer/dist/index.js\");\n/* harmony import */ var _body_js__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./body.js */ \"./node_modules/node-fetch/src/body.js\");\n/* harmony import */ var _response_js__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./response.js */ \"./node_modules/node-fetch/src/response.js\");\n/* harmony import */ var _headers_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./headers.js */ \"./node_modules/node-fetch/src/headers.js\");\n/* harmony import */ var _request_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./request.js */ \"./node_modules/node-fetch/src/request.js\");\n/* harmony import */ var _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./errors/fetch-error.js */ \"./node_modules/node-fetch/src/errors/fetch-error.js\");\n/* harmony import */ var _errors_abort_error_js__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./errors/abort-error.js */ \"./node_modules/node-fetch/src/errors/abort-error.js\");\n/* harmony import */ var _utils_is_redirect_js__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./utils/is-redirect.js */ \"./node_modules/node-fetch/src/utils/is-redirect.js\");\n/* harmony import */ var formdata_polyfill_esm_min_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! formdata-polyfill/esm.min.js */ \"./node_modules/formdata-polyfill/esm.min.js\");\n/* harmony import */ var _utils_is_js__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./utils/is.js */ \"./node_modules/node-fetch/src/utils/is.js\");\n/* harmony import */ var _utils_referrer_js__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./utils/referrer.js */ \"./node_modules/node-fetch/src/utils/referrer.js\");\n/* harmony import */ var fetch_blob_from_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! fetch-blob/from.js */ \"./node_modules/fetch-blob/from.js\");\n/**\n * Index.js\n *\n * a request API compatible with window.fetch\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst supportedSchemas = new Set(['data:', 'http:', 'https:']);\n\n/**\n * Fetch function\n *\n * @param   {string | URL | import('./request').default} url - Absolute url or Request instance\n * @param   {*} [options_] - Fetch options\n * @return  {Promise<import('./response').default>}\n */\nasync function fetch(url, options_) {\n\treturn new Promise((resolve, reject) => {\n\t\t// Build request object\n\t\tconst request = new _request_js__WEBPACK_IMPORTED_MODULE_9__[\"default\"](url, options_);\n\t\tconst {parsedURL, options} = (0,_request_js__WEBPACK_IMPORTED_MODULE_9__.getNodeRequestOptions)(request);\n\t\tif (!supportedSchemas.has(parsedURL.protocol)) {\n\t\t\tthrow new TypeError(`node-fetch cannot load ${url}. URL scheme \"${parsedURL.protocol.replace(/:$/, '')}\" is not supported.`);\n\t\t}\n\n\t\tif (parsedURL.protocol === 'data:') {\n\t\t\tconst data = (0,data_uri_to_buffer__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(request.url);\n\t\t\tconst response = new _response_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"](data, {headers: {'Content-Type': data.typeFull}});\n\t\t\tresolve(response);\n\t\t\treturn;\n\t\t}\n\n\t\t// Wrap http.request into fetch\n\t\tconst send = (parsedURL.protocol === 'https:' ? node_https__WEBPACK_IMPORTED_MODULE_1__ : node_http__WEBPACK_IMPORTED_MODULE_0__).request;\n\t\tconst {signal} = request;\n\t\tlet response = null;\n\n\t\tconst abort = () => {\n\t\t\tconst error = new _errors_abort_error_js__WEBPACK_IMPORTED_MODULE_12__.AbortError('The operation was aborted.');\n\t\t\treject(error);\n\t\t\tif (request.body && request.body instanceof node_stream__WEBPACK_IMPORTED_MODULE_3__.Readable) {\n\t\t\t\trequest.body.destroy(error);\n\t\t\t}\n\n\t\t\tif (!response || !response.body) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tresponse.body.emit('error', error);\n\t\t};\n\n\t\tif (signal && signal.aborted) {\n\t\t\tabort();\n\t\t\treturn;\n\t\t}\n\n\t\tconst abortAndFinalize = () => {\n\t\t\tabort();\n\t\t\tfinalize();\n\t\t};\n\n\t\t// Send request\n\t\tconst request_ = send(parsedURL.toString(), options);\n\n\t\tif (signal) {\n\t\t\tsignal.addEventListener('abort', abortAndFinalize);\n\t\t}\n\n\t\tconst finalize = () => {\n\t\t\trequest_.abort();\n\t\t\tif (signal) {\n\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t}\n\t\t};\n\n\t\trequest_.on('error', error => {\n\t\t\treject(new _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_11__.FetchError(`request to ${request.url} failed, reason: ${error.message}`, 'system', error));\n\t\t\tfinalize();\n\t\t});\n\n\t\tfixResponseChunkedTransferBadEnding(request_, error => {\n\t\t\tif (response && response.body) {\n\t\t\t\tresponse.body.destroy(error);\n\t\t\t}\n\t\t});\n\n\t\t/* c8 ignore next 18 */\n\t\tif (process.version < 'v14') {\n\t\t\t// Before Node.js 14, pipeline() does not fully support async iterators and does not always\n\t\t\t// properly handle when the socket close/end events are out of order.\n\t\t\trequest_.on('socket', s => {\n\t\t\t\tlet endedWithEventsCount;\n\t\t\t\ts.prependListener('end', () => {\n\t\t\t\t\tendedWithEventsCount = s._eventsCount;\n\t\t\t\t});\n\t\t\t\ts.prependListener('close', hadError => {\n\t\t\t\t\t// if end happened before close but the socket didn't emit an error, do it now\n\t\t\t\t\tif (response && endedWithEventsCount < s._eventsCount && !hadError) {\n\t\t\t\t\t\tconst error = new Error('Premature close');\n\t\t\t\t\t\terror.code = 'ERR_STREAM_PREMATURE_CLOSE';\n\t\t\t\t\t\tresponse.body.emit('error', error);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t});\n\t\t}\n\n\t\trequest_.on('response', response_ => {\n\t\t\trequest_.setTimeout(0);\n\t\t\tconst headers = (0,_headers_js__WEBPACK_IMPORTED_MODULE_8__.fromRawHeaders)(response_.rawHeaders);\n\n\t\t\t// HTTP fetch step 5\n\t\t\tif ((0,_utils_is_redirect_js__WEBPACK_IMPORTED_MODULE_13__.isRedirect)(response_.statusCode)) {\n\t\t\t\t// HTTP fetch step 5.2\n\t\t\t\tconst location = headers.get('Location');\n\n\t\t\t\t// HTTP fetch step 5.3\n\t\t\t\tlet locationURL = null;\n\t\t\t\ttry {\n\t\t\t\t\tlocationURL = location === null ? null : new URL(location, request.url);\n\t\t\t\t} catch {\n\t\t\t\t\t// error here can only be invalid URL in Location: header\n\t\t\t\t\t// do not throw when options.redirect == manual\n\t\t\t\t\t// let the user extract the errorneous redirect URL\n\t\t\t\t\tif (request.redirect !== 'manual') {\n\t\t\t\t\t\treject(new _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_11__.FetchError(`uri requested responds with an invalid redirect URL: ${location}`, 'invalid-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// HTTP fetch step 5.5\n\t\t\t\tswitch (request.redirect) {\n\t\t\t\t\tcase 'error':\n\t\t\t\t\t\treject(new _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_11__.FetchError(`uri requested responds with a redirect, redirect mode is set to error: ${request.url}`, 'no-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\tcase 'manual':\n\t\t\t\t\t\t// Nothing to do\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'follow': {\n\t\t\t\t\t\t// HTTP-redirect fetch step 2\n\t\t\t\t\t\tif (locationURL === null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 5\n\t\t\t\t\t\tif (request.counter >= request.follow) {\n\t\t\t\t\t\t\treject(new _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_11__.FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 6 (counter increment)\n\t\t\t\t\t\t// Create a new Request object.\n\t\t\t\t\t\tconst requestOptions = {\n\t\t\t\t\t\t\theaders: new _headers_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"](request.headers),\n\t\t\t\t\t\t\tfollow: request.follow,\n\t\t\t\t\t\t\tcounter: request.counter + 1,\n\t\t\t\t\t\t\tagent: request.agent,\n\t\t\t\t\t\t\tcompress: request.compress,\n\t\t\t\t\t\t\tmethod: request.method,\n\t\t\t\t\t\t\tbody: (0,_body_js__WEBPACK_IMPORTED_MODULE_14__.clone)(request),\n\t\t\t\t\t\t\tsignal: request.signal,\n\t\t\t\t\t\t\tsize: request.size,\n\t\t\t\t\t\t\treferrer: request.referrer,\n\t\t\t\t\t\t\treferrerPolicy: request.referrerPolicy\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// when forwarding sensitive headers like \"Authorization\",\n\t\t\t\t\t\t// \"WWW-Authenticate\", and \"Cookie\" to untrusted targets,\n\t\t\t\t\t\t// headers will be ignored when following a redirect to a domain\n\t\t\t\t\t\t// that is not a subdomain match or exact match of the initial domain.\n\t\t\t\t\t\t// For example, a redirect from \"foo.com\" to either \"foo.com\" or \"sub.foo.com\"\n\t\t\t\t\t\t// will forward the sensitive headers, but a redirect to \"bar.com\" will not.\n\t\t\t\t\t\t// headers will also be ignored when following a redirect to a domain using\n\t\t\t\t\t\t// a different protocol. For example, a redirect from \"https://foo.com\" to \"http://foo.com\"\n\t\t\t\t\t\t// will not forward the sensitive headers\n\t\t\t\t\t\tif (!(0,_utils_is_js__WEBPACK_IMPORTED_MODULE_15__.isDomainOrSubdomain)(request.url, locationURL) || !(0,_utils_is_js__WEBPACK_IMPORTED_MODULE_15__.isSameProtocol)(request.url, locationURL)) {\n\t\t\t\t\t\t\tfor (const name of ['authorization', 'www-authenticate', 'cookie', 'cookie2']) {\n\t\t\t\t\t\t\t\trequestOptions.headers.delete(name);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 9\n\t\t\t\t\t\tif (response_.statusCode !== 303 && request.body && options_.body instanceof node_stream__WEBPACK_IMPORTED_MODULE_3__.Readable) {\n\t\t\t\t\t\t\treject(new _errors_fetch_error_js__WEBPACK_IMPORTED_MODULE_11__.FetchError('Cannot follow redirect with body being a readable stream', 'unsupported-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 11\n\t\t\t\t\t\tif (response_.statusCode === 303 || ((response_.statusCode === 301 || response_.statusCode === 302) && request.method === 'POST')) {\n\t\t\t\t\t\t\trequestOptions.method = 'GET';\n\t\t\t\t\t\t\trequestOptions.body = undefined;\n\t\t\t\t\t\t\trequestOptions.headers.delete('content-length');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 14\n\t\t\t\t\t\tconst responseReferrerPolicy = (0,_utils_referrer_js__WEBPACK_IMPORTED_MODULE_16__.parseReferrerPolicyFromHeader)(headers);\n\t\t\t\t\t\tif (responseReferrerPolicy) {\n\t\t\t\t\t\t\trequestOptions.referrerPolicy = responseReferrerPolicy;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 15\n\t\t\t\t\t\tresolve(fetch(new _request_js__WEBPACK_IMPORTED_MODULE_9__[\"default\"](locationURL, requestOptions)));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn reject(new TypeError(`Redirect option '${request.redirect}' is not a valid value of RequestRedirect`));\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Prepare response\n\t\t\tif (signal) {\n\t\t\t\tresponse_.once('end', () => {\n\t\t\t\t\tsignal.removeEventListener('abort', abortAndFinalize);\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tlet body = (0,node_stream__WEBPACK_IMPORTED_MODULE_3__.pipeline)(response_, new node_stream__WEBPACK_IMPORTED_MODULE_3__.PassThrough(), error => {\n\t\t\t\tif (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t}\n\t\t\t});\n\t\t\t// see https://github.com/nodejs/node/pull/29376\n\t\t\t/* c8 ignore next 3 */\n\t\t\tif (process.version < 'v12.10') {\n\t\t\t\tresponse_.on('aborted', abortAndFinalize);\n\t\t\t}\n\n\t\t\tconst responseOptions = {\n\t\t\t\turl: request.url,\n\t\t\t\tstatus: response_.statusCode,\n\t\t\t\tstatusText: response_.statusMessage,\n\t\t\t\theaders,\n\t\t\t\tsize: request.size,\n\t\t\t\tcounter: request.counter,\n\t\t\t\thighWaterMark: request.highWaterMark\n\t\t\t};\n\n\t\t\t// HTTP-network fetch step 12.1.1.3\n\t\t\tconst codings = headers.get('Content-Encoding');\n\n\t\t\t// HTTP-network fetch step 12.1.1.4: handle content codings\n\n\t\t\t// in following scenarios we ignore compression support\n\t\t\t// 1. compression support is disabled\n\t\t\t// 2. HEAD request\n\t\t\t// 3. no Content-Encoding header\n\t\t\t// 4. no content response (204)\n\t\t\t// 5. content not modified response (304)\n\t\t\tif (!request.compress || request.method === 'HEAD' || codings === null || response_.statusCode === 204 || response_.statusCode === 304) {\n\t\t\t\tresponse = new _response_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"](body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For Node v6+\n\t\t\t// Be less strict when decoding compressed responses, since sometimes\n\t\t\t// servers send slightly invalid responses that are still accepted\n\t\t\t// by common browsers.\n\t\t\t// Always using Z_SYNC_FLUSH is what cURL does.\n\t\t\tconst zlibOptions = {\n\t\t\t\tflush: node_zlib__WEBPACK_IMPORTED_MODULE_2__.Z_SYNC_FLUSH,\n\t\t\t\tfinishFlush: node_zlib__WEBPACK_IMPORTED_MODULE_2__.Z_SYNC_FLUSH\n\t\t\t};\n\n\t\t\t// For gzip\n\t\t\tif (codings === 'gzip' || codings === 'x-gzip') {\n\t\t\t\tbody = (0,node_stream__WEBPACK_IMPORTED_MODULE_3__.pipeline)(body, node_zlib__WEBPACK_IMPORTED_MODULE_2__.createGunzip(zlibOptions), error => {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\treject(error);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tresponse = new _response_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"](body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For deflate\n\t\t\tif (codings === 'deflate' || codings === 'x-deflate') {\n\t\t\t\t// Handle the infamous raw deflate response from old servers\n\t\t\t\t// a hack for old IIS and Apache servers\n\t\t\t\tconst raw = (0,node_stream__WEBPACK_IMPORTED_MODULE_3__.pipeline)(response_, new node_stream__WEBPACK_IMPORTED_MODULE_3__.PassThrough(), error => {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\treject(error);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\traw.once('data', chunk => {\n\t\t\t\t\t// See http://stackoverflow.com/questions/37519828\n\t\t\t\t\tif ((chunk[0] & 0x0F) === 0x08) {\n\t\t\t\t\t\tbody = (0,node_stream__WEBPACK_IMPORTED_MODULE_3__.pipeline)(body, node_zlib__WEBPACK_IMPORTED_MODULE_2__.createInflate(), error => {\n\t\t\t\t\t\t\tif (error) {\n\t\t\t\t\t\t\t\treject(error);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbody = (0,node_stream__WEBPACK_IMPORTED_MODULE_3__.pipeline)(body, node_zlib__WEBPACK_IMPORTED_MODULE_2__.createInflateRaw(), error => {\n\t\t\t\t\t\t\tif (error) {\n\t\t\t\t\t\t\t\treject(error);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\n\t\t\t\t\tresponse = new _response_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"](body, responseOptions);\n\t\t\t\t\tresolve(response);\n\t\t\t\t});\n\t\t\t\traw.once('end', () => {\n\t\t\t\t\t// Some old IIS servers return zero-length OK deflate responses, so\n\t\t\t\t\t// 'data' is never emitted. See https://github.com/node-fetch/node-fetch/pull/903\n\t\t\t\t\tif (!response) {\n\t\t\t\t\t\tresponse = new _response_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"](body, responseOptions);\n\t\t\t\t\t\tresolve(response);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For br\n\t\t\tif (codings === 'br') {\n\t\t\t\tbody = (0,node_stream__WEBPACK_IMPORTED_MODULE_3__.pipeline)(body, node_zlib__WEBPACK_IMPORTED_MODULE_2__.createBrotliDecompress(), error => {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\treject(error);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tresponse = new _response_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"](body, responseOptions);\n\t\t\t\tresolve(response);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Otherwise, use response as-is\n\t\t\tresponse = new _response_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"](body, responseOptions);\n\t\t\tresolve(response);\n\t\t});\n\n\t\t// eslint-disable-next-line promise/prefer-await-to-then\n\t\t(0,_body_js__WEBPACK_IMPORTED_MODULE_14__.writeToStream)(request_, request).catch(reject);\n\t});\n}\n\nfunction fixResponseChunkedTransferBadEnding(request, errorCallback) {\n\tconst LAST_CHUNK = node_buffer__WEBPACK_IMPORTED_MODULE_4__.Buffer.from('0\\r\\n\\r\\n');\n\n\tlet isChunkedTransfer = false;\n\tlet properLastChunkReceived = false;\n\tlet previousChunk;\n\n\trequest.on('response', response => {\n\t\tconst {headers} = response;\n\t\tisChunkedTransfer = headers['transfer-encoding'] === 'chunked' && !headers['content-length'];\n\t});\n\n\trequest.on('socket', socket => {\n\t\tconst onSocketClose = () => {\n\t\t\tif (isChunkedTransfer && !properLastChunkReceived) {\n\t\t\t\tconst error = new Error('Premature close');\n\t\t\t\terror.code = 'ERR_STREAM_PREMATURE_CLOSE';\n\t\t\t\terrorCallback(error);\n\t\t\t}\n\t\t};\n\n\t\tconst onData = buf => {\n\t\t\tproperLastChunkReceived = node_buffer__WEBPACK_IMPORTED_MODULE_4__.Buffer.compare(buf.slice(-5), LAST_CHUNK) === 0;\n\n\t\t\t// Sometimes final 0-length chunk and end of message code are in separate packets\n\t\t\tif (!properLastChunkReceived && previousChunk) {\n\t\t\t\tproperLastChunkReceived = (\n\t\t\t\t\tnode_buffer__WEBPACK_IMPORTED_MODULE_4__.Buffer.compare(previousChunk.slice(-3), LAST_CHUNK.slice(0, 3)) === 0 &&\n\t\t\t\t\tnode_buffer__WEBPACK_IMPORTED_MODULE_4__.Buffer.compare(buf.slice(-2), LAST_CHUNK.slice(3)) === 0\n\t\t\t\t);\n\t\t\t}\n\n\t\t\tpreviousChunk = buf;\n\t\t};\n\n\t\tsocket.prependListener('close', onSocketClose);\n\t\tsocket.on('data', onData);\n\n\t\trequest.on('close', () => {\n\t\t\tsocket.removeListener('close', onSocketClose);\n\t\t\tsocket.removeListener('data', onData);\n\t\t});\n\t});\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/index.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/request.js":
/*!************************************************!*\
  !*** ./node_modules/node-fetch/src/request.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Request),\n/* harmony export */   \"getNodeRequestOptions\": () => (/* binding */ getNodeRequestOptions)\n/* harmony export */ });\n/* harmony import */ var node_url__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:url */ \"node:url\");\n/* harmony import */ var node_util__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:util */ \"node:util\");\n/* harmony import */ var _headers_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./headers.js */ \"./node_modules/node-fetch/src/headers.js\");\n/* harmony import */ var _body_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./body.js */ \"./node_modules/node-fetch/src/body.js\");\n/* harmony import */ var _utils_is_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./utils/is.js */ \"./node_modules/node-fetch/src/utils/is.js\");\n/* harmony import */ var _utils_get_search_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./utils/get-search.js */ \"./node_modules/node-fetch/src/utils/get-search.js\");\n/* harmony import */ var _utils_referrer_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./utils/referrer.js */ \"./node_modules/node-fetch/src/utils/referrer.js\");\n/**\n * Request.js\n *\n * Request class contains server only options\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\n\n\n\n\n\n\n\n\nconst INTERNALS = Symbol('Request internals');\n\n/**\n * Check if `obj` is an instance of Request.\n *\n * @param  {*} object\n * @return {boolean}\n */\nconst isRequest = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object[INTERNALS] === 'object'\n\t);\n};\n\nconst doBadDataWarn = (0,node_util__WEBPACK_IMPORTED_MODULE_1__.deprecate)(() => {},\n\t'.data is not a valid RequestInit property, use .body instead',\n\t'https://github.com/node-fetch/node-fetch/issues/1000 (request)');\n\n/**\n * Request class\n *\n * Ref: https://fetch.spec.whatwg.org/#request-class\n *\n * @param   Mixed   input  Url or Request instance\n * @param   Object  init   Custom options\n * @return  Void\n */\nclass Request extends _body_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"] {\n\tconstructor(input, init = {}) {\n\t\tlet parsedURL;\n\n\t\t// Normalize input and force URL to be encoded as UTF-8 (https://github.com/node-fetch/node-fetch/issues/245)\n\t\tif (isRequest(input)) {\n\t\t\tparsedURL = new URL(input.url);\n\t\t} else {\n\t\t\tparsedURL = new URL(input);\n\t\t\tinput = {};\n\t\t}\n\n\t\tif (parsedURL.username !== '' || parsedURL.password !== '') {\n\t\t\tthrow new TypeError(`${parsedURL} is an url with embedded credentials.`);\n\t\t}\n\n\t\tlet method = init.method || input.method || 'GET';\n\t\tif (/^(delete|get|head|options|post|put)$/i.test(method)) {\n\t\t\tmethod = method.toUpperCase();\n\t\t}\n\n\t\tif (!isRequest(init) && 'data' in init) {\n\t\t\tdoBadDataWarn();\n\t\t}\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif ((init.body != null || (isRequest(input) && input.body !== null)) &&\n\t\t\t(method === 'GET' || method === 'HEAD')) {\n\t\t\tthrow new TypeError('Request with GET/HEAD method cannot have body');\n\t\t}\n\n\t\tconst inputBody = init.body ?\n\t\t\tinit.body :\n\t\t\t(isRequest(input) && input.body !== null ?\n\t\t\t\t(0,_body_js__WEBPACK_IMPORTED_MODULE_2__.clone)(input) :\n\t\t\t\tnull);\n\n\t\tsuper(inputBody, {\n\t\t\tsize: init.size || input.size || 0\n\t\t});\n\n\t\tconst headers = new _headers_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"](init.headers || input.headers || {});\n\n\t\tif (inputBody !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = (0,_body_js__WEBPACK_IMPORTED_MODULE_2__.extractContentType)(inputBody, this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.set('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tlet signal = isRequest(input) ?\n\t\t\tinput.signal :\n\t\t\tnull;\n\t\tif ('signal' in init) {\n\t\t\tsignal = init.signal;\n\t\t}\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tif (signal != null && !(0,_utils_is_js__WEBPACK_IMPORTED_MODULE_4__.isAbortSignal)(signal)) {\n\t\t\tthrow new TypeError('Expected signal to be an instanceof AbortSignal or EventTarget');\n\t\t}\n\n\t\t// Â§5.4, Request constructor steps, step 15.1\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq\n\t\tlet referrer = init.referrer == null ? input.referrer : init.referrer;\n\t\tif (referrer === '') {\n\t\t\t// Â§5.4, Request constructor steps, step 15.2\n\t\t\treferrer = 'no-referrer';\n\t\t} else if (referrer) {\n\t\t\t// Â§5.4, Request constructor steps, step 15.3.1, 15.3.2\n\t\t\tconst parsedReferrer = new URL(referrer);\n\t\t\t// Â§5.4, Request constructor steps, step 15.3.3, 15.3.4\n\t\t\treferrer = /^about:(\\/\\/)?client$/.test(parsedReferrer) ? 'client' : parsedReferrer;\n\t\t} else {\n\t\t\treferrer = undefined;\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\tmethod,\n\t\t\tredirect: init.redirect || input.redirect || 'follow',\n\t\t\theaders,\n\t\t\tparsedURL,\n\t\t\tsignal,\n\t\t\treferrer\n\t\t};\n\n\t\t// Node-fetch-only options\n\t\tthis.follow = init.follow === undefined ? (input.follow === undefined ? 20 : input.follow) : init.follow;\n\t\tthis.compress = init.compress === undefined ? (input.compress === undefined ? true : input.compress) : init.compress;\n\t\tthis.counter = init.counter || input.counter || 0;\n\t\tthis.agent = init.agent || input.agent;\n\t\tthis.highWaterMark = init.highWaterMark || input.highWaterMark || 16384;\n\t\tthis.insecureHTTPParser = init.insecureHTTPParser || input.insecureHTTPParser || false;\n\n\t\t// Â§5.4, Request constructor steps, step 16.\n\t\t// Default is empty string per https://fetch.spec.whatwg.org/#concept-request-referrer-policy\n\t\tthis.referrerPolicy = init.referrerPolicy || input.referrerPolicy || '';\n\t}\n\n\t/** @returns {string} */\n\tget method() {\n\t\treturn this[INTERNALS].method;\n\t}\n\n\t/** @returns {string} */\n\tget url() {\n\t\treturn (0,node_url__WEBPACK_IMPORTED_MODULE_0__.format)(this[INTERNALS].parsedURL);\n\t}\n\n\t/** @returns {Headers} */\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget redirect() {\n\t\treturn this[INTERNALS].redirect;\n\t}\n\n\t/** @returns {AbortSignal} */\n\tget signal() {\n\t\treturn this[INTERNALS].signal;\n\t}\n\n\t// https://fetch.spec.whatwg.org/#dom-request-referrer\n\tget referrer() {\n\t\tif (this[INTERNALS].referrer === 'no-referrer') {\n\t\t\treturn '';\n\t\t}\n\n\t\tif (this[INTERNALS].referrer === 'client') {\n\t\t\treturn 'about:client';\n\t\t}\n\n\t\tif (this[INTERNALS].referrer) {\n\t\t\treturn this[INTERNALS].referrer.toString();\n\t\t}\n\n\t\treturn undefined;\n\t}\n\n\tget referrerPolicy() {\n\t\treturn this[INTERNALS].referrerPolicy;\n\t}\n\n\tset referrerPolicy(referrerPolicy) {\n\t\tthis[INTERNALS].referrerPolicy = (0,_utils_referrer_js__WEBPACK_IMPORTED_MODULE_5__.validateReferrerPolicy)(referrerPolicy);\n\t}\n\n\t/**\n\t * Clone this request\n\t *\n\t * @return  Request\n\t */\n\tclone() {\n\t\treturn new Request(this);\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Request';\n\t}\n}\n\nObject.defineProperties(Request.prototype, {\n\tmethod: {enumerable: true},\n\turl: {enumerable: true},\n\theaders: {enumerable: true},\n\tredirect: {enumerable: true},\n\tclone: {enumerable: true},\n\tsignal: {enumerable: true},\n\treferrer: {enumerable: true},\n\treferrerPolicy: {enumerable: true}\n});\n\n/**\n * Convert a Request to Node.js http request options.\n *\n * @param {Request} request - A Request instance\n * @return The options object to be passed to http.request\n */\nconst getNodeRequestOptions = request => {\n\tconst {parsedURL} = request[INTERNALS];\n\tconst headers = new _headers_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"](request[INTERNALS].headers);\n\n\t// Fetch step 1.3\n\tif (!headers.has('Accept')) {\n\t\theaders.set('Accept', '*/*');\n\t}\n\n\t// HTTP-network-or-cache fetch steps 2.4-2.7\n\tlet contentLengthValue = null;\n\tif (request.body === null && /^(post|put)$/i.test(request.method)) {\n\t\tcontentLengthValue = '0';\n\t}\n\n\tif (request.body !== null) {\n\t\tconst totalBytes = (0,_body_js__WEBPACK_IMPORTED_MODULE_2__.getTotalBytes)(request);\n\t\t// Set Content-Length if totalBytes is a number (that is not NaN)\n\t\tif (typeof totalBytes === 'number' && !Number.isNaN(totalBytes)) {\n\t\t\tcontentLengthValue = String(totalBytes);\n\t\t}\n\t}\n\n\tif (contentLengthValue) {\n\t\theaders.set('Content-Length', contentLengthValue);\n\t}\n\n\t// 4.1. Main fetch, step 2.6\n\t// > If request's referrer policy is the empty string, then set request's referrer policy to the\n\t// > default referrer policy.\n\tif (request.referrerPolicy === '') {\n\t\trequest.referrerPolicy = _utils_referrer_js__WEBPACK_IMPORTED_MODULE_5__.DEFAULT_REFERRER_POLICY;\n\t}\n\n\t// 4.1. Main fetch, step 2.7\n\t// > If request's referrer is not \"no-referrer\", set request's referrer to the result of invoking\n\t// > determine request's referrer.\n\tif (request.referrer && request.referrer !== 'no-referrer') {\n\t\trequest[INTERNALS].referrer = (0,_utils_referrer_js__WEBPACK_IMPORTED_MODULE_5__.determineRequestsReferrer)(request);\n\t} else {\n\t\trequest[INTERNALS].referrer = 'no-referrer';\n\t}\n\n\t// 4.5. HTTP-network-or-cache fetch, step 6.9\n\t// > If httpRequest's referrer is a URL, then append `Referer`/httpRequest's referrer, serialized\n\t// >  and isomorphic encoded, to httpRequest's header list.\n\tif (request[INTERNALS].referrer instanceof URL) {\n\t\theaders.set('Referer', request.referrer);\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.11\n\tif (!headers.has('User-Agent')) {\n\t\theaders.set('User-Agent', 'node-fetch');\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.15\n\tif (request.compress && !headers.has('Accept-Encoding')) {\n\t\theaders.set('Accept-Encoding', 'gzip, deflate, br');\n\t}\n\n\tlet {agent} = request;\n\tif (typeof agent === 'function') {\n\t\tagent = agent(parsedURL);\n\t}\n\n\tif (!headers.has('Connection') && !agent) {\n\t\theaders.set('Connection', 'close');\n\t}\n\n\t// HTTP-network fetch step 4.2\n\t// chunked encoding is handled by Node.js\n\n\tconst search = (0,_utils_get_search_js__WEBPACK_IMPORTED_MODULE_6__.getSearch)(parsedURL);\n\n\t// Pass the full URL directly to request(), but overwrite the following\n\t// options:\n\tconst options = {\n\t\t// Overwrite search to retain trailing ? (issue #776)\n\t\tpath: parsedURL.pathname + search,\n\t\t// The following options are not expressed in the URL\n\t\tmethod: request.method,\n\t\theaders: headers[Symbol.for('nodejs.util.inspect.custom')](),\n\t\tinsecureHTTPParser: request.insecureHTTPParser,\n\t\tagent\n\t};\n\n\treturn {\n\t\t/** @type {URL} */\n\t\tparsedURL,\n\t\toptions\n\t};\n};\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/request.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/response.js":
/*!*************************************************!*\
  !*** ./node_modules/node-fetch/src/response.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Response)\n/* harmony export */ });\n/* harmony import */ var _headers_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./headers.js */ \"./node_modules/node-fetch/src/headers.js\");\n/* harmony import */ var _body_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./body.js */ \"./node_modules/node-fetch/src/body.js\");\n/* harmony import */ var _utils_is_redirect_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils/is-redirect.js */ \"./node_modules/node-fetch/src/utils/is-redirect.js\");\n/**\n * Response.js\n *\n * Response class provides content decoding\n */\n\n\n\n\n\nconst INTERNALS = Symbol('Response internals');\n\n/**\n * Response class\n *\n * Ref: https://fetch.spec.whatwg.org/#response-class\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nclass Response extends _body_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n\tconstructor(body = null, options = {}) {\n\t\tsuper(body, options);\n\n\t\t// eslint-disable-next-line no-eq-null, eqeqeq, no-negated-condition\n\t\tconst status = options.status != null ? options.status : 200;\n\n\t\tconst headers = new _headers_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](options.headers);\n\n\t\tif (body !== null && !headers.has('Content-Type')) {\n\t\t\tconst contentType = (0,_body_js__WEBPACK_IMPORTED_MODULE_0__.extractContentType)(body, this);\n\t\t\tif (contentType) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tthis[INTERNALS] = {\n\t\t\ttype: 'default',\n\t\t\turl: options.url,\n\t\t\tstatus,\n\t\t\tstatusText: options.statusText || '',\n\t\t\theaders,\n\t\t\tcounter: options.counter,\n\t\t\thighWaterMark: options.highWaterMark\n\t\t};\n\t}\n\n\tget type() {\n\t\treturn this[INTERNALS].type;\n\t}\n\n\tget url() {\n\t\treturn this[INTERNALS].url || '';\n\t}\n\n\tget status() {\n\t\treturn this[INTERNALS].status;\n\t}\n\n\t/**\n\t * Convenience property representing if the request ended normally\n\t */\n\tget ok() {\n\t\treturn this[INTERNALS].status >= 200 && this[INTERNALS].status < 300;\n\t}\n\n\tget redirected() {\n\t\treturn this[INTERNALS].counter > 0;\n\t}\n\n\tget statusText() {\n\t\treturn this[INTERNALS].statusText;\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS].headers;\n\t}\n\n\tget highWaterMark() {\n\t\treturn this[INTERNALS].highWaterMark;\n\t}\n\n\t/**\n\t * Clone this response\n\t *\n\t * @return  Response\n\t */\n\tclone() {\n\t\treturn new Response((0,_body_js__WEBPACK_IMPORTED_MODULE_0__.clone)(this, this.highWaterMark), {\n\t\t\ttype: this.type,\n\t\t\turl: this.url,\n\t\t\tstatus: this.status,\n\t\t\tstatusText: this.statusText,\n\t\t\theaders: this.headers,\n\t\t\tok: this.ok,\n\t\t\tredirected: this.redirected,\n\t\t\tsize: this.size,\n\t\t\thighWaterMark: this.highWaterMark\n\t\t});\n\t}\n\n\t/**\n\t * @param {string} url    The URL that the new response is to originate from.\n\t * @param {number} status An optional status code for the response (e.g., 302.)\n\t * @returns {Response}    A Response object.\n\t */\n\tstatic redirect(url, status = 302) {\n\t\tif (!(0,_utils_is_redirect_js__WEBPACK_IMPORTED_MODULE_2__.isRedirect)(status)) {\n\t\t\tthrow new RangeError('Failed to execute \"redirect\" on \"response\": Invalid status code');\n\t\t}\n\n\t\treturn new Response(null, {\n\t\t\theaders: {\n\t\t\t\tlocation: new URL(url).toString()\n\t\t\t},\n\t\t\tstatus\n\t\t});\n\t}\n\n\tstatic error() {\n\t\tconst response = new Response(null, {status: 0, statusText: ''});\n\t\tresponse[INTERNALS].type = 'error';\n\t\treturn response;\n\t}\n\n\tstatic json(data = undefined, init = {}) {\n\t\tconst body = JSON.stringify(data);\n\n\t\tif (body === undefined) {\n\t\t\tthrow new TypeError('data is not JSON serializable');\n\t\t}\n\n\t\tconst headers = new _headers_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](init && init.headers);\n\n\t\tif (!headers.has('content-type')) {\n\t\t\theaders.set('content-type', 'application/json');\n\t\t}\n\n\t\treturn new Response(body, {\n\t\t\t...init,\n\t\t\theaders\n\t\t});\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn 'Response';\n\t}\n}\n\nObject.defineProperties(Response.prototype, {\n\ttype: {enumerable: true},\n\turl: {enumerable: true},\n\tstatus: {enumerable: true},\n\tok: {enumerable: true},\n\tredirected: {enumerable: true},\n\tstatusText: {enumerable: true},\n\theaders: {enumerable: true},\n\tclone: {enumerable: true}\n});\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/response.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/utils/get-search.js":
/*!*********************************************************!*\
  !*** ./node_modules/node-fetch/src/utils/get-search.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getSearch\": () => (/* binding */ getSearch)\n/* harmony export */ });\nconst getSearch = parsedURL => {\n\tif (parsedURL.search) {\n\t\treturn parsedURL.search;\n\t}\n\n\tconst lastOffset = parsedURL.href.length - 1;\n\tconst hash = parsedURL.hash || (parsedURL.href[lastOffset] === '#' ? '#' : '');\n\treturn parsedURL.href[lastOffset - hash.length] === '?' ? '?' : '';\n};\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/utils/get-search.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/utils/is-redirect.js":
/*!**********************************************************!*\
  !*** ./node_modules/node-fetch/src/utils/is-redirect.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isRedirect\": () => (/* binding */ isRedirect)\n/* harmony export */ });\nconst redirectStatus = new Set([301, 302, 303, 307, 308]);\n\n/**\n * Redirect code matching\n *\n * @param {number} code - Status code\n * @return {boolean}\n */\nconst isRedirect = code => {\n\treturn redirectStatus.has(code);\n};\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/utils/is-redirect.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/utils/is.js":
/*!*************************************************!*\
  !*** ./node_modules/node-fetch/src/utils/is.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAbortSignal\": () => (/* binding */ isAbortSignal),\n/* harmony export */   \"isBlob\": () => (/* binding */ isBlob),\n/* harmony export */   \"isDomainOrSubdomain\": () => (/* binding */ isDomainOrSubdomain),\n/* harmony export */   \"isSameProtocol\": () => (/* binding */ isSameProtocol),\n/* harmony export */   \"isURLSearchParameters\": () => (/* binding */ isURLSearchParameters)\n/* harmony export */ });\n/**\n * Is.js\n *\n * Object type checks.\n */\n\nconst NAME = Symbol.toStringTag;\n\n/**\n * Check if `obj` is a URLSearchParams object\n * ref: https://github.com/node-fetch/node-fetch/issues/296#issuecomment-307598143\n * @param {*} object - Object to check for\n * @return {boolean}\n */\nconst isURLSearchParameters = object => {\n\treturn (\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.append === 'function' &&\n\t\ttypeof object.delete === 'function' &&\n\t\ttypeof object.get === 'function' &&\n\t\ttypeof object.getAll === 'function' &&\n\t\ttypeof object.has === 'function' &&\n\t\ttypeof object.set === 'function' &&\n\t\ttypeof object.sort === 'function' &&\n\t\tobject[NAME] === 'URLSearchParams'\n\t);\n};\n\n/**\n * Check if `object` is a W3C `Blob` object (which `File` inherits from)\n * @param {*} object - Object to check for\n * @return {boolean}\n */\nconst isBlob = object => {\n\treturn (\n\t\tobject &&\n\t\ttypeof object === 'object' &&\n\t\ttypeof object.arrayBuffer === 'function' &&\n\t\ttypeof object.type === 'string' &&\n\t\ttypeof object.stream === 'function' &&\n\t\ttypeof object.constructor === 'function' &&\n\t\t/^(Blob|File)$/.test(object[NAME])\n\t);\n};\n\n/**\n * Check if `obj` is an instance of AbortSignal.\n * @param {*} object - Object to check for\n * @return {boolean}\n */\nconst isAbortSignal = object => {\n\treturn (\n\t\ttypeof object === 'object' && (\n\t\t\tobject[NAME] === 'AbortSignal' ||\n\t\t\tobject[NAME] === 'EventTarget'\n\t\t)\n\t);\n};\n\n/**\n * isDomainOrSubdomain reports whether sub is a subdomain (or exact match) of\n * the parent domain.\n *\n * Both domains must already be in canonical form.\n * @param {string|URL} original\n * @param {string|URL} destination\n */\nconst isDomainOrSubdomain = (destination, original) => {\n\tconst orig = new URL(original).hostname;\n\tconst dest = new URL(destination).hostname;\n\n\treturn orig === dest || orig.endsWith(`.${dest}`);\n};\n\n/**\n * isSameProtocol reports whether the two provided URLs use the same protocol.\n *\n * Both domains must already be in canonical form.\n * @param {string|URL} original\n * @param {string|URL} destination\n */\nconst isSameProtocol = (destination, original) => {\n\tconst orig = new URL(original).protocol;\n\tconst dest = new URL(destination).protocol;\n\n\treturn orig === dest;\n};\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/utils/is.js?");

/***/ }),

/***/ "./node_modules/node-fetch/src/utils/referrer.js":
/*!*******************************************************!*\
  !*** ./node_modules/node-fetch/src/utils/referrer.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DEFAULT_REFERRER_POLICY\": () => (/* binding */ DEFAULT_REFERRER_POLICY),\n/* harmony export */   \"ReferrerPolicy\": () => (/* binding */ ReferrerPolicy),\n/* harmony export */   \"determineRequestsReferrer\": () => (/* binding */ determineRequestsReferrer),\n/* harmony export */   \"isOriginPotentiallyTrustworthy\": () => (/* binding */ isOriginPotentiallyTrustworthy),\n/* harmony export */   \"isUrlPotentiallyTrustworthy\": () => (/* binding */ isUrlPotentiallyTrustworthy),\n/* harmony export */   \"parseReferrerPolicyFromHeader\": () => (/* binding */ parseReferrerPolicyFromHeader),\n/* harmony export */   \"stripURLForUseAsAReferrer\": () => (/* binding */ stripURLForUseAsAReferrer),\n/* harmony export */   \"validateReferrerPolicy\": () => (/* binding */ validateReferrerPolicy)\n/* harmony export */ });\n/* harmony import */ var node_net__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:net */ \"node:net\");\n\n\n/**\n * @external URL\n * @see {@link https://developer.mozilla.org/en-US/docs/Web/API/URL|URL}\n */\n\n/**\n * @module utils/referrer\n * @private\n */\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#strip-url|Referrer Policy Â§8.4. Strip url for use as a referrer}\n * @param {string} URL\n * @param {boolean} [originOnly=false]\n */\nfunction stripURLForUseAsAReferrer(url, originOnly = false) {\n\t// 1. If url is null, return no referrer.\n\tif (url == null) { // eslint-disable-line no-eq-null, eqeqeq\n\t\treturn 'no-referrer';\n\t}\n\n\turl = new URL(url);\n\n\t// 2. If url's scheme is a local scheme, then return no referrer.\n\tif (/^(about|blob|data):$/.test(url.protocol)) {\n\t\treturn 'no-referrer';\n\t}\n\n\t// 3. Set url's username to the empty string.\n\turl.username = '';\n\n\t// 4. Set url's password to null.\n\t// Note: `null` appears to be a mistake as this actually results in the password being `\"null\"`.\n\turl.password = '';\n\n\t// 5. Set url's fragment to null.\n\t// Note: `null` appears to be a mistake as this actually results in the fragment being `\"#null\"`.\n\turl.hash = '';\n\n\t// 6. If the origin-only flag is true, then:\n\tif (originOnly) {\n\t\t// 6.1. Set url's path to null.\n\t\t// Note: `null` appears to be a mistake as this actually results in the path being `\"/null\"`.\n\t\turl.pathname = '';\n\n\t\t// 6.2. Set url's query to null.\n\t\t// Note: `null` appears to be a mistake as this actually results in the query being `\"?null\"`.\n\t\turl.search = '';\n\t}\n\n\t// 7. Return url.\n\treturn url;\n}\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#enumdef-referrerpolicy|enum ReferrerPolicy}\n */\nconst ReferrerPolicy = new Set([\n\t'',\n\t'no-referrer',\n\t'no-referrer-when-downgrade',\n\t'same-origin',\n\t'origin',\n\t'strict-origin',\n\t'origin-when-cross-origin',\n\t'strict-origin-when-cross-origin',\n\t'unsafe-url'\n]);\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#default-referrer-policy|default referrer policy}\n */\nconst DEFAULT_REFERRER_POLICY = 'strict-origin-when-cross-origin';\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#referrer-policies|Referrer Policy Â§3. Referrer Policies}\n * @param {string} referrerPolicy\n * @returns {string} referrerPolicy\n */\nfunction validateReferrerPolicy(referrerPolicy) {\n\tif (!ReferrerPolicy.has(referrerPolicy)) {\n\t\tthrow new TypeError(`Invalid referrerPolicy: ${referrerPolicy}`);\n\t}\n\n\treturn referrerPolicy;\n}\n\n/**\n * @see {@link https://w3c.github.io/webappsec-secure-contexts/#is-origin-trustworthy|Referrer Policy Â§3.2. Is origin potentially trustworthy?}\n * @param {external:URL} url\n * @returns `true`: \"Potentially Trustworthy\", `false`: \"Not Trustworthy\"\n */\nfunction isOriginPotentiallyTrustworthy(url) {\n\t// 1. If origin is an opaque origin, return \"Not Trustworthy\".\n\t// Not applicable\n\n\t// 2. Assert: origin is a tuple origin.\n\t// Not for implementations\n\n\t// 3. If origin's scheme is either \"https\" or \"wss\", return \"Potentially Trustworthy\".\n\tif (/^(http|ws)s:$/.test(url.protocol)) {\n\t\treturn true;\n\t}\n\n\t// 4. If origin's host component matches one of the CIDR notations 127.0.0.0/8 or ::1/128 [RFC4632], return \"Potentially Trustworthy\".\n\tconst hostIp = url.host.replace(/(^\\[)|(]$)/g, '');\n\tconst hostIPVersion = (0,node_net__WEBPACK_IMPORTED_MODULE_0__.isIP)(hostIp);\n\n\tif (hostIPVersion === 4 && /^127\\./.test(hostIp)) {\n\t\treturn true;\n\t}\n\n\tif (hostIPVersion === 6 && /^(((0+:){7})|(::(0+:){0,6}))0*1$/.test(hostIp)) {\n\t\treturn true;\n\t}\n\n\t// 5. If origin's host component is \"localhost\" or falls within \".localhost\", and the user agent conforms to the name resolution rules in [let-localhost-be-localhost], return \"Potentially Trustworthy\".\n\t// We are returning FALSE here because we cannot ensure conformance to\n\t// let-localhost-be-loalhost (https://tools.ietf.org/html/draft-west-let-localhost-be-localhost)\n\tif (url.host === 'localhost' || url.host.endsWith('.localhost')) {\n\t\treturn false;\n\t}\n\n\t// 6. If origin's scheme component is file, return \"Potentially Trustworthy\".\n\tif (url.protocol === 'file:') {\n\t\treturn true;\n\t}\n\n\t// 7. If origin's scheme component is one which the user agent considers to be authenticated, return \"Potentially Trustworthy\".\n\t// Not supported\n\n\t// 8. If origin has been configured as a trustworthy origin, return \"Potentially Trustworthy\".\n\t// Not supported\n\n\t// 9. Return \"Not Trustworthy\".\n\treturn false;\n}\n\n/**\n * @see {@link https://w3c.github.io/webappsec-secure-contexts/#is-url-trustworthy|Referrer Policy Â§3.3. Is url potentially trustworthy?}\n * @param {external:URL} url\n * @returns `true`: \"Potentially Trustworthy\", `false`: \"Not Trustworthy\"\n */\nfunction isUrlPotentiallyTrustworthy(url) {\n\t// 1. If url is \"about:blank\" or \"about:srcdoc\", return \"Potentially Trustworthy\".\n\tif (/^about:(blank|srcdoc)$/.test(url)) {\n\t\treturn true;\n\t}\n\n\t// 2. If url's scheme is \"data\", return \"Potentially Trustworthy\".\n\tif (url.protocol === 'data:') {\n\t\treturn true;\n\t}\n\n\t// Note: The origin of blob: and filesystem: URLs is the origin of the context in which they were\n\t// created. Therefore, blobs created in a trustworthy origin will themselves be potentially\n\t// trustworthy.\n\tif (/^(blob|filesystem):$/.test(url.protocol)) {\n\t\treturn true;\n\t}\n\n\t// 3. Return the result of executing Â§3.2 Is origin potentially trustworthy? on url's origin.\n\treturn isOriginPotentiallyTrustworthy(url);\n}\n\n/**\n * Modifies the referrerURL to enforce any extra security policy considerations.\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer|Referrer Policy Â§8.3. Determine request's Referrer}, step 7\n * @callback module:utils/referrer~referrerURLCallback\n * @param {external:URL} referrerURL\n * @returns {external:URL} modified referrerURL\n */\n\n/**\n * Modifies the referrerOrigin to enforce any extra security policy considerations.\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer|Referrer Policy Â§8.3. Determine request's Referrer}, step 7\n * @callback module:utils/referrer~referrerOriginCallback\n * @param {external:URL} referrerOrigin\n * @returns {external:URL} modified referrerOrigin\n */\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer|Referrer Policy Â§8.3. Determine request's Referrer}\n * @param {Request} request\n * @param {object} o\n * @param {module:utils/referrer~referrerURLCallback} o.referrerURLCallback\n * @param {module:utils/referrer~referrerOriginCallback} o.referrerOriginCallback\n * @returns {external:URL} Request's referrer\n */\nfunction determineRequestsReferrer(request, {referrerURLCallback, referrerOriginCallback} = {}) {\n\t// There are 2 notes in the specification about invalid pre-conditions.  We return null, here, for\n\t// these cases:\n\t// > Note: If request's referrer is \"no-referrer\", Fetch will not call into this algorithm.\n\t// > Note: If request's referrer policy is the empty string, Fetch will not call into this\n\t// > algorithm.\n\tif (request.referrer === 'no-referrer' || request.referrerPolicy === '') {\n\t\treturn null;\n\t}\n\n\t// 1. Let policy be request's associated referrer policy.\n\tconst policy = request.referrerPolicy;\n\n\t// 2. Let environment be request's client.\n\t// not applicable to node.js\n\n\t// 3. Switch on request's referrer:\n\tif (request.referrer === 'about:client') {\n\t\treturn 'no-referrer';\n\t}\n\n\t// \"a URL\": Let referrerSource be request's referrer.\n\tconst referrerSource = request.referrer;\n\n\t// 4. Let request's referrerURL be the result of stripping referrerSource for use as a referrer.\n\tlet referrerURL = stripURLForUseAsAReferrer(referrerSource);\n\n\t// 5. Let referrerOrigin be the result of stripping referrerSource for use as a referrer, with the\n\t//    origin-only flag set to true.\n\tlet referrerOrigin = stripURLForUseAsAReferrer(referrerSource, true);\n\n\t// 6. If the result of serializing referrerURL is a string whose length is greater than 4096, set\n\t//    referrerURL to referrerOrigin.\n\tif (referrerURL.toString().length > 4096) {\n\t\treferrerURL = referrerOrigin;\n\t}\n\n\t// 7. The user agent MAY alter referrerURL or referrerOrigin at this point to enforce arbitrary\n\t//    policy considerations in the interests of minimizing data leakage. For example, the user\n\t//    agent could strip the URL down to an origin, modify its host, replace it with an empty\n\t//    string, etc.\n\tif (referrerURLCallback) {\n\t\treferrerURL = referrerURLCallback(referrerURL);\n\t}\n\n\tif (referrerOriginCallback) {\n\t\treferrerOrigin = referrerOriginCallback(referrerOrigin);\n\t}\n\n\t// 8.Execute the statements corresponding to the value of policy:\n\tconst currentURL = new URL(request.url);\n\n\tswitch (policy) {\n\t\tcase 'no-referrer':\n\t\t\treturn 'no-referrer';\n\n\t\tcase 'origin':\n\t\t\treturn referrerOrigin;\n\n\t\tcase 'unsafe-url':\n\t\t\treturn referrerURL;\n\n\t\tcase 'strict-origin':\n\t\t\t// 1. If referrerURL is a potentially trustworthy URL and request's current URL is not a\n\t\t\t//    potentially trustworthy URL, then return no referrer.\n\t\t\tif (isUrlPotentiallyTrustworthy(referrerURL) && !isUrlPotentiallyTrustworthy(currentURL)) {\n\t\t\t\treturn 'no-referrer';\n\t\t\t}\n\n\t\t\t// 2. Return referrerOrigin.\n\t\t\treturn referrerOrigin.toString();\n\n\t\tcase 'strict-origin-when-cross-origin':\n\t\t\t// 1. If the origin of referrerURL and the origin of request's current URL are the same, then\n\t\t\t//    return referrerURL.\n\t\t\tif (referrerURL.origin === currentURL.origin) {\n\t\t\t\treturn referrerURL;\n\t\t\t}\n\n\t\t\t// 2. If referrerURL is a potentially trustworthy URL and request's current URL is not a\n\t\t\t//    potentially trustworthy URL, then return no referrer.\n\t\t\tif (isUrlPotentiallyTrustworthy(referrerURL) && !isUrlPotentiallyTrustworthy(currentURL)) {\n\t\t\t\treturn 'no-referrer';\n\t\t\t}\n\n\t\t\t// 3. Return referrerOrigin.\n\t\t\treturn referrerOrigin;\n\n\t\tcase 'same-origin':\n\t\t\t// 1. If the origin of referrerURL and the origin of request's current URL are the same, then\n\t\t\t//    return referrerURL.\n\t\t\tif (referrerURL.origin === currentURL.origin) {\n\t\t\t\treturn referrerURL;\n\t\t\t}\n\n\t\t\t// 2. Return no referrer.\n\t\t\treturn 'no-referrer';\n\n\t\tcase 'origin-when-cross-origin':\n\t\t\t// 1. If the origin of referrerURL and the origin of request's current URL are the same, then\n\t\t\t//    return referrerURL.\n\t\t\tif (referrerURL.origin === currentURL.origin) {\n\t\t\t\treturn referrerURL;\n\t\t\t}\n\n\t\t\t// Return referrerOrigin.\n\t\t\treturn referrerOrigin;\n\n\t\tcase 'no-referrer-when-downgrade':\n\t\t\t// 1. If referrerURL is a potentially trustworthy URL and request's current URL is not a\n\t\t\t//    potentially trustworthy URL, then return no referrer.\n\t\t\tif (isUrlPotentiallyTrustworthy(referrerURL) && !isUrlPotentiallyTrustworthy(currentURL)) {\n\t\t\t\treturn 'no-referrer';\n\t\t\t}\n\n\t\t\t// 2. Return referrerURL.\n\t\t\treturn referrerURL;\n\n\t\tdefault:\n\t\t\tthrow new TypeError(`Invalid referrerPolicy: ${policy}`);\n\t}\n}\n\n/**\n * @see {@link https://w3c.github.io/webappsec-referrer-policy/#parse-referrer-policy-from-header|Referrer Policy Â§8.1. Parse a referrer policy from a Referrer-Policy header}\n * @param {Headers} headers Response headers\n * @returns {string} policy\n */\nfunction parseReferrerPolicyFromHeader(headers) {\n\t// 1. Let policy-tokens be the result of extracting header list values given `Referrer-Policy`\n\t//    and responseâs header list.\n\tconst policyTokens = (headers.get('referrer-policy') || '').split(/[,\\s]+/);\n\n\t// 2. Let policy be the empty string.\n\tlet policy = '';\n\n\t// 3. For each token in policy-tokens, if token is a referrer policy and token is not the empty\n\t//    string, then set policy to token.\n\t// Note: This algorithm loops over multiple policy values to allow deployment of new policy\n\t// values with fallbacks for older user agents, as described in Â§ 11.1 Unknown Policy Values.\n\tfor (const token of policyTokens) {\n\t\tif (token && ReferrerPolicy.has(token)) {\n\t\t\tpolicy = token;\n\t\t}\n\t}\n\n\t// 4. Return policy.\n\treturn policy;\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/node-fetch/src/utils/referrer.js?");

/***/ }),

/***/ "./node_modules/query-string/base.js":
/*!*******************************************!*\
  !*** ./node_modules/query-string/base.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"exclude\": () => (/* binding */ exclude),\n/* harmony export */   \"extract\": () => (/* binding */ extract),\n/* harmony export */   \"parse\": () => (/* binding */ parse),\n/* harmony export */   \"parseUrl\": () => (/* binding */ parseUrl),\n/* harmony export */   \"pick\": () => (/* binding */ pick),\n/* harmony export */   \"stringify\": () => (/* binding */ stringify),\n/* harmony export */   \"stringifyUrl\": () => (/* binding */ stringifyUrl)\n/* harmony export */ });\n/* harmony import */ var decode_uri_component__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! decode-uri-component */ \"./node_modules/decode-uri-component/index.js\");\n/* harmony import */ var split_on_first__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! split-on-first */ \"./node_modules/split-on-first/index.js\");\n/* harmony import */ var filter_obj__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! filter-obj */ \"./node_modules/filter-obj/index.js\");\n\n\n\n\nconst isNullOrUndefined = value => value === null || value === undefined;\n\n// eslint-disable-next-line unicorn/prefer-code-point\nconst strictUriEncode = string => encodeURIComponent(string).replace(/[!'()*]/g, x => `%${x.charCodeAt(0).toString(16).toUpperCase()}`);\n\nconst encodeFragmentIdentifier = Symbol('encodeFragmentIdentifier');\n\nfunction encoderForArrayFormat(options) {\n\tswitch (options.arrayFormat) {\n\t\tcase 'index': {\n\t\t\treturn key => (result, value) => {\n\t\t\t\tconst index = result.length;\n\n\t\t\t\tif (\n\t\t\t\t\tvalue === undefined\n\t\t\t\t\t|| (options.skipNull && value === null)\n\t\t\t\t\t|| (options.skipEmptyString && value === '')\n\t\t\t\t) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\n\t\t\t\tif (value === null) {\n\t\t\t\t\treturn [\n\t\t\t\t\t\t...result, [encode(key, options), '[', index, ']'].join(''),\n\t\t\t\t\t];\n\t\t\t\t}\n\n\t\t\t\treturn [\n\t\t\t\t\t...result,\n\t\t\t\t\t[encode(key, options), '[', encode(index, options), ']=', encode(value, options)].join(''),\n\t\t\t\t];\n\t\t\t};\n\t\t}\n\n\t\tcase 'bracket': {\n\t\t\treturn key => (result, value) => {\n\t\t\t\tif (\n\t\t\t\t\tvalue === undefined\n\t\t\t\t\t|| (options.skipNull && value === null)\n\t\t\t\t\t|| (options.skipEmptyString && value === '')\n\t\t\t\t) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\n\t\t\t\tif (value === null) {\n\t\t\t\t\treturn [\n\t\t\t\t\t\t...result,\n\t\t\t\t\t\t[encode(key, options), '[]'].join(''),\n\t\t\t\t\t];\n\t\t\t\t}\n\n\t\t\t\treturn [\n\t\t\t\t\t...result,\n\t\t\t\t\t[encode(key, options), '[]=', encode(value, options)].join(''),\n\t\t\t\t];\n\t\t\t};\n\t\t}\n\n\t\tcase 'colon-list-separator': {\n\t\t\treturn key => (result, value) => {\n\t\t\t\tif (\n\t\t\t\t\tvalue === undefined\n\t\t\t\t\t|| (options.skipNull && value === null)\n\t\t\t\t\t|| (options.skipEmptyString && value === '')\n\t\t\t\t) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\n\t\t\t\tif (value === null) {\n\t\t\t\t\treturn [\n\t\t\t\t\t\t...result,\n\t\t\t\t\t\t[encode(key, options), ':list='].join(''),\n\t\t\t\t\t];\n\t\t\t\t}\n\n\t\t\t\treturn [\n\t\t\t\t\t...result,\n\t\t\t\t\t[encode(key, options), ':list=', encode(value, options)].join(''),\n\t\t\t\t];\n\t\t\t};\n\t\t}\n\n\t\tcase 'comma':\n\t\tcase 'separator':\n\t\tcase 'bracket-separator': {\n\t\t\tconst keyValueSep = options.arrayFormat === 'bracket-separator'\n\t\t\t\t? '[]='\n\t\t\t\t: '=';\n\n\t\t\treturn key => (result, value) => {\n\t\t\t\tif (\n\t\t\t\t\tvalue === undefined\n\t\t\t\t\t|| (options.skipNull && value === null)\n\t\t\t\t\t|| (options.skipEmptyString && value === '')\n\t\t\t\t) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\n\t\t\t\t// Translate null to an empty string so that it doesn't serialize as 'null'\n\t\t\t\tvalue = value === null ? '' : value;\n\n\t\t\t\tif (result.length === 0) {\n\t\t\t\t\treturn [[encode(key, options), keyValueSep, encode(value, options)].join('')];\n\t\t\t\t}\n\n\t\t\t\treturn [[result, encode(value, options)].join(options.arrayFormatSeparator)];\n\t\t\t};\n\t\t}\n\n\t\tdefault: {\n\t\t\treturn key => (result, value) => {\n\t\t\t\tif (\n\t\t\t\t\tvalue === undefined\n\t\t\t\t\t|| (options.skipNull && value === null)\n\t\t\t\t\t|| (options.skipEmptyString && value === '')\n\t\t\t\t) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\n\t\t\t\tif (value === null) {\n\t\t\t\t\treturn [\n\t\t\t\t\t\t...result,\n\t\t\t\t\t\tencode(key, options),\n\t\t\t\t\t];\n\t\t\t\t}\n\n\t\t\t\treturn [\n\t\t\t\t\t...result,\n\t\t\t\t\t[encode(key, options), '=', encode(value, options)].join(''),\n\t\t\t\t];\n\t\t\t};\n\t\t}\n\t}\n}\n\nfunction parserForArrayFormat(options) {\n\tlet result;\n\n\tswitch (options.arrayFormat) {\n\t\tcase 'index': {\n\t\t\treturn (key, value, accumulator) => {\n\t\t\t\tresult = /\\[(\\d*)]$/.exec(key);\n\n\t\t\t\tkey = key.replace(/\\[\\d*]$/, '');\n\n\t\t\t\tif (!result) {\n\t\t\t\t\taccumulator[key] = value;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (accumulator[key] === undefined) {\n\t\t\t\t\taccumulator[key] = {};\n\t\t\t\t}\n\n\t\t\t\taccumulator[key][result[1]] = value;\n\t\t\t};\n\t\t}\n\n\t\tcase 'bracket': {\n\t\t\treturn (key, value, accumulator) => {\n\t\t\t\tresult = /(\\[])$/.exec(key);\n\t\t\t\tkey = key.replace(/\\[]$/, '');\n\n\t\t\t\tif (!result) {\n\t\t\t\t\taccumulator[key] = value;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (accumulator[key] === undefined) {\n\t\t\t\t\taccumulator[key] = [value];\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\taccumulator[key] = [...accumulator[key], value];\n\t\t\t};\n\t\t}\n\n\t\tcase 'colon-list-separator': {\n\t\t\treturn (key, value, accumulator) => {\n\t\t\t\tresult = /(:list)$/.exec(key);\n\t\t\t\tkey = key.replace(/:list$/, '');\n\n\t\t\t\tif (!result) {\n\t\t\t\t\taccumulator[key] = value;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tif (accumulator[key] === undefined) {\n\t\t\t\t\taccumulator[key] = [value];\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\taccumulator[key] = [...accumulator[key], value];\n\t\t\t};\n\t\t}\n\n\t\tcase 'comma':\n\t\tcase 'separator': {\n\t\t\treturn (key, value, accumulator) => {\n\t\t\t\tconst isArray = typeof value === 'string' && value.includes(options.arrayFormatSeparator);\n\t\t\t\tconst isEncodedArray = (typeof value === 'string' && !isArray && decode(value, options).includes(options.arrayFormatSeparator));\n\t\t\t\tvalue = isEncodedArray ? decode(value, options) : value;\n\t\t\t\tconst newValue = isArray || isEncodedArray ? value.split(options.arrayFormatSeparator).map(item => decode(item, options)) : (value === null ? value : decode(value, options));\n\t\t\t\taccumulator[key] = newValue;\n\t\t\t};\n\t\t}\n\n\t\tcase 'bracket-separator': {\n\t\t\treturn (key, value, accumulator) => {\n\t\t\t\tconst isArray = /(\\[])$/.test(key);\n\t\t\t\tkey = key.replace(/\\[]$/, '');\n\n\t\t\t\tif (!isArray) {\n\t\t\t\t\taccumulator[key] = value ? decode(value, options) : value;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\tconst arrayValue = value === null\n\t\t\t\t\t? []\n\t\t\t\t\t: value.split(options.arrayFormatSeparator).map(item => decode(item, options));\n\n\t\t\t\tif (accumulator[key] === undefined) {\n\t\t\t\t\taccumulator[key] = arrayValue;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\taccumulator[key] = [...accumulator[key], ...arrayValue];\n\t\t\t};\n\t\t}\n\n\t\tdefault: {\n\t\t\treturn (key, value, accumulator) => {\n\t\t\t\tif (accumulator[key] === undefined) {\n\t\t\t\t\taccumulator[key] = value;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\n\t\t\t\taccumulator[key] = [...[accumulator[key]].flat(), value];\n\t\t\t};\n\t\t}\n\t}\n}\n\nfunction validateArrayFormatSeparator(value) {\n\tif (typeof value !== 'string' || value.length !== 1) {\n\t\tthrow new TypeError('arrayFormatSeparator must be single character string');\n\t}\n}\n\nfunction encode(value, options) {\n\tif (options.encode) {\n\t\treturn options.strict ? strictUriEncode(value) : encodeURIComponent(value);\n\t}\n\n\treturn value;\n}\n\nfunction decode(value, options) {\n\tif (options.decode) {\n\t\treturn (0,decode_uri_component__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(value);\n\t}\n\n\treturn value;\n}\n\nfunction keysSorter(input) {\n\tif (Array.isArray(input)) {\n\t\treturn input.sort();\n\t}\n\n\tif (typeof input === 'object') {\n\t\treturn keysSorter(Object.keys(input))\n\t\t\t.sort((a, b) => Number(a) - Number(b))\n\t\t\t.map(key => input[key]);\n\t}\n\n\treturn input;\n}\n\nfunction removeHash(input) {\n\tconst hashStart = input.indexOf('#');\n\tif (hashStart !== -1) {\n\t\tinput = input.slice(0, hashStart);\n\t}\n\n\treturn input;\n}\n\nfunction getHash(url) {\n\tlet hash = '';\n\tconst hashStart = url.indexOf('#');\n\tif (hashStart !== -1) {\n\t\thash = url.slice(hashStart);\n\t}\n\n\treturn hash;\n}\n\nfunction parseValue(value, options) {\n\tif (options.parseNumbers && !Number.isNaN(Number(value)) && (typeof value === 'string' && value.trim() !== '')) {\n\t\tvalue = Number(value);\n\t} else if (options.parseBooleans && value !== null && (value.toLowerCase() === 'true' || value.toLowerCase() === 'false')) {\n\t\tvalue = value.toLowerCase() === 'true';\n\t}\n\n\treturn value;\n}\n\nfunction extract(input) {\n\tinput = removeHash(input);\n\tconst queryStart = input.indexOf('?');\n\tif (queryStart === -1) {\n\t\treturn '';\n\t}\n\n\treturn input.slice(queryStart + 1);\n}\n\nfunction parse(query, options) {\n\toptions = {\n\t\tdecode: true,\n\t\tsort: true,\n\t\tarrayFormat: 'none',\n\t\tarrayFormatSeparator: ',',\n\t\tparseNumbers: false,\n\t\tparseBooleans: false,\n\t\t...options,\n\t};\n\n\tvalidateArrayFormatSeparator(options.arrayFormatSeparator);\n\n\tconst formatter = parserForArrayFormat(options);\n\n\t// Create an object with no prototype\n\tconst returnValue = Object.create(null);\n\n\tif (typeof query !== 'string') {\n\t\treturn returnValue;\n\t}\n\n\tquery = query.trim().replace(/^[?#&]/, '');\n\n\tif (!query) {\n\t\treturn returnValue;\n\t}\n\n\tfor (const parameter of query.split('&')) {\n\t\tif (parameter === '') {\n\t\t\tcontinue;\n\t\t}\n\n\t\tconst parameter_ = options.decode ? parameter.replace(/\\+/g, ' ') : parameter;\n\n\t\tlet [key, value] = (0,split_on_first__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(parameter_, '=');\n\n\t\tif (key === undefined) {\n\t\t\tkey = parameter_;\n\t\t}\n\n\t\t// Missing `=` should be `null`:\n\t\t// http://w3.org/TR/2012/WD-url-20120524/#collect-url-parameters\n\t\tvalue = value === undefined ? null : (['comma', 'separator', 'bracket-separator'].includes(options.arrayFormat) ? value : decode(value, options));\n\t\tformatter(decode(key, options), value, returnValue);\n\t}\n\n\tfor (const [key, value] of Object.entries(returnValue)) {\n\t\tif (typeof value === 'object' && value !== null) {\n\t\t\tfor (const [key2, value2] of Object.entries(value)) {\n\t\t\t\tvalue[key2] = parseValue(value2, options);\n\t\t\t}\n\t\t} else {\n\t\t\treturnValue[key] = parseValue(value, options);\n\t\t}\n\t}\n\n\tif (options.sort === false) {\n\t\treturn returnValue;\n\t}\n\n\t// TODO: Remove the use of `reduce`.\n\t// eslint-disable-next-line unicorn/no-array-reduce\n\treturn (options.sort === true ? Object.keys(returnValue).sort() : Object.keys(returnValue).sort(options.sort)).reduce((result, key) => {\n\t\tconst value = returnValue[key];\n\t\tif (Boolean(value) && typeof value === 'object' && !Array.isArray(value)) {\n\t\t\t// Sort object keys, not values\n\t\t\tresult[key] = keysSorter(value);\n\t\t} else {\n\t\t\tresult[key] = value;\n\t\t}\n\n\t\treturn result;\n\t}, Object.create(null));\n}\n\nfunction stringify(object, options) {\n\tif (!object) {\n\t\treturn '';\n\t}\n\n\toptions = {encode: true,\n\t\tstrict: true,\n\t\tarrayFormat: 'none',\n\t\tarrayFormatSeparator: ',', ...options};\n\n\tvalidateArrayFormatSeparator(options.arrayFormatSeparator);\n\n\tconst shouldFilter = key => (\n\t\t(options.skipNull && isNullOrUndefined(object[key]))\n\t\t|| (options.skipEmptyString && object[key] === '')\n\t);\n\n\tconst formatter = encoderForArrayFormat(options);\n\n\tconst objectCopy = {};\n\n\tfor (const [key, value] of Object.entries(object)) {\n\t\tif (!shouldFilter(key)) {\n\t\t\tobjectCopy[key] = value;\n\t\t}\n\t}\n\n\tconst keys = Object.keys(objectCopy);\n\n\tif (options.sort !== false) {\n\t\tkeys.sort(options.sort);\n\t}\n\n\treturn keys.map(key => {\n\t\tconst value = object[key];\n\n\t\tif (value === undefined) {\n\t\t\treturn '';\n\t\t}\n\n\t\tif (value === null) {\n\t\t\treturn encode(key, options);\n\t\t}\n\n\t\tif (Array.isArray(value)) {\n\t\t\tif (value.length === 0 && options.arrayFormat === 'bracket-separator') {\n\t\t\t\treturn encode(key, options) + '[]';\n\t\t\t}\n\n\t\t\treturn value\n\t\t\t\t.reduce(formatter(key), [])\n\t\t\t\t.join('&');\n\t\t}\n\n\t\treturn encode(key, options) + '=' + encode(value, options);\n\t}).filter(x => x.length > 0).join('&');\n}\n\nfunction parseUrl(url, options) {\n\toptions = {\n\t\tdecode: true,\n\t\t...options,\n\t};\n\n\tlet [url_, hash] = (0,split_on_first__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(url, '#');\n\n\tif (url_ === undefined) {\n\t\turl_ = url;\n\t}\n\n\treturn {\n\t\turl: url_?.split('?')?.[0] ?? '',\n\t\tquery: parse(extract(url), options),\n\t\t...(options && options.parseFragmentIdentifier && hash ? {fragmentIdentifier: decode(hash, options)} : {}),\n\t};\n}\n\nfunction stringifyUrl(object, options) {\n\toptions = {\n\t\tencode: true,\n\t\tstrict: true,\n\t\t[encodeFragmentIdentifier]: true,\n\t\t...options,\n\t};\n\n\tconst url = removeHash(object.url).split('?')[0] || '';\n\tconst queryFromUrl = extract(object.url);\n\n\tconst query = {\n\t\t...parse(queryFromUrl, {sort: false}),\n\t\t...object.query,\n\t};\n\n\tlet queryString = stringify(query, options);\n\tif (queryString) {\n\t\tqueryString = `?${queryString}`;\n\t}\n\n\tlet hash = getHash(object.url);\n\tif (object.fragmentIdentifier) {\n\t\tconst urlObjectForFragmentEncode = new URL(url);\n\t\turlObjectForFragmentEncode.hash = object.fragmentIdentifier;\n\t\thash = options[encodeFragmentIdentifier] ? urlObjectForFragmentEncode.hash : `#${object.fragmentIdentifier}`;\n\t}\n\n\treturn `${url}${queryString}${hash}`;\n}\n\nfunction pick(input, filter, options) {\n\toptions = {\n\t\tparseFragmentIdentifier: true,\n\t\t[encodeFragmentIdentifier]: false,\n\t\t...options,\n\t};\n\n\tconst {url, query, fragmentIdentifier} = parseUrl(input, options);\n\n\treturn stringifyUrl({\n\t\turl,\n\t\tquery: (0,filter_obj__WEBPACK_IMPORTED_MODULE_2__.includeKeys)(query, filter),\n\t\tfragmentIdentifier,\n\t}, options);\n}\n\nfunction exclude(input, filter, options) {\n\tconst exclusionFilter = Array.isArray(filter) ? key => !filter.includes(key) : (key, value) => !filter(key, value);\n\n\treturn pick(input, exclusionFilter, options);\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/query-string/base.js?");

/***/ }),

/***/ "./node_modules/query-string/index.js":
/*!********************************************!*\
  !*** ./node_modules/query-string/index.js ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _base_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./base.js */ \"./node_modules/query-string/base.js\");\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_base_js__WEBPACK_IMPORTED_MODULE_0__);\n\n\n//# sourceURL=webpack://next-work/./node_modules/query-string/index.js?");

/***/ }),

/***/ "./node_modules/split-on-first/index.js":
/*!**********************************************!*\
  !*** ./node_modules/split-on-first/index.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ splitOnFirst)\n/* harmony export */ });\nfunction splitOnFirst(string, separator) {\n\tif (!(typeof string === 'string' && typeof separator === 'string')) {\n\t\tthrow new TypeError('Expected the arguments to be of type `string`');\n\t}\n\n\tif (string === '' || separator === '') {\n\t\treturn [];\n\t}\n\n\tconst separatorIndex = string.indexOf(separator);\n\n\tif (separatorIndex === -1) {\n\t\treturn [];\n\t}\n\n\treturn [\n\t\tstring.slice(0, separatorIndex),\n\t\tstring.slice(separatorIndex + separator.length)\n\t];\n}\n\n\n//# sourceURL=webpack://next-work/./node_modules/split-on-first/index.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = __webpack_modules__;
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/ensure chunk */
/******/ 	(() => {
/******/ 		__webpack_require__.f = {};
/******/ 		// This file contains only the entry chunk.
/******/ 		// The chunk loading function for additional chunks
/******/ 		__webpack_require__.e = (chunkId) => {
/******/ 			return Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {
/******/ 				__webpack_require__.f[key](chunkId, promises);
/******/ 				return promises;
/******/ 			}, []));
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/get javascript chunk filename */
/******/ 	(() => {
/******/ 		// This function allow to reference async chunks
/******/ 		__webpack_require__.u = (chunkId) => {
/******/ 			// return url for filenames based on template
/******/ 			return "" + chunkId + ".nextWork.js";
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/require chunk loading */
/******/ 	(() => {
/******/ 		// no baseURI
/******/ 		
/******/ 		// object to store loaded chunks
/******/ 		// "1" means "loaded", otherwise not loaded yet
/******/ 		var installedChunks = {
/******/ 			"main": 1
/******/ 		};
/******/ 		
/******/ 		// no on chunks loaded
/******/ 		
/******/ 		var installChunk = (chunk) => {
/******/ 			var moreModules = chunk.modules, chunkIds = chunk.ids, runtime = chunk.runtime;
/******/ 			for(var moduleId in moreModules) {
/******/ 				if(__webpack_require__.o(moreModules, moduleId)) {
/******/ 					__webpack_require__.m[moduleId] = moreModules[moduleId];
/******/ 				}
/******/ 			}
/******/ 			if(runtime) runtime(__webpack_require__);
/******/ 			for(var i = 0; i < chunkIds.length; i++)
/******/ 				installedChunks[chunkIds[i]] = 1;
/******/ 		
/******/ 		};
/******/ 		
/******/ 		// require() chunk loading for javascript
/******/ 		__webpack_require__.f.require = (chunkId, promises) => {
/******/ 			// "1" is the signal for "already loaded"
/******/ 			if(!installedChunks[chunkId]) {
/******/ 				if(true) { // all chunks have JS
/******/ 					installChunk(require("./" + __webpack_require__.u(chunkId)));
/******/ 				} else installedChunks[chunkId] = 1;
/******/ 			}
/******/ 		};
/******/ 		
/******/ 		// no external install chunk
/******/ 		
/******/ 		// no HMR
/******/ 		
/******/ 		// no HMR manifest
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module is referenced by other modules so it can't be inlined
/******/ 	var __webpack_exports__ = __webpack_require__("./src/nextWork.ts");
/******/ 	
/******/ })()
;